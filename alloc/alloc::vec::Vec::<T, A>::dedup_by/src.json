{
  "name": "alloc::vec::Vec::<T, A>::dedup_by",
  "span": "$library/alloc/src/vec/mod.rs:2373:5: 2375:42",
  "src": "pub fn dedup_by<F>(&mut self, mut same_bucket: F)\n    where\n        F: FnMut(&mut T, &mut T) -> bool,\n    {\n        let len = self.len();\n        if len <= 1 {\n            return;\n        }\n\n        // Check if we ever want to remove anything.\n        // This allows to use copy_non_overlapping in next cycle.\n        // And avoids any memory writes if we don't need to remove anything.\n        let mut first_duplicate_idx: usize = 1;\n        let start = self.as_mut_ptr();\n        while first_duplicate_idx != len {\n            let found_duplicate = unsafe {\n                // SAFETY: first_duplicate always in range [1..len)\n                // Note that we start iteration from 1 so we never overflow.\n                let prev = start.add(first_duplicate_idx.wrapping_sub(1));\n                let current = start.add(first_duplicate_idx);\n                // We explicitly say in docs that references are reversed.\n                same_bucket(&mut *current, &mut *prev)\n            };\n            if found_duplicate {\n                break;\n            }\n            first_duplicate_idx += 1;\n        }\n        // Don't need to remove anything.\n        // We cannot get bigger than len.\n        if first_duplicate_idx == len {\n            return;\n        }\n\n        /* INVARIANT: vec.len() > read > write > write-1 >= 0 */\n        struct FillGapOnDrop<'a, T, A: core::alloc::Allocator> {\n            /* Offset of the element we want to check if it is duplicate */\n            read: usize,\n\n            /* Offset of the place where we want to place the non-duplicate\n             * when we find it. */\n            write: usize,\n\n            /* The Vec that would need correction if `same_bucket` panicked */\n            vec: &'a mut Vec<T, A>,\n        }\n\n        impl<'a, T, A: core::alloc::Allocator> Drop for FillGapOnDrop<'a, T, A> {\n            fn drop(&mut self) {\n                /* This code gets executed when `same_bucket` panics */\n\n                /* SAFETY: invariant guarantees that `read - write`\n                 * and `len - read` never overflow and that the copy is always\n                 * in-bounds. */\n                unsafe {\n                    let ptr = self.vec.as_mut_ptr();\n                    let len = self.vec.len();\n\n                    /* How many items were left when `same_bucket` panicked.\n                     * Basically vec[read..].len() */\n                    let items_left = len.wrapping_sub(self.read);\n\n                    /* Pointer to first item in vec[write..write+items_left] slice */\n                    let dropped_ptr = ptr.add(self.write);\n                    /* Pointer to first item in vec[read..] slice */\n                    let valid_ptr = ptr.add(self.read);\n\n                    /* Copy `vec[read..]` to `vec[write..write+items_left]`.\n                     * The slices can overlap, so `copy_nonoverlapping` cannot be used */\n                    ptr::copy(valid_ptr, dropped_ptr, items_left);\n\n                    /* How many items have been already dropped\n                     * Basically vec[read..write].len() */\n                    let dropped = self.read.wrapping_sub(self.write);\n\n                    self.vec.set_len(len - dropped);\n                }\n            }\n        }\n\n        /* Drop items while going through Vec, it should be more efficient than\n         * doing slice partition_dedup + truncate */\n\n        // Construct gap first and then drop item to avoid memory corruption if `T::drop` panics.\n        let mut gap =\n            FillGapOnDrop { read: first_duplicate_idx + 1, write: first_duplicate_idx, vec: self };\n        unsafe {\n            // SAFETY: we checked that first_duplicate_idx in bounds before.\n            // If drop panics, `gap` would remove this item without drop.\n            ptr::drop_in_place(start.add(first_duplicate_idx));\n        }\n\n        /* SAFETY: Because of the invariant, read_ptr, prev_ptr and write_ptr\n         * are always in-bounds and read_ptr never aliases prev_ptr */\n        unsafe {\n            while gap.read < len {\n                let read_ptr = start.add(gap.read);\n                let prev_ptr = start.add(gap.write.wrapping_sub(1));\n\n                // We explicitly say in docs that references are reversed.\n                let found_duplicate = same_bucket(&mut *read_ptr, &mut *prev_ptr);\n                if found_duplicate {\n                    // Increase `gap.read` now since the drop may panic.\n                    gap.read += 1;\n                    /* We have found duplicate, drop it in-place */\n                    ptr::drop_in_place(read_ptr);\n                } else {\n                    let write_ptr = start.add(gap.write);\n\n                    /* read_ptr cannot be equal to write_ptr because at this point\n                     * we guaranteed to skip at least one element (before loop starts).\n                     */\n                    ptr::copy_nonoverlapping(read_ptr, write_ptr, 1);\n\n                    /* We have filled that place, so go further */\n                    gap.write += 1;\n                    gap.read += 1;\n                }\n            }\n\n            /* Technically we could let `gap` clean up with its Drop, but\n             * when `same_bucket` is guaranteed to not panic, this bloats a little\n             * the codegen, so we just do it manually */\n            gap.vec.set_len(gap.write);\n            mem::forget(gap);\n        }\n    }"
}