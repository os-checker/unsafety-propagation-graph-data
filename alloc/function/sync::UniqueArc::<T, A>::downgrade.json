{
  "name": "sync::UniqueArc::<T, A>::downgrade",
  "safe": true,
  "callees": {
    "core::ptr::NonNull::<T>::as_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Acquires the underlying `*mut` pointer.\n\n # Examples\n\n ```\n use std::ptr::NonNull;\n\n let mut x = 0u32;\n let ptr = NonNull::new(&mut x).expect(\"ptr is null!\");\n\n let x_value = unsafe { *ptr.as_ptr() };\n assert_eq!(x_value, 0);\n\n unsafe { *ptr.as_ptr() += 2; }\n let x_value = unsafe { *ptr.as_ptr() };\n assert_eq!(x_value, 2);\n ```\n",
      "adt": {}
    },
    "core::sync::atomic::AtomicUsize::fetch_add": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Adds to the current value, returning the previous value.\n\n This operation wraps around on overflow.\n\n `fetch_add` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. All ordering modes are possible. Note that using\n [`Acquire`] makes the store part of this operation [`Relaxed`], and\n using [`Release`] makes the load part [`Relaxed`].\n\n **Note**: This method is only available on platforms that support atomic operations on\n\n # Examples\n\n ```\n\n assert_eq!(foo.fetch_add(10, Ordering::SeqCst), 0);\n assert_eq!(foo.load(Ordering::SeqCst), 10);\n ```\n",
      "adt": {}
    },
    "core::intrinsics::abort": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Aborts the execution of the process.\n\n Note that, unlike most intrinsics, this is safe to call;\n it does not require an `unsafe` block.\n Therefore, implementations must not require the user to uphold\n any safety invariants.\n\n [`std::process::abort`](../../std/process/fn.abort.html) is to be preferred if possible,\n as its behavior is more user-friendly and more stable.\n\n The current implementation of `intrinsics::abort` is to invoke an invalid instruction,\n on most platforms.\n On Unix, the\n process will probably terminate with a signal like `SIGABRT`, `SIGILL`, `SIGTRAP`, `SIGSEGV` or\n `SIGBUS`.  The precise behavior is not guaranteed and not stable.\n",
      "adt": {}
    },
    "core::clone::Clone::clone": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns a duplicate of the value.\n\n Note that what \"duplicate\" means varies by type:\n - For most types, this creates a deep, independent copy\n - For reference types like `&T`, this creates another reference to the same value\n - For smart pointers like [`Arc`] or [`Rc`], this increments the reference count\n   but still points to the same underlying data\n\n [`Arc`]: ../../std/sync/struct.Arc.html\n [`Rc`]: ../../std/rc/struct.Rc.html\n\n # Examples\n\n ```\n # #![allow(noop_method_call)]\n let hello = \"Hello\"; // &str implements Clone\n\n assert_eq!(\"Hello\", hello.clone());\n ```\n\n Example with a reference-counted type:\n\n ```\n use std::sync::{Arc, Mutex};\n\n let data = Arc::new(Mutex::new(vec![1, 2, 3]));\n let data_clone = data.clone(); // Creates another Arc pointing to the same Mutex\n\n {\n     let mut lock = data.lock().unwrap();\n     lock.push(4);\n }\n\n // Changes are visible through the clone because they share the same underlying data\n assert_eq!(*data_clone.lock().unwrap(), vec![1, 2, 3, 4]);\n ```\n",
      "adt": {}
    }
  },
  "adts": {
    "core::ptr::NonNull": [
      "Plain"
    ],
    "sync::UniqueArc": [
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(3)))",
      "Ref"
    ],
    "core::sync::atomic::AtomicUsize": [
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ],
    "sync::Weak": [
      "Plain"
    ]
  },
  "path": 2138,
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/alloc/src/sync.rs:4815:5: 4833:6",
  "src": "pub fn downgrade(this: &Self) -> Weak<T, A> {\n        // Using a relaxed ordering is alright here, as knowledge of the\n        // original reference prevents other threads from erroneously deleting\n        // the object or converting the object to a normal `Arc<T, A>`.\n        //\n        // Note that we don't need to test if the weak counter is locked because there\n        // are no such operations like `Arc::get_mut` or `Arc::make_mut` that will lock\n        // the weak counter.\n        //\n        // SAFETY: This pointer was allocated at creation time so we know it is valid.\n        let old_size = unsafe { (*this.ptr.as_ptr()).weak.fetch_add(1, Relaxed) };\n\n        // See comments in Arc::clone() for why we do this (for mem::forget).\n        if old_size > MAX_REFCOUNT {\n            abort();\n        }\n\n        Weak { ptr: this.ptr, alloc: this.alloc.clone() }\n    }",
  "mir": "fn sync::UniqueArc::<T, A>::downgrade(_1: &sync::UniqueArc<T, A>) -> sync::Weak<T, A> {\n    let mut _0: sync::Weak<T, A>;\n    let  _2: usize;\n    let mut _3: &core::sync::atomic::AtomicUsize;\n    let  _4: *mut sync::ArcInner<T>;\n    let mut _5: core::ptr::NonNull<sync::ArcInner<T>>;\n    let mut _6: core::sync::atomic::Ordering;\n    let mut _7: bool;\n    let  _8: !;\n    let mut _9: core::ptr::NonNull<sync::ArcInner<T>>;\n    let mut _10: A;\n    let mut _11: &A;\n    debug this => _1;\n    debug old_size => _2;\n    bb0: {\n        StorageLive(_3);\n        StorageLive(_4);\n        StorageLive(_5);\n        _5 = ((*_1).0: core::ptr::NonNull<sync::ArcInner<T>>);\n        _4 = core::ptr::NonNull::<sync::ArcInner<T>>::as_ptr(move _5) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_5);\n        _3 = &((*_4).1: core::sync::atomic::AtomicUsize);\n        StorageLive(_6);\n        _6 = core::sync::atomic::Ordering::Relaxed;\n        _2 = core::sync::atomic::AtomicUsize::fetch_add(move _3, 1_usize, move _6) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_6);\n        StorageDead(_4);\n        StorageDead(_3);\n        StorageLive(_7);\n        _7 = Gt(_2, sync::MAX_REFCOUNT);\n        switchInt(move _7) -> [0: bb4, otherwise: bb3];\n    }\n    bb3: {\n        _8 = core::intrinsics::abort() -> unwind unreachable;\n    }\n    bb4: {\n        StorageDead(_7);\n        StorageLive(_9);\n        _9 = ((*_1).0: core::ptr::NonNull<sync::ArcInner<T>>);\n        StorageLive(_10);\n        StorageLive(_11);\n        _11 = &((*_1).3: A);\n        _10 = <A as core::clone::Clone>::clone(move _11) -> [return: bb5, unwind unreachable];\n    }\n    bb5: {\n        StorageDead(_11);\n        _0 = Weak(move _9, move _10);\n        StorageDead(_10);\n        StorageDead(_9);\n        return;\n    }\n}\n",
  "doc": " Creates a new weak reference to the `UniqueArc`.\n\n Attempting to upgrade this weak reference will fail before the `UniqueArc` has been converted\n to a [`Arc`] using [`UniqueArc::into_arc`].\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}