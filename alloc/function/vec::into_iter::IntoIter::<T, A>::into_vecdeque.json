{
  "name": "vec::into_iter::IntoIter::<T, A>::into_vecdeque",
  "safe": true,
  "callees": {
    "core::mem::ManuallyDrop::<T>::new": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Wrap a value to be manually dropped.\n\n # Examples\n\n ```rust\n use std::mem::ManuallyDrop;\n let mut x = ManuallyDrop::new(String::from(\"Hello World!\"));\n x.truncate(5); // You can still safely operate on the value\n assert_eq!(*x, \"Hello\");\n // But `Drop` will not be run here\n # // FIXME(https://github.com/rust-lang/miri/issues/3670):\n # // use -Zmiri-disable-leak-check instead of unleaking in tests meant to leak.\n # let _ = ManuallyDrop::into_inner(x);\n ```\n",
      "adt": {}
    },
    "core::ops::Deref::deref": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Dereferences the value.\n",
      "adt": {}
    },
    "core::ptr::NonNull::<T>::as_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Acquires the underlying `*mut` pointer.\n\n # Examples\n\n ```\n use std::ptr::NonNull;\n\n let mut x = 0u32;\n let ptr = NonNull::new(&mut x).expect(\"ptr is null!\");\n\n let x_value = unsafe { *ptr.as_ptr() };\n assert_eq!(x_value, 0);\n\n unsafe { *ptr.as_ptr() += 2; }\n let x_value = unsafe { *ptr.as_ptr() };\n assert_eq!(x_value, 2);\n ```\n",
      "adt": {}
    },
    "core::iter::ExactSizeIterator::len": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the exact remaining length of the iterator.\n\n The implementation ensures that the iterator will return exactly `len()`\n more times a [`Some(T)`] value, before returning [`None`].\n This method has a default implementation, so you usually should not\n implement it directly. However, if you can provide a more efficient\n implementation, you can do so. See the [trait-level] docs for an\n example.\n\n This function has the same safety guarantees as the\n [`Iterator::size_hint`] function.\n\n [trait-level]: ExactSizeIterator\n [`Some(T)`]: Some\n\n # Examples\n\n Basic usage:\n\n ```\n // a finite range knows exactly how many times it will iterate\n let mut range = 0..5;\n\n assert_eq!(5, range.len());\n let _ = range.next();\n assert_eq!(4, range.len());\n ```\n",
      "adt": {}
    },
    "core::ptr::NonNull::<T>::offset_from_unsigned": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Calculates the distance between two pointers within the same allocation, *where it's known that\n `self` is equal to or greater than `origin`*. The returned value is in\n units of T: the distance in bytes is divided by `size_of::<T>()`.\n\n This computes the same value that [`offset_from`](#method.offset_from)\n would compute, but with the added precondition that the offset is\n guaranteed to be non-negative.  This method is equivalent to\n `usize::try_from(self.offset_from(origin)).unwrap_unchecked()`,\n but it provides slightly more information to the optimizer, which can\n sometimes allow it to optimize slightly better with some backends.\n\n This method can be though of as recovering the `count` that was passed\n to [`add`](#method.add) (or, with the parameters in the other order,\n to [`sub`](#method.sub)).  The following are all equivalent, assuming\n that their safety preconditions are met:\n ```rust\n # unsafe fn blah(ptr: std::ptr::NonNull<u32>, origin: std::ptr::NonNull<u32>, count: usize) -> bool { unsafe {\n ptr.offset_from_unsigned(origin) == count\n # &&\n origin.add(count) == ptr\n # &&\n ptr.sub(count) == origin\n # } }\n ```\n\n # Safety\n\n - The distance between the pointers must be non-negative (`self >= origin`)\n\n - *All* the safety conditions of [`offset_from`](#method.offset_from)\n   apply to this method as well; see it for the full details.\n\n Importantly, despite the return type of this method being able to represent\n a larger offset, it's still *not permitted* to pass pointers which differ\n by more than `isize::MAX` *bytes*.  As such, the result of this method will\n always be less than or equal to `isize::MAX as usize`.\n\n # Panics\n\n This function panics if `T` is a Zero-Sized Type (\"ZST\").\n\n # Examples\n\n ```\n use std::ptr::NonNull;\n\n let a = [0; 5];\n let ptr1: NonNull<u32> = NonNull::from(&a[1]);\n let ptr2: NonNull<u32> = NonNull::from(&a[3]);\n unsafe {\n     assert_eq!(ptr2.offset_from_unsigned(ptr1), 2);\n     assert_eq!(ptr1.add(2), ptr2);\n     assert_eq!(ptr2.sub(2), ptr1);\n     assert_eq!(ptr2.offset_from_unsigned(ptr2), 0);\n }\n\n // This would be incorrect, as the pointers are not correctly ordered:\n // ptr1.offset_from_unsigned(ptr2)\n ```\n",
      "adt": {}
    },
    "core::ptr::const_ptr::<impl *const T>::offset_from_unsigned": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Calculates the distance between two pointers within the same allocation, *where it's known that\n `self` is equal to or greater than `origin`*. The returned value is in\n units of T: the distance in bytes is divided by `size_of::<T>()`.\n\n This computes the same value that [`offset_from`](#method.offset_from)\n would compute, but with the added precondition that the offset is\n guaranteed to be non-negative.  This method is equivalent to\n `usize::try_from(self.offset_from(origin)).unwrap_unchecked()`,\n but it provides slightly more information to the optimizer, which can\n sometimes allow it to optimize slightly better with some backends.\n\n This method can be thought of as recovering the `count` that was passed\n to [`add`](#method.add) (or, with the parameters in the other order,\n to [`sub`](#method.sub)).  The following are all equivalent, assuming\n that their safety preconditions are met:\n ```rust\n # unsafe fn blah(ptr: *const i32, origin: *const i32, count: usize) -> bool { unsafe {\n ptr.offset_from_unsigned(origin) == count\n # &&\n origin.add(count) == ptr\n # &&\n ptr.sub(count) == origin\n # } }\n ```\n\n # Safety\n\n - The distance between the pointers must be non-negative (`self >= origin`)\n\n - *All* the safety conditions of [`offset_from`](#method.offset_from)\n   apply to this method as well; see it for the full details.\n\n Importantly, despite the return type of this method being able to represent\n a larger offset, it's still *not permitted* to pass pointers which differ\n by more than `isize::MAX` *bytes*.  As such, the result of this method will\n always be less than or equal to `isize::MAX as usize`.\n\n # Panics\n\n This function panics if `T` is a Zero-Sized Type (\"ZST\").\n\n # Examples\n\n ```\n let a = [0; 5];\n let ptr1: *const i32 = &a[1];\n let ptr2: *const i32 = &a[3];\n unsafe {\n     assert_eq!(ptr2.offset_from_unsigned(ptr1), 2);\n     assert_eq!(ptr1.add(2), ptr2);\n     assert_eq!(ptr2.sub(2), ptr1);\n     assert_eq!(ptr2.offset_from_unsigned(ptr2), 0);\n }\n\n // This would be incorrect, as the pointers are not correctly ordered:\n // ptr1.offset_from_unsigned(ptr2)\n ```\n",
      "adt": {}
    },
    "core::ops::DerefMut::deref_mut": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Mutably dereferences the value.\n",
      "adt": {}
    },
    "core::mem::ManuallyDrop::<T>::take": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Takes the value from the `ManuallyDrop<T>` container out.\n\n This method is primarily intended for moving out values in drop.\n Instead of using [`ManuallyDrop::drop`] to manually drop the value,\n you can use this method to take the value and use it however desired.\n\n Whenever possible, it is preferable to use [`into_inner`][`ManuallyDrop::into_inner`]\n instead, which prevents duplicating the content of the `ManuallyDrop<T>`.\n\n # Safety\n\n This function semantically moves out the contained value without preventing further usage,\n leaving the state of this container unchanged.\n It is your responsibility to ensure that this `ManuallyDrop` is not used again.\n\n",
      "adt": {}
    },
    "collections::vec_deque::VecDeque::<T, A>::from_contiguous_raw_parts_in": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates a `VecDeque` from a raw allocation, when the initialized\n part of that allocation forms a *contiguous* subslice thereof.\n\n For use by `vec::IntoIter::into_vecdeque`\n\n # Safety\n\n All the usual requirements on the allocated memory like in\n `Vec::from_raw_parts_in`, but takes a *range* of elements that are\n initialized rather than only supporting `0..len`.  Requires that\n `initialized.start` ≤ `initialized.end` ≤ `capacity`.\n",
      "adt": {
        "collections::vec_deque::VecDeque": "Constructor"
      }
    }
  },
  "adts": {
    "vec::into_iter::IntoIter": [
      "Plain",
      "Ref",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(4)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(5)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(2)))",
      "MutRef",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(3)))"
    ],
    "core::mem::ManuallyDrop": [
      "Plain",
      "Ref",
      "MutRef"
    ],
    "core::ptr::NonNull": [
      "Plain"
    ],
    "core::ops::Range": [
      "Plain"
    ],
    "collections::vec_deque::VecDeque": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "alloc::vec::into_iter::IntoIter::<T, A>::into_vecdeque"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/alloc/src/vec/into_iter.rs:171:5: 194:6",
  "src": "pub(crate) fn into_vecdeque(self) -> VecDeque<T, A> {\n        // Keep our `Drop` impl from dropping the elements and the allocator\n        let mut this = ManuallyDrop::new(self);\n\n        // SAFETY: This allocation originally came from a `Vec`, so it passes\n        // all those checks. We have `this.buf` ≤ `this.ptr` ≤ `this.end`,\n        // so the `offset_from_unsigned`s below cannot wrap, and will produce a well-formed\n        // range. `end` ≤ `buf + cap`, so the range will be in-bounds.\n        // Taking `alloc` is ok because nothing else is going to look at it,\n        // since our `Drop` impl isn't going to run so there's no more code.\n        unsafe {\n            let buf = this.buf.as_ptr();\n            let initialized = if T::IS_ZST {\n                // All the pointers are the same for ZSTs, so it's fine to\n                // say that they're all at the beginning of the \"allocation\".\n                0..this.len()\n            } else {\n                this.ptr.offset_from_unsigned(this.buf)..this.end.offset_from_unsigned(buf)\n            };\n            let cap = this.cap;\n            let alloc = ManuallyDrop::take(&mut this.alloc);\n            VecDeque::from_contiguous_raw_parts_in(buf, initialized, cap, alloc)\n        }\n    }",
  "mir": "fn vec::into_iter::IntoIter::<T, A>::into_vecdeque(_1: vec::into_iter::IntoIter<T, A>) -> collections::vec_deque::VecDeque<T, A> {\n    let mut _0: collections::vec_deque::VecDeque<T, A>;\n    let mut _2: core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>>;\n    let  _3: *mut T;\n    let mut _4: core::ptr::NonNull<T>;\n    let mut _5: &vec::into_iter::IntoIter<T, A>;\n    let mut _6: &core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>>;\n    let  _7: core::ops::Range<usize>;\n    let mut _8: usize;\n    let  _9: &vec::into_iter::IntoIter<T, A>;\n    let mut _10: &core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>>;\n    let mut _11: usize;\n    let mut _12: core::ptr::NonNull<T>;\n    let mut _13: &vec::into_iter::IntoIter<T, A>;\n    let mut _14: &core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>>;\n    let mut _15: core::ptr::NonNull<T>;\n    let mut _16: &vec::into_iter::IntoIter<T, A>;\n    let mut _17: &core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>>;\n    let mut _18: usize;\n    let mut _19: *const T;\n    let mut _20: &vec::into_iter::IntoIter<T, A>;\n    let mut _21: &core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>>;\n    let mut _22: *const T;\n    let  _23: usize;\n    let mut _24: &vec::into_iter::IntoIter<T, A>;\n    let mut _25: &core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>>;\n    let  _26: A;\n    let mut _27: &mut core::mem::ManuallyDrop<A>;\n    let mut _28: &mut vec::into_iter::IntoIter<T, A>;\n    let mut _29: &mut core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>>;\n    let mut _30: core::ops::Range<usize>;\n    debug self => _1;\n    debug this => _2;\n    debug buf => _3;\n    debug initialized => _7;\n    debug cap => _23;\n    debug alloc => _26;\n    bb0: {\n        StorageLive(_2);\n        _2 = core::mem::ManuallyDrop::<vec::into_iter::IntoIter<T, A>>::new(_1) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageLive(_4);\n        StorageLive(_5);\n        StorageLive(_6);\n        _6 = &_2;\n        _5 = <core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>> as core::ops::Deref>::deref(move _6) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_6);\n        _4 = ((*_5).0: core::ptr::NonNull<T>);\n        _3 = core::ptr::NonNull::<T>::as_ptr(move _4) -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        StorageDead(_4);\n        StorageDead(_5);\n        StorageLive(_7);\n        switchInt(<T as core::mem::SizedTypeProperties>::IS_ZST) -> [0: bb7, otherwise: bb4];\n    }\n    bb4: {\n        StorageLive(_8);\n        StorageLive(_10);\n        _10 = &_2;\n        _9 = <core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>> as core::ops::Deref>::deref(move _10) -> [return: bb5, unwind unreachable];\n    }\n    bb5: {\n        StorageDead(_10);\n        _8 = <vec::into_iter::IntoIter<T, A> as core::iter::ExactSizeIterator>::len(_9) -> [return: bb6, unwind unreachable];\n    }\n    bb6: {\n        _7 = Range(0_usize, move _8);\n        StorageDead(_8);\n        goto -> bb13;\n    }\n    bb7: {\n        StorageLive(_11);\n        StorageLive(_12);\n        StorageLive(_13);\n        StorageLive(_14);\n        _14 = &_2;\n        _13 = <core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>> as core::ops::Deref>::deref(move _14) -> [return: bb8, unwind unreachable];\n    }\n    bb8: {\n        StorageDead(_14);\n        _12 = ((*_13).4: core::ptr::NonNull<T>);\n        StorageLive(_15);\n        StorageLive(_16);\n        StorageLive(_17);\n        _17 = &_2;\n        _16 = <core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>> as core::ops::Deref>::deref(move _17) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_17);\n        _15 = ((*_16).0: core::ptr::NonNull<T>);\n        _11 = core::ptr::NonNull::<T>::offset_from_unsigned(move _12, move _15) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        StorageDead(_15);\n        StorageDead(_12);\n        StorageLive(_18);\n        StorageLive(_19);\n        StorageLive(_20);\n        StorageLive(_21);\n        _21 = &_2;\n        _20 = <core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>> as core::ops::Deref>::deref(move _21) -> [return: bb11, unwind unreachable];\n    }\n    bb11: {\n        StorageDead(_21);\n        _19 = ((*_20).5: *const T);\n        StorageLive(_22);\n        _22 = _3 as *const T;\n        _18 = core::ptr::const_ptr::<impl *const T>::offset_from_unsigned(move _19, move _22) -> [return: bb12, unwind unreachable];\n    }\n    bb12: {\n        StorageDead(_22);\n        StorageDead(_19);\n        _7 = Range(move _11, move _18);\n        StorageDead(_20);\n        StorageDead(_18);\n        StorageDead(_16);\n        StorageDead(_13);\n        StorageDead(_11);\n        goto -> bb13;\n    }\n    bb13: {\n        StorageLive(_24);\n        StorageLive(_25);\n        _25 = &_2;\n        _24 = <core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>> as core::ops::Deref>::deref(move _25) -> [return: bb14, unwind unreachable];\n    }\n    bb14: {\n        StorageDead(_25);\n        _23 = ((*_24).2: usize);\n        StorageDead(_24);\n        StorageLive(_28);\n        StorageLive(_29);\n        _29 = &mut _2;\n        _28 = <core::mem::ManuallyDrop<vec::into_iter::IntoIter<T, A>> as core::ops::DerefMut>::deref_mut(move _29) -> [return: bb15, unwind unreachable];\n    }\n    bb15: {\n        StorageDead(_29);\n        _27 = &mut ((*_28).3: core::mem::ManuallyDrop<A>);\n        _26 = core::mem::ManuallyDrop::<A>::take(_27) -> [return: bb16, unwind unreachable];\n    }\n    bb16: {\n        StorageDead(_28);\n        StorageLive(_30);\n        _30 = move _7;\n        _0 = collections::vec_deque::VecDeque::<T, A>::from_contiguous_raw_parts_in(_3, move _30, _23, _26) -> [return: bb17, unwind unreachable];\n    }\n    bb17: {\n        StorageDead(_30);\n        StorageDead(_7);\n        StorageDead(_2);\n        return;\n    }\n}\n",
  "doc": "",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}