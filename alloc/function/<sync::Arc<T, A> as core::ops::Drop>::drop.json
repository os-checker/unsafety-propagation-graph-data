{
  "name": "<sync::Arc<T, A> as core::ops::Drop>::drop",
  "safe": true,
  "callees": {
    "sync::Arc::<T, A>::inner": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "sync::Arc": "ImmutableAsArgument"
      }
    },
    "core::sync::atomic::AtomicUsize::fetch_sub": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Subtracts from the current value, returning the previous value.\n\n This operation wraps around on overflow.\n\n `fetch_sub` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. All ordering modes are possible. Note that using\n [`Acquire`] makes the store part of this operation [`Relaxed`], and\n using [`Release`] makes the load part [`Relaxed`].\n\n **Note**: This method is only available on platforms that support atomic operations on\n\n # Examples\n\n ```\n\n assert_eq!(foo.fetch_sub(10, Ordering::SeqCst), 20);\n assert_eq!(foo.load(Ordering::SeqCst), 10);\n ```\n",
      "adt": {}
    },
    "core::sync::atomic::fence": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " An atomic fence.\n\n Fences create synchronization between themselves and atomic operations or fences in other\n threads. To achieve this, a fence prevents the compiler and CPU from reordering certain types of\n memory operations around it.\n\n There are 3 different ways to use an atomic fence:\n\n - atomic - fence synchronization: an atomic operation with (at least) [`Release`] ordering\n   semantics synchronizes with a fence with (at least) [`Acquire`] ordering semantics.\n - fence - atomic synchronization: a fence with (at least) [`Release`] ordering semantics\n   synchronizes with an atomic operation with (at least) [`Acquire`] ordering semantics.\n - fence - fence synchronization: a fence with (at least) [`Release`] ordering semantics\n   synchronizes with a fence with (at least) [`Acquire`] ordering semantics.\n\n These 3 ways complement the regular, fence-less, atomic - atomic synchronization.\n\n ## Atomic - Fence\n\n An atomic operation on one thread will synchronize with a fence on another thread when:\n\n -   on thread 1:\n     -   an atomic operation 'X' with (at least) [`Release`] ordering semantics on some atomic\n         object 'm',\n\n -   is paired on thread 2 with:\n     -   an atomic read 'Y' with any order on 'm',\n     -   followed by a fence 'B' with (at least) [`Acquire`] ordering semantics.\n\n This provides a happens-before dependence between X and B.\n\n ```text\n     Thread 1                                          Thread 2\n\n m.store(3, Release); X ---------\n                                |\n                                |\n                                -------------> Y  if m.load(Relaxed) == 3 {\n                                               B      fence(Acquire);\n                                                      ...\n                                                  }\n ```\n\n ## Fence - Atomic\n\n A fence on one thread will synchronize with an atomic operation on another thread when:\n\n -   on thread:\n     -   a fence 'A' with (at least) [`Release`] ordering semantics,\n     -   followed by an atomic write 'X' with any ordering on some atomic object 'm',\n\n -   is paired on thread 2 with:\n     -   an atomic operation 'Y' with (at least) [`Acquire`] ordering semantics.\n\n This provides a happens-before dependence between A and Y.\n\n ```text\n     Thread 1                                          Thread 2\n\n fence(Release);      A\n m.store(3, Relaxed); X ---------\n                                |\n                                |\n                                -------------> Y  if m.load(Acquire) == 3 {\n                                                      ...\n                                                  }\n ```\n\n ## Fence - Fence\n\n A fence on one thread will synchronize with a fence on another thread when:\n\n -   on thread 1:\n     -   a fence 'A' which has (at least) [`Release`] ordering semantics,\n     -   followed by an atomic write 'X' with any ordering on some atomic object 'm',\n\n -   is paired on thread 2 with:\n     -   an atomic read 'Y' with any ordering on 'm',\n     -   followed by a fence 'B' with (at least) [`Acquire`] ordering semantics.\n\n This provides a happens-before dependence between A and B.\n\n ```text\n     Thread 1                                          Thread 2\n\n fence(Release);      A --------------\n m.store(3, Relaxed); X ---------    |\n                                |    |\n                                |    |\n                                -------------> Y  if m.load(Relaxed) == 3 {\n                                     |-------> B      fence(Acquire);\n                                                      ...\n                                                  }\n ```\n\n ## Mandatory Atomic\n\n Note that in the examples above, it is crucial that the access to `m` are atomic. Fences cannot\n be used to establish synchronization between non-atomic accesses in different threads. However,\n thanks to the happens-before relationship, any non-atomic access that happen-before the atomic\n operation or fence with (at least) [`Release`] ordering semantics are now also properly\n synchronized with any non-atomic accesses that happen-after the atomic operation or fence with\n (at least) [`Acquire`] ordering semantics.\n\n ## Memory Ordering\n\n A fence which has [`SeqCst`] ordering, in addition to having both [`Acquire`] and [`Release`]\n semantics, participates in the global program order of the other [`SeqCst`] operations and/or\n fences.\n\n Accepts [`Acquire`], [`Release`], [`AcqRel`] and [`SeqCst`] orderings.\n\n # Panics\n\n Panics if `order` is [`Relaxed`].\n\n # Examples\n\n ```\n use std::sync::atomic::AtomicBool;\n use std::sync::atomic::fence;\n use std::sync::atomic::Ordering;\n\n // A mutual exclusion primitive based on spinlock.\n pub struct Mutex {\n     flag: AtomicBool,\n }\n\n impl Mutex {\n     pub fn new() -> Mutex {\n         Mutex {\n             flag: AtomicBool::new(false),\n         }\n     }\n\n     pub fn lock(&self) {\n         // Wait until the old value is `false`.\n         while self\n             .flag\n             .compare_exchange_weak(false, true, Ordering::Relaxed, Ordering::Relaxed)\n             .is_err()\n         {}\n         // This fence synchronizes-with store in `unlock`.\n         fence(Ordering::Acquire);\n     }\n\n     pub fn unlock(&self) {\n         self.flag.store(false, Ordering::Release);\n     }\n }\n ```\n",
      "adt": {}
    },
    "core::ptr::NonNull::<T>::as_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Acquires the underlying `*mut` pointer.\n\n # Examples\n\n ```\n use std::ptr::NonNull;\n\n let mut x = 0u32;\n let ptr = NonNull::new(&mut x).expect(\"ptr is null!\");\n\n let x_value = unsafe { *ptr.as_ptr() };\n assert_eq!(x_value, 0);\n\n unsafe { *ptr.as_ptr() += 2; }\n let x_value = unsafe { *ptr.as_ptr() };\n assert_eq!(x_value, 2);\n ```\n",
      "adt": {}
    },
    "core::ptr::addr_eq": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Compares the *addresses* of the two pointers for equality,\n ignoring any metadata in fat pointers.\n\n If the arguments are thin pointers of the same type,\n then this is the same as [`eq`].\n\n # Examples\n\n ```\n use std::ptr;\n\n let whole: &[i32; 3] = &[1, 2, 3];\n let first: &i32 = &whole[0];\n\n assert!(ptr::addr_eq(whole, first));\n assert!(!ptr::eq::<dyn std::fmt::Debug>(whole, first));\n ```\n",
      "adt": {}
    },
    "core::fmt::Arguments::<'a>::from_str": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Create a `fmt::Arguments` object for a single static string.\n\n Formatting this `fmt::Arguments` will just produce the string as-is.\n",
      "adt": {}
    },
    "sync::Arc::<T, A>::drop_slow": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "sync::Arc": "MutableAsArgument"
      }
    },
    "core::panicking::panic_fmt": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " The entry point for panicking with a formatted message.\n\n This is designed to reduce the amount of code required at the call\n site as much as possible (so that `panic!()` has as low an impact\n on (e.g.) the inlining of other functions as possible), by moving\n the actual formatting into this shared place.\n",
      "adt": {}
    }
  },
  "adts": {
    "sync::Arc": [
      "Ref",
      "Deref",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "MutRef"
    ],
    "sync::ArcInner": [
      "Ref",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "Deref"
    ],
    "core::sync::atomic::AtomicUsize": [
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ],
    "core::ptr::NonNull": [
      "Plain"
    ],
    "sync::SliceArcInnerForStatic": [
      "Ref",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))"
    ],
    "core::fmt::Arguments": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "alloc::<sync::Arc<T, A> as core::ops::Drop>::drop"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/alloc/src/sync.rs:2807:5: 2856:6",
  "src": "fn drop(&mut self) {\n        // Because `fetch_sub` is already atomic, we do not need to synchronize\n        // with other threads unless we are going to delete the object. This\n        // same logic applies to the below `fetch_sub` to the `weak` count.\n        if self.inner().strong.fetch_sub(1, Release) != 1 {\n            return;\n        }\n\n        // This fence is needed to prevent reordering of use of the data and\n        // deletion of the data. Because it is marked `Release`, the decreasing\n        // of the reference count synchronizes with this `Acquire` fence. This\n        // means that use of the data happens before decreasing the reference\n        // count, which happens before this fence, which happens before the\n        // deletion of the data.\n        //\n        // As explained in the [Boost documentation][1],\n        //\n        // > It is important to enforce any possible access to the object in one\n        // > thread (through an existing reference) to *happen before* deleting\n        // > the object in a different thread. This is achieved by a \"release\"\n        // > operation after dropping a reference (any access to the object\n        // > through this reference must obviously happened before), and an\n        // > \"acquire\" operation before deleting the object.\n        //\n        // In particular, while the contents of an Arc are usually immutable, it's\n        // possible to have interior writes to something like a Mutex<T>. Since a\n        // Mutex is not acquired when it is deleted, we can't rely on its\n        // synchronization logic to make writes in thread A visible to a destructor\n        // running in thread B.\n        //\n        // Also note that the Acquire fence here could probably be replaced with an\n        // Acquire load, which could improve performance in highly-contended\n        // situations. See [2].\n        //\n        // [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)\n        // [2]: (https://github.com/rust-lang/rust/pull/41714)\n        acquire!(self.inner().strong);\n\n        // Make sure we aren't trying to \"drop\" the shared static for empty slices\n        // used by Default::default.\n        debug_assert!(\n            !ptr::addr_eq(self.ptr.as_ptr(), &STATIC_INNER_SLICE.inner),\n            \"Arcs backed by a static should never reach a strong count of 0. \\\n            Likely decrement_strong_count or from_raw were called too many times.\",\n        );\n\n        unsafe {\n            self.drop_slow();\n        }\n    }",
  "mir": "fn <sync::Arc<T, A> as core::ops::Drop>::drop(_1: &mut sync::Arc<T, A>) -> () {\n    let mut _0: ();\n    let mut _2: usize;\n    let mut _3: &core::sync::atomic::AtomicUsize;\n    let  _4: &sync::ArcInner<T>;\n    let mut _5: &sync::Arc<T, A>;\n    let mut _6: core::sync::atomic::Ordering;\n    let  _7: ();\n    let mut _8: core::sync::atomic::Ordering;\n    let mut _9: bool;\n    let mut _10: *const sync::ArcInner<T>;\n    let mut _11: *mut sync::ArcInner<T>;\n    let mut _12: core::ptr::NonNull<sync::ArcInner<T>>;\n    let mut _13: *const sync::ArcInner<[u8; 1]>;\n    let  _14: &sync::ArcInner<[u8; 1]>;\n    let  _15: &sync::SliceArcInnerForStatic;\n    let  _16: !;\n    let mut _17: core::fmt::Arguments<'_>;\n    let  _18: ();\n    debug self => _1;\n    bb0: {\n        StorageLive(_2);\n        StorageLive(_3);\n        StorageLive(_4);\n        StorageLive(_5);\n        _5 = &(*_1);\n        _4 = sync::Arc::<T, A>::inner(move _5) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_5);\n        _3 = &((*_4).0: core::sync::atomic::AtomicUsize);\n        StorageLive(_6);\n        _6 = core::sync::atomic::Ordering::Release;\n        _2 = core::sync::atomic::AtomicUsize::fetch_sub(move _3, 1_usize, move _6) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_6);\n        StorageDead(_3);\n        switchInt(move _2) -> [1: bb4, otherwise: bb3];\n    }\n    bb3: {\n        StorageDead(_4);\n        StorageDead(_2);\n        goto -> bb12;\n    }\n    bb4: {\n        StorageDead(_4);\n        StorageDead(_2);\n        StorageLive(_8);\n        _8 = core::sync::atomic::Ordering::Acquire;\n        _7 = core::sync::atomic::fence(move _8) -> [return: bb5, unwind unreachable];\n    }\n    bb5: {\n        StorageDead(_8);\n        StorageLive(_9);\n        StorageLive(_10);\n        StorageLive(_11);\n        StorageLive(_12);\n        _12 = ((*_1).0: core::ptr::NonNull<sync::ArcInner<T>>);\n        _11 = core::ptr::NonNull::<sync::ArcInner<T>>::as_ptr(move _12) -> [return: bb6, unwind unreachable];\n    }\n    bb6: {\n        _10 = move _11 as *const sync::ArcInner<T>;\n        StorageDead(_12);\n        StorageDead(_11);\n        StorageLive(_13);\n        StorageLive(_14);\n        StorageLive(_15);\n        _15 = {alloc107: &sync::SliceArcInnerForStatic};\n        _14 = &((*_15).0: sync::ArcInner<[u8; 1]>);\n        _13 = &raw const (*_14);\n        _9 = core::ptr::addr_eq::<sync::ArcInner<T>, sync::ArcInner<[u8; 1]>>(move _10, move _13) -> [return: bb7, unwind unreachable];\n    }\n    bb7: {\n        switchInt(move _9) -> [0: bb9, otherwise: bb8];\n    }\n    bb8: {\n        StorageDead(_13);\n        StorageDead(_10);\n        StorageDead(_15);\n        StorageDead(_14);\n        StorageLive(_17);\n        _17 = core::fmt::Arguments::<'_>::from_str(\"Arcs backed by a static should never reach a strong count of 0. Likely decrement_strong_count or from_raw were called too many times.\") -> [return: bb10, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_13);\n        StorageDead(_10);\n        StorageDead(_15);\n        StorageDead(_14);\n        StorageDead(_9);\n        _18 = sync::Arc::<T, A>::drop_slow(_1) -> [return: bb11, unwind unreachable];\n    }\n    bb10: {\n        _16 = core::panicking::panic_fmt(move _17) -> unwind unreachable;\n    }\n    bb11: {\n        goto -> bb12;\n    }\n    bb12: {\n        return;\n    }\n}\n",
  "doc": " Drops the `Arc`.\n\n This will decrement the strong reference count. If the strong reference\n count reaches zero then the only other references (if any) are\n [`Weak`], so we `drop` the inner value.\n\n # Examples\n\n ```\n use std::sync::Arc;\n\n struct Foo;\n\n impl Drop for Foo {\n     fn drop(&mut self) {\n         println!(\"dropped!\");\n     }\n }\n\n let foo  = Arc::new(Foo);\n let foo2 = Arc::clone(&foo);\n\n drop(foo);    // Doesn't print anything\n drop(foo2);   // Prints \"dropped!\"\n ```\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}