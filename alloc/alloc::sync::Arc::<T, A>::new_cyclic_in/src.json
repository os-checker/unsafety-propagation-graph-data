{
  "name": "alloc::sync::Arc::<T, A>::new_cyclic_in",
  "span": "$library/alloc/src/sync.rs:882:5: 884:37",
  "src": "pub fn new_cyclic_in<F>(data_fn: F, alloc: A) -> Arc<T, A>\n    where\n        F: FnOnce(&Weak<T, A>) -> T,\n    {\n        // Construct the inner in the \"uninitialized\" state with a single\n        // weak reference.\n        let (uninit_raw_ptr, alloc) = Box::into_raw_with_allocator(Box::new_in(\n            ArcInner {\n                strong: atomic::AtomicUsize::new(0),\n                weak: atomic::AtomicUsize::new(1),\n                data: mem::MaybeUninit::<T>::uninit(),\n            },\n            alloc,\n        ));\n        let uninit_ptr: NonNull<_> = (unsafe { &mut *uninit_raw_ptr }).into();\n        let init_ptr: NonNull<ArcInner<T>> = uninit_ptr.cast();\n\n        let weak = Weak { ptr: init_ptr, alloc };\n\n        // It's important we don't give up ownership of the weak pointer, or\n        // else the memory might be freed by the time `data_fn` returns. If\n        // we really wanted to pass ownership, we could create an additional\n        // weak pointer for ourselves, but this would result in additional\n        // updates to the weak reference count which might not be necessary\n        // otherwise.\n        let data = data_fn(&weak);\n\n        // Now we can properly initialize the inner value and turn our weak\n        // reference into a strong reference.\n        let strong = unsafe {\n            let inner = init_ptr.as_ptr();\n            ptr::write(&raw mut (*inner).data, data);\n\n            // The above write to the data field must be visible to any threads which\n            // observe a non-zero strong count. Therefore we need at least \"Release\" ordering\n            // in order to synchronize with the `compare_exchange_weak` in `Weak::upgrade`.\n            //\n            // \"Acquire\" ordering is not required. When considering the possible behaviors\n            // of `data_fn` we only need to look at what it could do with a reference to a\n            // non-upgradeable `Weak`:\n            // - It can *clone* the `Weak`, increasing the weak reference count.\n            // - It can drop those clones, decreasing the weak reference count (but never to zero).\n            //\n            // These side effects do not impact us in any way, and no other side effects are\n            // possible with safe code alone.\n            let prev_value = (*inner).strong.fetch_add(1, Release);\n            debug_assert_eq!(prev_value, 0, \"No prior strong references should exist\");\n\n            // Strong references should collectively own a shared weak reference,\n            // so don't run the destructor for our old weak reference.\n            // Calling into_raw_with_allocator has the double effect of giving us back the allocator,\n            // and forgetting the weak reference.\n            let alloc = weak.into_raw_with_allocator().1;\n\n            Arc::from_inner_in(init_ptr, alloc)\n        };\n\n        strong\n    }"
}