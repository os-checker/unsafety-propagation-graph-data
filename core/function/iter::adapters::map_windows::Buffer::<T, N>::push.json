{
  "name": "iter::adapters::map_windows::Buffer::<T, N>::push",
  "safe": true,
  "callees": {
    "iter::adapters::map_windows::Buffer::<T, N>::buffer_mut_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "iter::adapters::map_windows::Buffer": "MutableAsArgument"
      }
    },
    "panicking::panic": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " The underlying implementation of core's `panic!` macro when no formatting is used.\n",
      "adt": {}
    },
    "ptr::mut_ptr::<impl *mut T>::add": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "\n # Examples\n\n ```\n let mut s: String = \"123\".to_string();\n let ptr: *mut u8 = s.as_mut_ptr();\n\n unsafe {\n     assert_eq!('2', *ptr.add(1) as char);\n     assert_eq!('3', *ptr.add(2) as char);\n }\n ```\n",
      "adt": {}
    },
    "ptr::copy_nonoverlapping": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Copies `count * size_of::<T>()` bytes from `src` to `dst`. The source\n and destination must *not* overlap.\n\n For regions of memory which might overlap, use [`copy`] instead.\n\n `copy_nonoverlapping` is semantically equivalent to C's [`memcpy`], but\n with the source and destination arguments swapped,\n and `count` counting the number of `T`s instead of bytes.\n\n The copy is \"untyped\" in the sense that data may be uninitialized or otherwise violate the\n requirements of `T`. The initialization state is preserved exactly.\n\n [`memcpy`]: https://en.cppreference.com/w/c/string/byte/memcpy\n\n # Safety\n\n Behavior is undefined if any of the following conditions are violated:\n\n * `src` must be [valid] for reads of `count * size_of::<T>()` bytes.\n\n * `dst` must be [valid] for writes of `count * size_of::<T>()` bytes.\n\n * Both `src` and `dst` must be properly aligned.\n\n * The region of memory beginning at `src` with a size of `count *\n   size_of::<T>()` bytes must *not* overlap with the region of memory\n   beginning at `dst` with the same size.\n\n Like [`read`], `copy_nonoverlapping` creates a bitwise copy of `T`, regardless of\n whether `T` is [`Copy`]. If `T` is not [`Copy`], using *both* the values\n in the region beginning at `*src` and the region beginning at `*dst` can\n [violate memory safety][read-ownership].\n\n Note that even if the effectively copied size (`count * size_of::<T>()`) is\n `0`, the pointers must be properly aligned.\n\n [`read`]: crate::ptr::read\n [read-ownership]: crate::ptr::read#ownership-of-the-returned-value\n [valid]: crate::ptr#safety\n\n # Examples\n\n Manually implement [`Vec::append`]:\n\n ```\n use std::ptr;\n\n /// Moves all the elements of `src` into `dst`, leaving `src` empty.\n fn append<T>(dst: &mut Vec<T>, src: &mut Vec<T>) {\n     let src_len = src.len();\n     let dst_len = dst.len();\n\n     // Ensure that `dst` has enough capacity to hold all of `src`.\n     dst.reserve(src_len);\n\n     unsafe {\n         // The call to add is always safe because `Vec` will never\n         // allocate more than `isize::MAX` bytes.\n         let dst_ptr = dst.as_mut_ptr().add(dst_len);\n         let src_ptr = src.as_ptr();\n\n         // Truncate `src` without dropping its contents. We do this first,\n         // to avoid problems in case something further down panics.\n         src.set_len(0);\n\n         // The two regions cannot overlap because mutable references do\n         // not alias, and two different vectors cannot own the same\n         // memory.\n         ptr::copy_nonoverlapping(src_ptr, dst_ptr, src_len);\n\n         // Notify `dst` that it now holds the contents of `src`.\n         dst.set_len(dst_len + src_len);\n     }\n }\n\n let mut a = vec!['r'];\n let mut b = vec!['u', 's', 't'];\n\n append(&mut a, &mut b);\n\n assert_eq!(a, &['r', 'u', 's', 't']);\n assert!(b.is_empty());\n ```\n\n [`Vec::append`]: ../../std/vec/struct.Vec.html#method.append\n",
      "adt": {}
    },
    "mem::maybe_uninit::MaybeUninit::<T>::write": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Sets the value of the `MaybeUninit<T>`.\n\n This overwrites any previous value without dropping it, so be careful\n not to use this twice unless you want to skip running the destructor.\n For your convenience, this also returns a mutable reference to the\n (now safely initialized) contents of `self`.\n\n As the content is stored inside a `ManuallyDrop`, the destructor is not\n run for the inner data if the MaybeUninit leaves scope without a call to\n [`assume_init`], [`assume_init_drop`], or similar. Code that receives\n the mutable reference returned by this function needs to keep this in\n mind. The safety model of Rust regards leaks as safe, but they are\n usually still undesirable. This being said, the mutable reference\n behaves like any other mutable reference would, so assigning a new value\n to it will drop the old content.\n\n [`assume_init`]: Self::assume_init\n [`assume_init_drop`]: Self::assume_init_drop\n\n # Examples\n\n Correct usage of this method:\n\n ```rust\n use std::mem::MaybeUninit;\n\n let mut x = MaybeUninit::<Vec<u8>>::uninit();\n\n {\n     let hello = x.write((&b\"Hello, world!\").to_vec());\n     // Setting hello does not leak prior allocations, but drops them\n     *hello = (&b\"Hello\").to_vec();\n     hello[0] = 'h' as u8;\n }\n // x is initialized now:\n let s = unsafe { x.assume_init() };\n assert_eq!(b\"hello\", s.as_slice());\n ```\n\n This usage of the method causes a leak:\n\n ```rust\n use std::mem::MaybeUninit;\n\n let mut x = MaybeUninit::<String>::uninit();\n\n x.write(\"Hello\".to_string());\n # // FIXME(https://github.com/rust-lang/miri/issues/3670):\n # // use -Zmiri-disable-leak-check instead of unleaking in tests meant to leak.\n # unsafe { MaybeUninit::assume_init_drop(&mut x); }\n // This leaks the contained string:\n x.write(\"hello\".to_string());\n // x is initialized now:\n let s = unsafe { x.assume_init() };\n ```\n\n This method can be used to avoid unsafe in some cases. The example below\n shows a part of an implementation of a fixed sized arena that lends out\n pinned references.\n With `write`, we can avoid the need to write through a raw pointer:\n\n ```rust\n use core::pin::Pin;\n use core::mem::MaybeUninit;\n\n struct PinArena<T> {\n     memory: Box<[MaybeUninit<T>]>,\n     len: usize,\n }\n\n impl <T> PinArena<T> {\n     pub fn capacity(&self) -> usize {\n         self.memory.len()\n     }\n     pub fn push(&mut self, val: T) -> Pin<&mut T> {\n         if self.len >= self.capacity() {\n             panic!(\"Attempted to push to a full pin arena!\");\n         }\n         let ref_ = self.memory[self.len].write(val);\n         self.len += 1;\n         unsafe { Pin::new_unchecked(ref_) }\n     }\n }\n ```\n",
      "adt": {
        "mem::maybe_uninit::MaybeUninit": "MutableAsArgument"
      }
    },
    "ptr::mut_ptr::<impl *mut mem::maybe_uninit::MaybeUninit<T>>::cast_init": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Casts from a maybe-uninitialized type to its initialized version.\n\n This is always safe, since UB can only occur if the pointer is read\n before being initialized.\n",
      "adt": {}
    },
    "ptr::drop_in_place": {
      "safe": false,
      "tags": {
        "tags": [
          {
            "tag": {
              "typ": null,
              "name": "unconditional_recursion"
            },
            "args": []
          }
        ],
        "spec": {},
        "docs": [
          "* unconditional_recursion\n"
        ]
      },
      "doc": " Executes the destructor (if any) of the pointed-to value.\n\n This is almost the same as calling [`ptr::read`] and discarding\n the result, but has the following advantages:\n\n * It is *required* to use `drop_in_place` to drop unsized types like\n   trait objects, because they can't be read out onto the stack and\n   dropped normally.\n\n * It is friendlier to the optimizer to do this over [`ptr::read`] when\n   dropping manually allocated memory (e.g., in the implementations of\n   `Box`/`Rc`/`Vec`), as the compiler doesn't need to prove that it's\n   sound to elide the copy.\n\n * It can be used to drop [pinned] data when `T` is not `repr(packed)`\n   (pinned data must not be moved before it is dropped).\n\n Unaligned values cannot be dropped in place, they must be copied to an aligned\n location first using [`ptr::read_unaligned`]. For packed structs, this move is\n done automatically by the compiler. This means the fields of packed structs\n are not dropped in-place.\n\n [`ptr::read`]: self::read\n [`ptr::read_unaligned`]: self::read_unaligned\n [pinned]: crate::pin\n\n # Safety\n\n Behavior is undefined if any of the following conditions are violated:\n\n * `to_drop` must be [valid] for both reads and writes.\n\n * `to_drop` must be properly aligned, even if `T` has size 0.\n\n * `to_drop` must be nonnull, even if `T` has size 0.\n\n * The value `to_drop` points to must be valid for dropping, which may mean\n   it must uphold additional invariants. These invariants depend on the type\n   of the value being dropped. For instance, when dropping a Box, the box's\n   pointer to the heap must be valid.\n\n * While `drop_in_place` is executing, the only way to access parts of\n   `to_drop` is through the `&mut self` references supplied to the\n   `Drop::drop` methods that `drop_in_place` invokes.\n\n Additionally, if `T` is not [`Copy`], using the pointed-to value after\n calling `drop_in_place` can cause undefined behavior. Note that `*to_drop =\n foo` counts as a use because it will cause the value to be dropped\n again. [`write()`] can be used to overwrite data without causing it to be\n dropped.\n\n [valid]: self#safety\n\n # Examples\n\n Manually remove the last item from a vector:\n\n ```\n use std::ptr;\n use std::rc::Rc;\n\n let last = Rc::new(1);\n let weak = Rc::downgrade(&last);\n\n let mut v = vec![Rc::new(0), last];\n\n unsafe {\n     // Get a raw pointer to the last element in `v`.\n     let ptr = &mut v[1] as *mut _;\n     // Shorten `v` to prevent the last item from being dropped. We do that first,\n     // to prevent issues if the `drop_in_place` below panics.\n     v.set_len(1);\n     // Without a call `drop_in_place`, the last item would never be dropped,\n     // and the memory it manages would be leaked.\n     ptr::drop_in_place(ptr);\n }\n\n assert_eq!(v, &[0.into()]);\n\n // Ensure that the last item was dropped.\n assert!(weak.upgrade().is_none());\n ```\n",
      "adt": {}
    }
  },
  "adts": {
    "iter::adapters::map_windows::Buffer": [
      "MutRef",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(1)))"
    ],
    "mem::maybe_uninit::MaybeUninit": [
      "MutRef"
    ]
  },
  "path": {
    "type": "Local",
    "path": "core::iter::adapters::map_windows::Buffer::<T, N>::push"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/iter/adapters/map_windows.rs:145:5: 199:6",
  "src": "fn push(&mut self, next: T) {\n        let buffer_mut_ptr = self.buffer_mut_ptr();\n        debug_assert!(self.start + N <= 2 * N);\n\n        let to_drop = if self.start == N {\n            // We have reached the end of our buffer and have to copy\n            // everything to the start. Example layout for N = 3.\n            //\n            //    0   1   2   3   4   5            0   1   2   3   4   5\n            //  ┌───┬───┬───┬───┬───┬───┐        ┌───┬───┬───┬───┬───┬───┐\n            //  │ - │ - │ - │ a │ b │ c │   ->   │ b │ c │ n │ - │ - │ - │\n            //  └───┴───┴───┴───┴───┴───┘        └───┴───┴───┴───┴───┴───┘\n            //                ↑                    ↑\n            //              start                start\n\n            // SAFETY: the two pointers are valid for reads/writes of N -1\n            // elements because our array's size is semantically 2 * N. The\n            // regions also don't overlap for the same reason.\n            //\n            // We leave the old elements in place. As soon as `start` is set\n            // to 0, we treat them as uninitialized and treat their copies\n            // as initialized.\n            let to_drop = unsafe {\n                ptr::copy_nonoverlapping(buffer_mut_ptr.add(self.start + 1), buffer_mut_ptr, N - 1);\n                (*buffer_mut_ptr.add(N - 1)).write(next);\n                buffer_mut_ptr.add(self.start)\n            };\n            self.start = 0;\n            to_drop\n        } else {\n            // SAFETY: `self.start` is < N as guaranteed by the invariant\n            // plus the check above. Even if the drop at the end panics,\n            // the invariant is upheld.\n            //\n            // Example layout for N = 3:\n            //\n            //    0   1   2   3   4   5            0   1   2   3   4   5\n            //  ┌───┬───┬───┬───┬───┬───┐        ┌───┬───┬───┬───┬───┬───┐\n            //  │ - │ a │ b │ c │ - │ - │   ->   │ - │ - │ b │ c │ n │ - │\n            //  └───┴───┴───┴───┴───┴───┘        └───┴───┴───┴───┴───┴───┘\n            //        ↑                                    ↑\n            //      start                                start\n            //\n            let to_drop = unsafe {\n                (*buffer_mut_ptr.add(self.start + N)).write(next);\n                buffer_mut_ptr.add(self.start)\n            };\n            self.start += 1;\n            to_drop\n        };\n\n        // SAFETY: the index is valid and this is element `a` in the\n        // diagram above and has not been dropped yet.\n        unsafe { ptr::drop_in_place(to_drop.cast_init()) };\n    }",
  "mir": "fn iter::adapters::map_windows::Buffer::<T, N>::push(_1: &mut iter::adapters::map_windows::Buffer<T, N>, _2: T) -> () {\n    let mut _0: ();\n    let  _3: *mut mem::maybe_uninit::MaybeUninit<T>;\n    let mut _4: bool;\n    let mut _5: usize;\n    let mut _6: usize;\n    let mut _7: (usize, bool);\n    let mut _8: usize;\n    let mut _9: (usize, bool);\n    let mut _10: !;\n    let  _11: *mut mem::maybe_uninit::MaybeUninit<T>;\n    let mut _12: bool;\n    let mut _13: usize;\n    let  _14: *mut mem::maybe_uninit::MaybeUninit<T>;\n    let  _15: ();\n    let mut _16: *const mem::maybe_uninit::MaybeUninit<T>;\n    let mut _17: *mut mem::maybe_uninit::MaybeUninit<T>;\n    let mut _18: usize;\n    let mut _19: usize;\n    let mut _20: (usize, bool);\n    let mut _21: usize;\n    let mut _22: (usize, bool);\n    let  _23: &mut T;\n    let mut _24: &mut mem::maybe_uninit::MaybeUninit<T>;\n    let mut _25: *mut mem::maybe_uninit::MaybeUninit<T>;\n    let mut _26: usize;\n    let mut _27: (usize, bool);\n    let mut _28: usize;\n    let  _29: *mut mem::maybe_uninit::MaybeUninit<T>;\n    let  _30: &mut T;\n    let mut _31: &mut mem::maybe_uninit::MaybeUninit<T>;\n    let mut _32: *mut mem::maybe_uninit::MaybeUninit<T>;\n    let mut _33: usize;\n    let mut _34: usize;\n    let mut _35: (usize, bool);\n    let mut _36: usize;\n    let mut _37: (usize, bool);\n    let  _38: ();\n    let mut _39: *mut T;\n    let mut _40: *mut mem::maybe_uninit::MaybeUninit<T>;\n    debug self => _1;\n    debug next => _2;\n    debug buffer_mut_ptr => _3;\n    debug to_drop => _11;\n    debug to_drop => _14;\n    debug to_drop => _29;\n    bb0: {\n        _3 = iter::adapters::map_windows::Buffer::<T, N>::buffer_mut_ptr(_1) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageLive(_4);\n        StorageLive(_5);\n        StorageLive(_6);\n        _6 = ((*_1).1: usize);\n        _7 = CheckedAdd(_6, N);\n        assert(!move (_7.1: bool), \"attempt to compute `{} + {}`, which would overflow\", move _6, N) -> [success: bb2, unwind unreachable];\n    }\n    bb2: {\n        _5 = move (_7.0: usize);\n        StorageDead(_6);\n        StorageLive(_8);\n        _9 = CheckedMul(2_usize, N);\n        assert(!move (_9.1: bool), \"attempt to compute `{} * {}`, which would overflow\", 2_usize, N) -> [success: bb3, unwind unreachable];\n    }\n    bb3: {\n        _8 = move (_9.0: usize);\n        _4 = Le(move _5, move _8);\n        switchInt(move _4) -> [0: bb5, otherwise: bb4];\n    }\n    bb4: {\n        StorageDead(_8);\n        StorageDead(_5);\n        StorageDead(_4);\n        StorageLive(_11);\n        StorageLive(_12);\n        StorageLive(_13);\n        _13 = ((*_1).1: usize);\n        _12 = Eq(move _13, N);\n        switchInt(move _12) -> [0: bb15, otherwise: bb6];\n    }\n    bb5: {\n        StorageDead(_8);\n        StorageDead(_5);\n        _10 = panicking::panic(\"assertion failed: self.start + N <= 2 * N\") -> unwind unreachable;\n    }\n    bb6: {\n        StorageDead(_13);\n        StorageLive(_14);\n        StorageLive(_16);\n        StorageLive(_17);\n        StorageLive(_18);\n        StorageLive(_19);\n        _19 = ((*_1).1: usize);\n        _20 = CheckedAdd(_19, 1_usize);\n        assert(!move (_20.1: bool), \"attempt to compute `{} + {}`, which would overflow\", move _19, 1_usize) -> [success: bb7, unwind unreachable];\n    }\n    bb7: {\n        _18 = move (_20.0: usize);\n        StorageDead(_19);\n        _17 = ptr::mut_ptr::<impl *mut mem::maybe_uninit::MaybeUninit<T>>::add(_3, move _18) -> [return: bb8, unwind unreachable];\n    }\n    bb8: {\n        _16 = move _17 as *const mem::maybe_uninit::MaybeUninit<T>;\n        StorageDead(_18);\n        StorageDead(_17);\n        StorageLive(_21);\n        _22 = CheckedSub(N, 1_usize);\n        assert(!move (_22.1: bool), \"attempt to compute `{} - {}`, which would overflow\", N, 1_usize) -> [success: bb9, unwind unreachable];\n    }\n    bb9: {\n        _21 = move (_22.0: usize);\n        _15 = ptr::copy_nonoverlapping::<mem::maybe_uninit::MaybeUninit<T>>(move _16, _3, move _21) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        StorageDead(_21);\n        StorageDead(_16);\n        StorageLive(_23);\n        StorageLive(_24);\n        StorageLive(_25);\n        StorageLive(_26);\n        _27 = CheckedSub(N, 1_usize);\n        assert(!move (_27.1: bool), \"attempt to compute `{} - {}`, which would overflow\", N, 1_usize) -> [success: bb11, unwind unreachable];\n    }\n    bb11: {\n        _26 = move (_27.0: usize);\n        _25 = ptr::mut_ptr::<impl *mut mem::maybe_uninit::MaybeUninit<T>>::add(_3, move _26) -> [return: bb12, unwind unreachable];\n    }\n    bb12: {\n        StorageDead(_26);\n        _24 = &mut (*_25);\n        _23 = mem::maybe_uninit::MaybeUninit::<T>::write(move _24, _2) -> [return: bb13, unwind unreachable];\n    }\n    bb13: {\n        StorageDead(_24);\n        StorageDead(_25);\n        StorageDead(_23);\n        StorageLive(_28);\n        _28 = ((*_1).1: usize);\n        _14 = ptr::mut_ptr::<impl *mut mem::maybe_uninit::MaybeUninit<T>>::add(_3, move _28) -> [return: bb14, unwind unreachable];\n    }\n    bb14: {\n        StorageDead(_28);\n        ((*_1).1: usize) = 0_usize;\n        _11 = _14;\n        StorageDead(_14);\n        goto -> bb21;\n    }\n    bb15: {\n        StorageDead(_13);\n        StorageLive(_29);\n        StorageLive(_30);\n        StorageLive(_31);\n        StorageLive(_32);\n        StorageLive(_33);\n        StorageLive(_34);\n        _34 = ((*_1).1: usize);\n        _35 = CheckedAdd(_34, N);\n        assert(!move (_35.1: bool), \"attempt to compute `{} + {}`, which would overflow\", move _34, N) -> [success: bb16, unwind unreachable];\n    }\n    bb16: {\n        _33 = move (_35.0: usize);\n        StorageDead(_34);\n        _32 = ptr::mut_ptr::<impl *mut mem::maybe_uninit::MaybeUninit<T>>::add(_3, move _33) -> [return: bb17, unwind unreachable];\n    }\n    bb17: {\n        StorageDead(_33);\n        _31 = &mut (*_32);\n        _30 = mem::maybe_uninit::MaybeUninit::<T>::write(move _31, _2) -> [return: bb18, unwind unreachable];\n    }\n    bb18: {\n        StorageDead(_31);\n        StorageDead(_32);\n        StorageDead(_30);\n        StorageLive(_36);\n        _36 = ((*_1).1: usize);\n        _29 = ptr::mut_ptr::<impl *mut mem::maybe_uninit::MaybeUninit<T>>::add(_3, move _36) -> [return: bb19, unwind unreachable];\n    }\n    bb19: {\n        StorageDead(_36);\n        _37 = CheckedAdd(((*_1).1: usize), 1_usize);\n        assert(!move (_37.1: bool), \"attempt to compute `{} + {}`, which would overflow\", ((*_1).1: usize), 1_usize) -> [success: bb20, unwind unreachable];\n    }\n    bb20: {\n        ((*_1).1: usize) = move (_37.0: usize);\n        _11 = _29;\n        StorageDead(_29);\n        goto -> bb21;\n    }\n    bb21: {\n        StorageDead(_12);\n        StorageLive(_39);\n        StorageLive(_40);\n        _40 = _11;\n        _39 = ptr::mut_ptr::<impl *mut mem::maybe_uninit::MaybeUninit<T>>::cast_init(move _40) -> [return: bb22, unwind unreachable];\n    }\n    bb22: {\n        StorageDead(_40);\n        _38 = ptr::drop_in_place::<T>(move _39) -> [return: bb23, unwind unreachable];\n    }\n    bb23: {\n        StorageDead(_39);\n        StorageDead(_11);\n        return;\n    }\n}\n",
  "doc": " Pushes a new item `next` to the back, and pops the front-most one.\n\n All the elements will be shifted to the front end when pushing reaches\n the back end.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}