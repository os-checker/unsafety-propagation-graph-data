{
  "name": "core_arch::x86::avx::_mm256_stream_pd",
  "safe": false,
  "callees": {},
  "adts": {
    "core_arch::x86::__m256d": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "core::core_arch::x86::avx::_mm256_stream_pd"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/../../stdarch/crates/core_arch/src/x86/avx.rs:1872:1: 1880:2",
  "src": "pub unsafe fn _mm256_stream_pd(mem_addr: *mut f64, a: __m256d) {\n    // see #1541, we should use inline asm to be sure, because LangRef isn't clear enough\n    crate::arch::asm!(\n        vps!(\"vmovntpd\", \",{a}\"),\n        p = in(reg) mem_addr,\n        a = in(ymm_reg) a,\n        options(nostack, preserves_flags),\n    );\n}",
  "mir": "fn core_arch::x86::avx::_mm256_stream_pd(_1: *mut f64, _2: core_arch::x86::__m256d) -> () {\n    let mut _0: ();\n    debug mem_addr => _1;\n    debug a => _2;\n    bb0: {\n        InlineAsm -> [goto: bb1, unwind unreachable];\n    }\n    bb1: {\n        return;\n    }\n}\n",
  "doc": " Moves double-precision values from a 256-bit vector of `[4 x double]`\n to a 32-byte aligned memory location. To minimize caching, the data is\n flagged as non-temporal (unlikely to be used again soon).\n\n [Intel's documentation](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm256_stream_pd)\n\n # Safety of non-temporal stores\n\n After using this intrinsic, but before any other access to the memory that this intrinsic\n mutates, a call to [`_mm_sfence`] must be performed by the thread that used the intrinsic. In\n particular, functions that call this intrinsic should generally call `_mm_sfence` before they\n return.\n\n See [`_mm_sfence`] for details.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}