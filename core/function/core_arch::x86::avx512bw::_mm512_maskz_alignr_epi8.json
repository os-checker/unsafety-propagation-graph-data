{
  "name": "core_arch::x86::avx512bw::_mm512_maskz_alignr_epi8",
  "safe": false,
  "callees": {
    "core_arch::x86::avx512bw::_mm512_alignr_epi8": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst.\n Unlike [`_mm_alignr_epi8`], [`_mm256_alignr_epi8`] functions, where the entire input vectors are concatenated to the temporary result,\n this concatenation happens in 4 steps, where each step builds 32-byte temporary result.\n\n [Intel's documentation](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm512_alignr_epi8&expand=263)\n",
      "adt": {
        "core_arch::x86::__m512i": "Constructor"
      }
    },
    "core_arch::x86::__m512i::as_i8x64": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "core_arch::simd::i8x64": "Constructor"
      }
    },
    "intrinsics::simd::simd_select_bitmask": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Selects elements from a bitmask.\n\n `M` must be an unsigned integer or array of `u8`, matching `simd_bitmask`.\n\n `T` must be a vector.\n\n For each element, if the bit in `mask` is `1`, select the element from\n `if_true`.  If the corresponding bit in `mask` is `0`, select the element from\n `if_false`.\n The remaining bits of the mask are ignored.\n\n The bitmask bit order matches `simd_bitmask`.\n",
      "adt": {}
    }
  },
  "adts": {
    "core_arch::x86::__m512i": [
      "Plain"
    ],
    "core_arch::simd::i8x64": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "core::core_arch::x86::avx512bw::_mm512_maskz_alignr_epi8"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/../../stdarch/crates/core_arch/src/x86/avx512bw.rs:11504:1: 11510:2",
  "src": "pub fn _mm512_maskz_alignr_epi8<const IMM8: i32>(k: __mmask64, a: __m512i, b: __m512i) -> __m512i {\n    unsafe {\n        static_assert_uimm_bits!(IMM8, 8);\n        let r = _mm512_alignr_epi8::<IMM8>(a, b);\n        transmute(simd_select_bitmask(k, r.as_i8x64(), i8x64::ZERO))\n    }\n}",
  "mir": "fn core_arch::x86::avx512bw::_mm512_maskz_alignr_epi8(_1: u64, _2: core_arch::x86::__m512i, _3: core_arch::x86::__m512i) -> core_arch::x86::__m512i {\n    let mut _0: core_arch::x86::__m512i;\n    let  _4: core_arch::x86::__m512i;\n    let mut _5: core_arch::simd::i8x64;\n    let mut _6: core_arch::simd::i8x64;\n    debug k => _1;\n    debug a => _2;\n    debug b => _3;\n    debug r => _4;\n    bb0: {\n        _4 = core_arch::x86::avx512bw::_mm512_alignr_epi8::<IMM8>(_2, _3) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageLive(_5);\n        StorageLive(_6);\n        _6 = core_arch::x86::__m512i::as_i8x64(_4) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        _5 = intrinsics::simd::simd_select_bitmask::<u64, core_arch::simd::i8x64>(_1, move _6, core_arch::simd::i8x64::ZERO) -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        StorageDead(_6);\n        _0 = move _5 as core_arch::x86::__m512i;\n        StorageDead(_5);\n        return;\n    }\n}\n",
  "doc": " Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\n\n [Intel's documentation](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm512_maskz_alignr_epi8&expand=265)\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}