{
  "name": "core_arch::x86::avx512f::_mm_mask_cmp_epi64_mask",
  "safe": false,
  "callees": {
    "core_arch::x86::__m128i::as_i64x2": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "core_arch::simd::i64x2": "Constructor"
      }
    },
    "core_arch::simd::i64x2::splat": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "core_arch::simd::i64x2": "Constructor"
      }
    },
    "intrinsics::simd::simd_select_bitmask": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Selects elements from a bitmask.\n\n `M` must be an unsigned integer or array of `u8`, matching `simd_bitmask`.\n\n `T` must be a vector.\n\n For each element, if the bit in `mask` is `1`, select the element from\n `if_true`.  If the corresponding bit in `mask` is `0`, select the element from\n `if_false`.\n The remaining bits of the mask are ignored.\n\n The bitmask bit order matches `simd_bitmask`.\n",
      "adt": {}
    },
    "intrinsics::simd::simd_gt": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Tests if `x` is greater than `y`, elementwise.\n\n `T` must be a vector of integers or floats.\n\n `U` must be a vector of integers with the same number of elements and element size as `T`.\n\n Returns `0` for false and `!0` for true.\n",
      "adt": {}
    },
    "intrinsics::simd::simd_ge": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Tests if `x` is greater than or equal to `y`, elementwise.\n\n `T` must be a vector of integers or floats.\n\n `U` must be a vector of integers with the same number of elements and element size as `T`.\n\n Returns `0` for false and `!0` for true.\n",
      "adt": {}
    },
    "intrinsics::simd::simd_ne": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Tests elementwise inequality equality of two vectors.\n\n `T` must be a vector of integers or floats.\n\n `U` must be a vector of integers with the same number of elements and element size as `T`.\n\n Returns `0` for false and `!0` for true.\n",
      "adt": {}
    },
    "intrinsics::simd::simd_le": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Tests if `x` is less than or equal to `y`, elementwise.\n\n `T` must be a vector of integers or floats.\n\n `U` must be a vector of integers with the same number of elements and element size as `T`.\n\n Returns `0` for false and `!0` for true.\n",
      "adt": {}
    },
    "intrinsics::simd::simd_lt": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Tests if `x` is less than `y`, elementwise.\n\n `T` must be a vector of integers or floats.\n\n `U` must be a vector of integers with the same number of elements and element size as `T`.\n\n Returns `0` for false and `!0` for true.\n",
      "adt": {}
    },
    "intrinsics::simd::simd_eq": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Tests elementwise equality of two vectors.\n\n `T` must be a vector of integers or floats.\n\n `U` must be a vector of integers with the same number of elements and element size as `T`.\n\n Returns `0` for false and `!0` for true.\n",
      "adt": {}
    },
    "intrinsics::simd::simd_and": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " \"And\"s vectors elementwise.\n\n `T` must be a vector of integers.\n",
      "adt": {}
    },
    "intrinsics::simd::simd_bitmask": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Truncates an integer vector to a bitmask.\n\n `T` must be an integer vector.\n\n `U` must be either the smallest unsigned integer with at least as many bits as the length\n of `T`, or the smallest array of `u8` with at least as many bits as the length of `T`.\n\n Each element is truncated to a single bit and packed into the result.\n\n No matter whether the output is an array or an unsigned integer, it is treated as a single\n contiguous list of bits. The bitmask is always packed on the least-significant side of the\n output, and padded with 0s in the most-significant bits. The order of the bits depends on\n endianness:\n\n * On little endian, the least significant bit corresponds to the first vector element.\n * On big endian, the least significant bit corresponds to the last vector element.\n\n For example, `[!0, 0, !0, !0]` packs to\n - `0b1101u8` or `[0b1101]` on little endian, and\n - `0b1011u8` or `[0b1011]` on big endian.\n\n To consider a larger example,\n `[!0, 0, 0, 0, 0, 0, 0, 0, !0, !0, 0, 0, 0, 0, !0, 0]` packs to\n - `0b0100001100000001u16` or `[0b00000001, 0b01000011]` on little endian, and\n - `0b1000000011000010u16` or `[0b10000000, 0b11000010]` on big endian.\n\n And finally, a non-power-of-2 example with multiple bytes:\n `[!0, !0, 0, !0, 0, 0, !0, 0, !0, 0]` packs to\n - `0b0101001011u16` or `[0b01001011, 0b01]` on little endian, and\n - `0b1101001010u16` or `[0b11, 0b01001010]` on big endian.\n\n # Safety\n `x` must contain only `0` and `!0`.\n",
      "adt": {}
    }
  },
  "adts": {
    "core_arch::x86::__m128i": [
      "Plain"
    ],
    "core_arch::simd::i64x2": [
      "Plain"
    ]
  },
  "path": 9516,
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/../../stdarch/crates/core_arch/src/x86/avx512f.rs:33143:1: 33165:2",
  "src": "pub fn _mm_mask_cmp_epi64_mask<const IMM3: _MM_CMPINT_ENUM>(\n    k1: __mmask8,\n    a: __m128i,\n    b: __m128i,\n) -> __mmask8 {\n    unsafe {\n        static_assert_uimm_bits!(IMM3, 3);\n        let a = a.as_i64x2();\n        let b = b.as_i64x2();\n        let k1 = simd_select_bitmask(k1, i64x2::splat(-1), i64x2::ZERO);\n        let r = match IMM3 {\n            0 => simd_and(k1, simd_eq(a, b)),\n            1 => simd_and(k1, simd_lt(a, b)),\n            2 => simd_and(k1, simd_le(a, b)),\n            3 => i64x2::ZERO,\n            4 => simd_and(k1, simd_ne(a, b)),\n            5 => simd_and(k1, simd_ge(a, b)),\n            6 => simd_and(k1, simd_gt(a, b)),\n            _ => k1,\n        };\n        simd_bitmask(r)\n    }\n}",
  "mir": "fn core_arch::x86::avx512f::_mm_mask_cmp_epi64_mask(_1: u8, _2: core_arch::x86::__m128i, _3: core_arch::x86::__m128i) -> u8 {\n    let mut _0: u8;\n    let  _4: core_arch::simd::i64x2;\n    let  _5: core_arch::simd::i64x2;\n    let  _6: core_arch::simd::i64x2;\n    let mut _7: core_arch::simd::i64x2;\n    let  _8: core_arch::simd::i64x2;\n    let mut _9: core_arch::simd::i64x2;\n    let mut _10: core_arch::simd::i64x2;\n    let mut _11: core_arch::simd::i64x2;\n    let mut _12: core_arch::simd::i64x2;\n    let mut _13: core_arch::simd::i64x2;\n    let mut _14: core_arch::simd::i64x2;\n    let mut _15: core_arch::simd::i64x2;\n    debug k1 => _1;\n    debug a => _2;\n    debug b => _3;\n    debug a => _4;\n    debug b => _5;\n    debug k1 => _6;\n    debug r => _8;\n    bb0: {\n        _4 = core_arch::x86::__m128i::as_i64x2(_2) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        _5 = core_arch::x86::__m128i::as_i64x2(_3) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageLive(_7);\n        _7 = core_arch::simd::i64x2::splat(-1_i64) -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        _6 = intrinsics::simd::simd_select_bitmask::<u8, core_arch::simd::i64x2>(_1, move _7, core_arch::simd::i64x2::ZERO) -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        StorageDead(_7);\n        StorageLive(_8);\n        switchInt(IMM3) -> [0: bb12, 1: bb11, 2: bb10, 3: bb9, 4: bb8, 5: bb7, 6: bb6, otherwise: bb5];\n    }\n    bb5: {\n        _8 = _6;\n        goto -> bb25;\n    }\n    bb6: {\n        StorageLive(_14);\n        _14 = intrinsics::simd::simd_gt::<core_arch::simd::i64x2, core_arch::simd::i64x2>(_4, _5) -> [return: bb23, unwind unreachable];\n    }\n    bb7: {\n        StorageLive(_13);\n        _13 = intrinsics::simd::simd_ge::<core_arch::simd::i64x2, core_arch::simd::i64x2>(_4, _5) -> [return: bb21, unwind unreachable];\n    }\n    bb8: {\n        StorageLive(_12);\n        _12 = intrinsics::simd::simd_ne::<core_arch::simd::i64x2, core_arch::simd::i64x2>(_4, _5) -> [return: bb19, unwind unreachable];\n    }\n    bb9: {\n        _8 = core_arch::simd::i64x2::ZERO;\n        goto -> bb25;\n    }\n    bb10: {\n        StorageLive(_11);\n        _11 = intrinsics::simd::simd_le::<core_arch::simd::i64x2, core_arch::simd::i64x2>(_4, _5) -> [return: bb17, unwind unreachable];\n    }\n    bb11: {\n        StorageLive(_10);\n        _10 = intrinsics::simd::simd_lt::<core_arch::simd::i64x2, core_arch::simd::i64x2>(_4, _5) -> [return: bb15, unwind unreachable];\n    }\n    bb12: {\n        StorageLive(_9);\n        _9 = intrinsics::simd::simd_eq::<core_arch::simd::i64x2, core_arch::simd::i64x2>(_4, _5) -> [return: bb13, unwind unreachable];\n    }\n    bb13: {\n        _8 = intrinsics::simd::simd_and::<core_arch::simd::i64x2>(_6, move _9) -> [return: bb14, unwind unreachable];\n    }\n    bb14: {\n        StorageDead(_9);\n        goto -> bb25;\n    }\n    bb15: {\n        _8 = intrinsics::simd::simd_and::<core_arch::simd::i64x2>(_6, move _10) -> [return: bb16, unwind unreachable];\n    }\n    bb16: {\n        StorageDead(_10);\n        goto -> bb25;\n    }\n    bb17: {\n        _8 = intrinsics::simd::simd_and::<core_arch::simd::i64x2>(_6, move _11) -> [return: bb18, unwind unreachable];\n    }\n    bb18: {\n        StorageDead(_11);\n        goto -> bb25;\n    }\n    bb19: {\n        _8 = intrinsics::simd::simd_and::<core_arch::simd::i64x2>(_6, move _12) -> [return: bb20, unwind unreachable];\n    }\n    bb20: {\n        StorageDead(_12);\n        goto -> bb25;\n    }\n    bb21: {\n        _8 = intrinsics::simd::simd_and::<core_arch::simd::i64x2>(_6, move _13) -> [return: bb22, unwind unreachable];\n    }\n    bb22: {\n        StorageDead(_13);\n        goto -> bb25;\n    }\n    bb23: {\n        _8 = intrinsics::simd::simd_and::<core_arch::simd::i64x2>(_6, move _14) -> [return: bb24, unwind unreachable];\n    }\n    bb24: {\n        StorageDead(_14);\n        goto -> bb25;\n    }\n    bb25: {\n        StorageLive(_15);\n        _15 = _8;\n        _0 = intrinsics::simd::simd_bitmask::<core_arch::simd::i64x2, u8>(move _15) -> [return: bb26, unwind unreachable];\n    }\n    bb26: {\n        StorageDead(_15);\n        StorageDead(_8);\n        return;\n    }\n}\n",
  "doc": " Compare packed signed 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).\n\n [Intel's documentation](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm_mask_cmp_epi64_mask&expand=700)\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}