{
  "name": "hash::Hasher::write_str",
  "safe": true,
  "callees": {
    "str::<impl str>::as_bytes": {
      "safe": true,
      "tags": {
        "tags": [
          {
            "tag": {
              "typ": null,
              "name": "unused_attributes"
            },
            "args": []
          }
        ],
        "spec": {},
        "docs": [
          "* unused_attributes\n"
        ]
      },
      "doc": " Converts a string slice to a byte slice. To convert the byte slice back\n into a string slice, use the [`from_utf8`] function.\n\n # Examples\n\n ```\n let bytes = \"bors\".as_bytes();\n assert_eq!(b\"bors\", bytes);\n ```\n",
      "adt": {}
    },
    "hash::Hasher::write": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Writes some data into this `Hasher`.\n\n # Examples\n\n ```\n use std::hash::{DefaultHasher, Hasher};\n\n let mut hasher = DefaultHasher::new();\n let data = [0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef];\n\n hasher.write(&data);\n\n println!(\"Hash is {:x}!\", hasher.finish());\n ```\n\n # Note to Implementers\n\n You generally should not do length-prefixing as part of implementing\n this method.  It's up to the [`Hash`] implementation to call\n [`Hasher::write_length_prefix`] before sequences that need it.\n",
      "adt": {}
    },
    "hash::Hasher::write_u8": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Writes a single `u8` into this hasher.\n",
      "adt": {}
    }
  },
  "adts": {},
  "path": "hash::Hasher::write_str",
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/hash/mod.rs:551:5: 554:6",
  "src": "fn write_str(&mut self, s: &str) {\n        self.write(s.as_bytes());\n        self.write_u8(0xff);\n    }",
  "mir": "fn hash::Hasher::write_str(_1: &mut Self, _2: &str) -> () {\n    let mut _0: ();\n    let  _3: ();\n    let  _4: &[u8];\n    let  _5: ();\n    debug self => _1;\n    debug s => _2;\n    bb0: {\n        _4 = str::<impl str>::as_bytes(_2) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        _3 = <Self as hash::Hasher>::write(_1, _4) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        _5 = <Self as hash::Hasher>::write_u8(_1, u8::MAX) -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        return;\n    }\n}\n",
  "doc": " Writes a single `str` into this hasher.\n\n If you're implementing [`Hash`], you generally do not need to call this,\n as the `impl Hash for str` does, so you should prefer that instead.\n\n This includes the domain separator for prefix-freedom, so you should\n **not** call `Self::write_length_prefix` before calling this.\n\n # Note to Implementers\n\n There are at least two reasonable default ways to implement this.\n Which one will be the default is not yet decided, so for now\n you probably want to override it specifically.\n\n ## The general answer\n\n It's always correct to implement this with a length prefix:\n\n ```\n # #![feature(hasher_prefixfree_extras)]\n # struct Foo;\n # impl std::hash::Hasher for Foo {\n # fn finish(&self) -> u64 { unimplemented!() }\n # fn write(&mut self, _bytes: &[u8]) { unimplemented!() }\n fn write_str(&mut self, s: &str) {\n     self.write_length_prefix(s.len());\n     self.write(s.as_bytes());\n }\n # }\n ```\n\n And, if your `Hasher` works in `usize` chunks, this is likely a very\n efficient way to do it, as anything more complicated may well end up\n slower than just running the round with the length.\n\n ## If your `Hasher` works byte-wise\n\n One nice thing about `str` being UTF-8 is that the `b'\\xFF'` byte\n never happens.  That means that you can append that to the byte stream\n being hashed and maintain prefix-freedom:\n\n ```\n # #![feature(hasher_prefixfree_extras)]\n # struct Foo;\n # impl std::hash::Hasher for Foo {\n # fn finish(&self) -> u64 { unimplemented!() }\n # fn write(&mut self, _bytes: &[u8]) { unimplemented!() }\n fn write_str(&mut self, s: &str) {\n     self.write(s.as_bytes());\n     self.write_u8(0xff);\n }\n # }\n ```\n\n This does require that your implementation not add extra padding, and\n thus generally requires that you maintain a buffer, running a round\n only once that buffer is full (or `finish` is called).\n\n That's because if `write` pads data out to a fixed chunk size, it's\n likely that it does it in such a way that `\"a\"` and `\"a\\x00\"` would\n end up hashing the same sequence of things, introducing conflicts.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}