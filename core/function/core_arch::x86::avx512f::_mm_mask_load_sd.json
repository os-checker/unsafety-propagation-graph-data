{
  "name": "core_arch::x86::avx512f::_mm_mask_load_sd",
  "safe": false,
  "callees": {},
  "adts": {
    "core_arch::x86::__m128d": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "core::core_arch::x86::avx512f::_mm_mask_load_sd"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/../../stdarch/crates/core_arch/src/x86/avx512f.rs:35450:1: 35460:2",
  "src": "pub unsafe fn _mm_mask_load_sd(src: __m128d, k: __mmask8, mem_addr: *const f64) -> __m128d {\n    let mut dst: __m128d = src;\n    asm!(\n        vpl!(\"vmovsd {dst}{{{k}}}\"),\n        p = in(reg) mem_addr,\n        k = in(kreg) k,\n        dst = inout(xmm_reg) dst,\n        options(pure, readonly, nostack, preserves_flags),\n    );\n    dst\n}",
  "mir": "fn core_arch::x86::avx512f::_mm_mask_load_sd(_1: core_arch::x86::__m128d, _2: u8, _3: *const f64) -> core_arch::x86::__m128d {\n    let mut _0: core_arch::x86::__m128d;\n    let mut _4: core_arch::x86::__m128d;\n    debug src => _1;\n    debug k => _2;\n    debug mem_addr => _3;\n    debug dst => _4;\n    bb0: {\n        StorageLive(_4);\n        _4 = _1;\n        InlineAsm -> [goto: bb1, unwind unreachable];\n    }\n    bb1: {\n        _0 = _4;\n        StorageDead(_4);\n        return;\n    }\n}\n",
  "doc": " Load a double-precision (64-bit) floating-point element from memory into the lower element of dst\n using writemask k (the element is copied from src when mask bit 0 is not set), and set the upper\n element of dst to zero. mem_addr must be aligned on a 16-byte boundary or a general-protection\n exception may be generated.\n\n [Intel's documentation](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_mask_load_sd)\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}