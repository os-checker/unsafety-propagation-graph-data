{
  "name": "slice::sort::unstable::quicksort::partition_lomuto_branchless_cyclic",
  "safe": true,
  "callees": {
    "slice::<impl [T]>::as_mut_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns an unsafe mutable pointer to the slice's buffer.\n\n The caller must ensure that the slice outlives the pointer this\n function returns, or else it will end up dangling.\n\n Modifying the container referenced by this slice may cause its buffer\n to be reallocated, which would also make any pointers to it invalid.\n\n # Examples\n\n ```\n let x = &mut [1, 2, 4];\n let x_ptr = x.as_mut_ptr();\n\n unsafe {\n     for i in 0..x.len() {\n         *x_ptr.add(i) += 2;\n     }\n }\n assert_eq!(x, &[3, 4, 6]);\n ```\n",
      "adt": {}
    },
    "ptr::read": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Reads the value from `src` without moving it. This leaves the\n memory in `src` unchanged.\n\n # Safety\n\n Behavior is undefined if any of the following conditions are violated:\n\n * `src` must be [valid] for reads.\n\n * `src` must be properly aligned. Use [`read_unaligned`] if this is not the\n   case.\n\n * `src` must point to a properly initialized value of type `T`.\n\n Note that even if `T` has size `0`, the pointer must be properly aligned.\n\n # Examples\n\n Basic usage:\n\n ```\n let x = 12;\n let y = &x as *const i32;\n\n unsafe {\n     assert_eq!(std::ptr::read(y), 12);\n }\n ```\n\n Manually implement [`mem::swap`]:\n\n ```\n use std::ptr;\n\n fn swap<T>(a: &mut T, b: &mut T) {\n     unsafe {\n         // Create a bitwise copy of the value at `a` in `tmp`.\n         let tmp = ptr::read(a);\n\n         // Exiting at this point (either by explicitly returning or by\n         // calling a function which panics) would cause the value in `tmp` to\n         // be dropped while the same value is still referenced by `a`. This\n         // could trigger undefined behavior if `T` is not `Copy`.\n\n         // Create a bitwise copy of the value at `b` in `a`.\n         // This is safe because mutable references cannot alias.\n         ptr::copy_nonoverlapping(b, a, 1);\n\n         // As above, exiting here could trigger undefined behavior because\n         // the same value is referenced by `a` and `b`.\n\n         // Move `tmp` into `b`.\n         ptr::write(b, tmp);\n\n         // `tmp` has been moved (`write` takes ownership of its second argument),\n         // so nothing is dropped implicitly here.\n     }\n }\n\n let mut foo = \"foo\".to_owned();\n let mut bar = \"bar\".to_owned();\n\n swap(&mut foo, &mut bar);\n\n assert_eq!(foo, \"bar\");\n assert_eq!(bar, \"foo\");\n ```\n\n ## Ownership of the Returned Value\n\n `read` creates a bitwise copy of `T`, regardless of whether `T` is [`Copy`].\n If `T` is not [`Copy`], using both the returned value and the value at\n `*src` can violate memory safety. Note that assigning to `*src` counts as a\n use because it will attempt to drop the value at `*src`.\n\n [`write()`] can be used to overwrite data without causing it to be dropped.\n\n ```\n use std::ptr;\n\n let mut s = String::from(\"foo\");\n unsafe {\n     // `s2` now points to the same underlying memory as `s`.\n     let mut s2: String = ptr::read(&s);\n\n     assert_eq!(s2, \"foo\");\n\n     // Assigning to `s2` causes its original value to be dropped. Beyond\n     // this point, `s` must no longer be used, as the underlying memory has\n     // been freed.\n     s2 = String::default();\n     assert_eq!(s2, \"\");\n\n     // Assigning to `s` would cause the old value to be dropped again,\n     // resulting in undefined behavior.\n     // s = String::from(\"bar\"); // ERROR\n\n     // `ptr::write` can be used to overwrite a value without dropping it.\n     ptr::write(&mut s, String::from(\"bar\"));\n }\n\n assert_eq!(s, \"bar\");\n ```\n\n [valid]: self#safety\n",
      "adt": {}
    },
    "mem::manually_drop::ManuallyDrop::<T>::new": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Wrap a value to be manually dropped.\n\n # Examples\n\n ```rust\n use std::mem::ManuallyDrop;\n let mut x = ManuallyDrop::new(String::from(\"Hello World!\"));\n x.truncate(5); // You can still safely operate on the value\n assert_eq!(*x, \"Hello\");\n // But `Drop` will not be run here\n # // FIXME(https://github.com/rust-lang/miri/issues/3670):\n # // use -Zmiri-disable-leak-check instead of unleaking in tests meant to leak.\n # let _ = ManuallyDrop::into_inner(x);\n ```\n",
      "adt": {
        "mem::manually_drop::ManuallyDrop": "Constructor"
      }
    },
    "ptr::mut_ptr::<impl *mut T>::add": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "\n # Examples\n\n ```\n let mut s: String = \"123\".to_string();\n let ptr: *mut u8 = s.as_mut_ptr();\n\n unsafe {\n     assert_eq!('2', *ptr.add(1) as char);\n     assert_eq!('3', *ptr.add(2) as char);\n }\n ```\n",
      "adt": {}
    },
    "ops::deref::DerefMut::deref_mut": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Mutably dereferences the value.\n",
      "adt": {}
    },
    "ops::function::FnMut::call_mut": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Performs the call operation.\n",
      "adt": {}
    },
    "mem::forget": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Takes ownership and \"forgets\" about the value **without running its destructor**.\n\n Any resources the value manages, such as heap memory or a file handle, will linger\n forever in an unreachable state. However, it does not guarantee that pointers\n to this memory will remain valid.\n\n * If you want to leak memory, see [`Box::leak`].\n * If you want to obtain a raw pointer to the memory, see [`Box::into_raw`].\n * If you want to dispose of a value properly, running its destructor, see\n   [`mem::drop`].\n\n # Safety\n\n `forget` is not marked as `unsafe`, because Rust's safety guarantees\n do not include a guarantee that destructors will always run. For example,\n a program can create a reference cycle using [`Rc`][rc], or call\n [`process::exit`][exit] to exit without running destructors. Thus, allowing\n `mem::forget` from safe code does not fundamentally change Rust's safety\n guarantees.\n\n That said, leaking resources such as memory or I/O objects is usually undesirable.\n The need comes up in some specialized use cases for FFI or unsafe code, but even\n then, [`ManuallyDrop`] is typically preferred.\n\n Because forgetting a value is allowed, any `unsafe` code you write must\n allow for this possibility. You cannot return a value and expect that the\n caller will necessarily run the value's destructor.\n\n [rc]: ../../std/rc/struct.Rc.html\n [exit]: ../../std/process/fn.exit.html\n\n # Examples\n\n The canonical safe use of `mem::forget` is to circumvent a value's destructor\n implemented by the `Drop` trait. For example, this will leak a `File`, i.e. reclaim\n the space taken by the variable but never close the underlying system resource:\n\n ```no_run\n use std::mem;\n use std::fs::File;\n\n let file = File::open(\"foo.txt\").unwrap();\n mem::forget(file);\n ```\n\n This is useful when the ownership of the underlying resource was previously\n transferred to code outside of Rust, for example by transmitting the raw\n file descriptor to C code.\n\n # Relationship with `ManuallyDrop`\n\n While `mem::forget` can also be used to transfer *memory* ownership, doing so is error-prone.\n [`ManuallyDrop`] should be used instead. Consider, for example, this code:\n\n ```\n use std::mem;\n\n let mut v = vec![65, 122];\n // Build a `String` using the contents of `v`\n let s = unsafe { String::from_raw_parts(v.as_mut_ptr(), v.len(), v.capacity()) };\n // leak `v` because its memory is now managed by `s`\n mem::forget(v);  // ERROR - v is invalid and must not be passed to a function\n assert_eq!(s, \"Az\");\n // `s` is implicitly dropped and its memory deallocated.\n ```\n\n There are two issues with the above example:\n\n * If more code were added between the construction of `String` and the invocation of\n   `mem::forget()`, a panic within it would cause a double free because the same memory\n   is handled by both `v` and `s`.\n * After calling `v.as_mut_ptr()` and transmitting the ownership of the data to `s`,\n   the `v` value is invalid. Even when a value is just moved to `mem::forget` (which won't\n   inspect it), some types have strict requirements on their values that\n   make them invalid when dangling or no longer owned. Using invalid values in any\n   way, including passing them to or returning them from functions, constitutes\n   undefined behavior and may break the assumptions made by the compiler.\n\n Switching to `ManuallyDrop` avoids both issues:\n\n ```\n use std::mem::ManuallyDrop;\n\n let v = vec![65, 122];\n // Before we disassemble `v` into its raw parts, make sure it\n // does not get dropped!\n let mut v = ManuallyDrop::new(v);\n // Now disassemble `v`. These operations cannot panic, so there cannot be a leak.\n let (ptr, len, cap) = (v.as_mut_ptr(), v.len(), v.capacity());\n // Finally, build a `String`.\n let s = unsafe { String::from_raw_parts(ptr, len, cap) };\n assert_eq!(s, \"Az\");\n // `s` is implicitly dropped and its memory deallocated.\n ```\n\n `ManuallyDrop` robustly prevents double-free because we disable `v`'s destructor\n before doing anything else. `mem::forget()` doesn't allow this because it consumes its\n argument, forcing us to call it only after extracting anything we need from `v`. Even\n if a panic were introduced between construction of `ManuallyDrop` and building the\n string (which cannot happen in the code as shown), it would result in a leak and not a\n double free. In other words, `ManuallyDrop` errs on the side of leaking instead of\n erring on the side of (double-)dropping.\n\n Also, `ManuallyDrop` prevents us from having to \"touch\" `v` after transferring the\n ownership to `s` â€” the final step of interacting with `v` to dispose of it without\n running its destructor is entirely avoided.\n\n [`Box`]: ../../std/boxed/struct.Box.html\n [`Box::leak`]: ../../std/boxed/struct.Box.html#method.leak\n [`Box::into_raw`]: ../../std/boxed/struct.Box.html#method.into_raw\n [`mem::drop`]: drop\n [ub]: ../../reference/behavior-considered-undefined.html\n",
      "adt": {}
    }
  },
  "adts": {
    "mem::manually_drop::ManuallyDrop": [
      "Plain",
      "MutRef"
    ],
    "slice::sort::unstable::quicksort::GapGuardRaw": [
      "Plain"
    ],
    "slice::sort::unstable::quicksort::PartitionState": [
      "Plain",
      "Unknown([Field(0, Ty { id: 1181, kind: RigidTy(RawPtr(Ty { id: 95, kind: Param(ParamTy { index: 0, name: \"T\" }) }, Mut)) })])",
      "MutRef",
      "Unknown([Field(2, Ty { id: 12346, kind: RigidTy(Adt(AdtDef(DefId { id: 28379, name: \"slice::sort::unstable::quicksort::GapGuardRaw\" }), GenericArgs([Type(Ty { id: 95, kind: Param(ParamTy { index: 0, name: \"T\" }) })]))) }), Field(1, Ty { id: 1181, kind: RigidTy(RawPtr(Ty { id: 95, kind: Param(ParamTy { index: 0, name: \"T\" }) }, Mut)) })])",
      "Unknown([Field(2, Ty { id: 12346, kind: RigidTy(Adt(AdtDef(DefId { id: 28379, name: \"slice::sort::unstable::quicksort::GapGuardRaw\" }), GenericArgs([Type(Ty { id: 95, kind: Param(ParamTy { index: 0, name: \"T\" }) })]))) })])",
      "Unknown([Field(1, Ty { id: 47, kind: RigidTy(Uint(Usize)) })])"
    ]
  },
  "path": {
    "type": "Local",
    "path": "core::slice::sort::unstable::quicksort::partition_lomuto_branchless_cyclic"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:249:1: 338:2",
  "src": "fn partition_lomuto_branchless_cyclic<T, F>(v: &mut [T], pivot: &T, is_less: &mut F) -> usize\nwhere\n    F: FnMut(&T, &T) -> bool,\n{\n    // Novel partition implementation by Lukas Bergdoll and Orson Peters. Branchless Lomuto\n    // partition paired with a cyclic permutation.\n    // https://github.com/Voultapher/sort-research-rs/blob/main/writeup/lomcyc_partition/text.md\n\n    let len = v.len();\n    let v_base = v.as_mut_ptr();\n\n    if len == 0 {\n        return 0;\n    }\n\n    // SAFETY: We checked that `len` is more than zero, which means that reading `v_base` is safe to\n    // do. From there we have a bounded loop where `v_base.add(i)` is guaranteed in-bounds. `v` and\n    // `pivot` can't alias because of type system rules. The drop-guard `gap` ensures that should\n    // `is_less` panic we always overwrite the duplicate in the input. `gap.pos` stores the previous\n    // value of `right` and starts at `v_base` and so it too is in-bounds. Given `UNROLL_LEN == 2`\n    // after the main loop we either have A) the last element in `v` that has not yet been processed\n    // because `len % 2 != 0`, or B) all elements have been processed except the gap value that was\n    // saved at the beginning with `ptr::read(v_base)`. In the case A) the loop will iterate twice,\n    // first performing loop_body to take care of the last element that didn't fit into the unroll.\n    // After that the behavior is the same as for B) where we use the saved value as `right` to\n    // overwrite the duplicate. If this very last call to `is_less` panics the saved value will be\n    // copied back including all possible changes via interior mutability. If `is_less` does not\n    // panic and the code continues we overwrite the duplicate and do `right = right.add(1)`, this\n    // is safe to do with `&mut *gap.value` because `T` is the same as `[T; 1]` and generating a\n    // pointer one past the allocation is safe.\n    unsafe {\n        let mut loop_body = |state: &mut PartitionState<T>| {\n            let right_is_lt = is_less(&*state.right, pivot);\n            let left = v_base.add(state.num_lt);\n\n            ptr::copy(left, state.gap.pos, 1);\n            ptr::copy_nonoverlapping(state.right, left, 1);\n\n            state.gap.pos = state.right;\n            state.num_lt += right_is_lt as usize;\n\n            state.right = state.right.add(1);\n        };\n\n        // Ideally we could just use GapGuard in PartitionState, but the reference that is\n        // materialized with `&mut state` when calling `loop_body` would create a mutable reference\n        // to the parent struct that contains the gap value, invalidating the reference pointer\n        // created from a reference to the gap value in the cleanup loop. This is only an issue\n        // under Stacked Borrows, Tree Borrows accepts the intuitive code using GapGuard as valid.\n        let mut gap_value = ManuallyDrop::new(ptr::read(v_base));\n\n        let mut state = PartitionState {\n            num_lt: 0,\n            right: v_base.add(1),\n\n            gap: GapGuardRaw { pos: v_base, value: &mut *gap_value },\n        };\n\n        // Manual unrolling that works well on x86, Arm and with opt-level=s without murdering\n        // compile-times. Leaving this to the compiler yields ok to bad results.\n        let unroll_len = const { if size_of::<T>() <= 16 { 2 } else { 1 } };\n\n        let unroll_end = v_base.add(len - (unroll_len - 1));\n        while state.right < unroll_end {\n            if unroll_len == 2 {\n                loop_body(&mut state);\n                loop_body(&mut state);\n            } else {\n                loop_body(&mut state);\n            }\n        }\n\n        // Single instantiate `loop_body` for both the unroll cleanup and cyclic permutation\n        // cleanup. Optimizes binary-size and compile-time.\n        let end = v_base.add(len);\n        loop {\n            let is_done = state.right == end;\n            state.right = if is_done { state.gap.value } else { state.right };\n\n            loop_body(&mut state);\n\n            if is_done {\n                mem::forget(state.gap);\n                break;\n            }\n        }\n\n        state.num_lt\n    }\n}",
  "mir": "fn slice::sort::unstable::quicksort::partition_lomuto_branchless_cyclic(_1: &mut [T], _2: &T, _3: &mut F) -> usize {\n    let mut _0: usize;\n    let  _4: usize;\n    let mut _5: &[T];\n    let  _6: *mut T;\n    let mut _7: {closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60};\n    let mut _8: &*mut T;\n    let mut _9: mem::manually_drop::ManuallyDrop<T>;\n    let mut _10: T;\n    let mut _11: *const T;\n    let mut _12: slice::sort::unstable::quicksort::PartitionState<T>;\n    let mut _13: *mut T;\n    let mut _14: slice::sort::unstable::quicksort::GapGuardRaw<T>;\n    let mut _15: *mut T;\n    let mut _16: &mut T;\n    let mut _17: &mut mem::manually_drop::ManuallyDrop<T>;\n    let  _18: usize;\n    let  _19: *mut T;\n    let mut _20: usize;\n    let mut _21: usize;\n    let mut _22: (usize, bool);\n    let mut _23: (usize, bool);\n    let mut _24: bool;\n    let mut _25: *mut T;\n    let  _26: ();\n    let mut _27: &mut {closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60};\n    let mut _28: (&mut slice::sort::unstable::quicksort::PartitionState<T>,);\n    let mut _29: &mut slice::sort::unstable::quicksort::PartitionState<T>;\n    let  _30: ();\n    let mut _31: &mut {closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60};\n    let mut _32: (&mut slice::sort::unstable::quicksort::PartitionState<T>,);\n    let mut _33: &mut slice::sort::unstable::quicksort::PartitionState<T>;\n    let  _34: ();\n    let mut _35: &mut {closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60};\n    let mut _36: (&mut slice::sort::unstable::quicksort::PartitionState<T>,);\n    let mut _37: &mut slice::sort::unstable::quicksort::PartitionState<T>;\n    let  _38: *mut T;\n    let  _39: bool;\n    let mut _40: *mut T;\n    let mut _41: *mut T;\n    let  _42: ();\n    let mut _43: &mut {closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60};\n    let mut _44: (&mut slice::sort::unstable::quicksort::PartitionState<T>,);\n    let mut _45: &mut slice::sort::unstable::quicksort::PartitionState<T>;\n    let  _46: ();\n    let mut _47: slice::sort::unstable::quicksort::GapGuardRaw<T>;\n    debug v => _1;\n    debug pivot => _2;\n    debug is_less => _3;\n    debug len => _4;\n    debug v_base => _6;\n    debug loop_body => _7;\n    debug gap_value => _9;\n    debug state => _12;\n    debug unroll_len => _18;\n    debug unroll_end => _19;\n    debug end => _38;\n    debug is_done => _39;\n    bb0: {\n        StorageLive(_5);\n        _5 = &(*_1);\n        _4 = PtrMetadata(move _5);\n        StorageDead(_5);\n        _6 = slice::<impl [T]>::as_mut_ptr(_1) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        switchInt(_4) -> [0: bb2, otherwise: bb3];\n    }\n    bb2: {\n        _0 = 0_usize;\n        goto -> bb29;\n    }\n    bb3: {\n        StorageLive(_7);\n        StorageLive(_8);\n        _8 = &_6;\n        _7 = {closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60}(_3, _2, move _8);\n        StorageDead(_8);\n        StorageLive(_9);\n        StorageLive(_10);\n        StorageLive(_11);\n        _11 = _6 as *const T;\n        _10 = ptr::read::<T>(move _11) -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        StorageDead(_11);\n        _9 = mem::manually_drop::ManuallyDrop::<T>::new(move _10) -> [return: bb5, unwind unreachable];\n    }\n    bb5: {\n        StorageDead(_10);\n        StorageLive(_12);\n        StorageLive(_13);\n        _13 = ptr::mut_ptr::<impl *mut T>::add(_6, 1_usize) -> [return: bb6, unwind unreachable];\n    }\n    bb6: {\n        StorageLive(_14);\n        StorageLive(_15);\n        StorageLive(_17);\n        _17 = &mut _9;\n        _16 = <mem::manually_drop::ManuallyDrop<T> as ops::deref::DerefMut>::deref_mut(move _17) -> [return: bb7, unwind unreachable];\n    }\n    bb7: {\n        StorageDead(_17);\n        _15 = &raw mut (*_16);\n        _14 = GapGuardRaw(_6, move _15);\n        StorageDead(_15);\n        _12 = PartitionState(move _13, 0_usize, move _14);\n        StorageDead(_14);\n        StorageDead(_13);\n        _18 = slice::sort::unstable::quicksort::partition_lomuto_branchless_cyclic::<T, F>::{constant#0};\n        StorageLive(_20);\n        StorageLive(_21);\n        _22 = CheckedSub(_18, 1_usize);\n        assert(!move (_22.1: bool), \"attempt to compute `{} - {}`, which would overflow\", _18, 1_usize) -> [success: bb8, unwind unreachable];\n    }\n    bb8: {\n        _21 = move (_22.0: usize);\n        _23 = CheckedSub(_4, _21);\n        assert(!move (_23.1: bool), \"attempt to compute `{} - {}`, which would overflow\", _4, move _21) -> [success: bb9, unwind unreachable];\n    }\n    bb9: {\n        _20 = move (_23.0: usize);\n        StorageDead(_21);\n        _19 = ptr::mut_ptr::<impl *mut T>::add(_6, move _20) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        StorageDead(_20);\n        goto -> bb11;\n    }\n    bb11: {\n        StorageLive(_24);\n        StorageLive(_25);\n        _25 = (_12.0: *mut T);\n        _24 = Lt(move _25, _19);\n        switchInt(move _24) -> [0: bb19, otherwise: bb12];\n    }\n    bb12: {\n        StorageDead(_25);\n        switchInt(_18) -> [2: bb13, otherwise: bb16];\n    }\n    bb13: {\n        StorageLive(_27);\n        _27 = &mut _7;\n        StorageLive(_28);\n        _29 = &mut _12;\n        _28 = (_29);\n        _26 = <{closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60} as ops::function::FnMut<(&mut slice::sort::unstable::quicksort::PartitionState<T>,)>>::call_mut(move _27, move _28) -> [return: bb14, unwind unreachable];\n    }\n    bb14: {\n        StorageDead(_28);\n        StorageDead(_27);\n        StorageLive(_31);\n        _31 = &mut _7;\n        StorageLive(_32);\n        _33 = &mut _12;\n        _32 = (_33);\n        _30 = <{closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60} as ops::function::FnMut<(&mut slice::sort::unstable::quicksort::PartitionState<T>,)>>::call_mut(move _31, move _32) -> [return: bb15, unwind unreachable];\n    }\n    bb15: {\n        StorageDead(_32);\n        StorageDead(_31);\n        goto -> bb18;\n    }\n    bb16: {\n        StorageLive(_35);\n        _35 = &mut _7;\n        StorageLive(_36);\n        _37 = &mut _12;\n        _36 = (_37);\n        _34 = <{closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60} as ops::function::FnMut<(&mut slice::sort::unstable::quicksort::PartitionState<T>,)>>::call_mut(move _35, move _36) -> [return: bb17, unwind unreachable];\n    }\n    bb17: {\n        StorageDead(_36);\n        StorageDead(_35);\n        goto -> bb18;\n    }\n    bb18: {\n        StorageDead(_24);\n        goto -> bb11;\n    }\n    bb19: {\n        StorageDead(_25);\n        StorageDead(_24);\n        _38 = ptr::mut_ptr::<impl *mut T>::add(_6, _4) -> [return: bb20, unwind unreachable];\n    }\n    bb20: {\n        goto -> bb21;\n    }\n    bb21: {\n        StorageLive(_40);\n        _40 = (_12.0: *mut T);\n        _39 = Eq(move _40, _38);\n        StorageDead(_40);\n        StorageLive(_41);\n        switchInt(_39) -> [0: bb23, otherwise: bb22];\n    }\n    bb22: {\n        _41 = ((_12.2: slice::sort::unstable::quicksort::GapGuardRaw<T>).1: *mut T);\n        goto -> bb24;\n    }\n    bb23: {\n        _41 = (_12.0: *mut T);\n        goto -> bb24;\n    }\n    bb24: {\n        (_12.0: *mut T) = move _41;\n        StorageDead(_41);\n        StorageLive(_43);\n        _43 = &mut _7;\n        StorageLive(_44);\n        _45 = &mut _12;\n        _44 = (_45);\n        _42 = <{closure@/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:280:29: 280:60} as ops::function::FnMut<(&mut slice::sort::unstable::quicksort::PartitionState<T>,)>>::call_mut(move _43, move _44) -> [return: bb25, unwind unreachable];\n    }\n    bb25: {\n        StorageDead(_44);\n        StorageDead(_43);\n        switchInt(_39) -> [0: bb28, otherwise: bb26];\n    }\n    bb26: {\n        StorageLive(_47);\n        _47 = move (_12.2: slice::sort::unstable::quicksort::GapGuardRaw<T>);\n        _46 = mem::forget::<slice::sort::unstable::quicksort::GapGuardRaw<T>>(move _47) -> [return: bb27, unwind unreachable];\n    }\n    bb27: {\n        StorageDead(_47);\n        _0 = (_12.1: usize);\n        StorageDead(_12);\n        StorageDead(_9);\n        StorageDead(_7);\n        goto -> bb29;\n    }\n    bb28: {\n        goto -> bb21;\n    }\n    bb29: {\n        return;\n    }\n}\n",
  "doc": "",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}