{
  "name": "core_arch::x86::avx512bw::_mm256_movm_epi8",
  "safe": false,
  "callees": {
    "core_arch::x86::avx::_mm256_set1_epi8": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Broadcasts 8-bit integer `a` to all elements of returned vector.\n This intrinsic may generate the `vpbroadcastb`.\n\n [Intel's documentation](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm256_set1_epi8)\n",
      "adt": {
        "core_arch::x86::__m256i": "Constructor"
      }
    },
    "core_arch::x86::__m256i::as_i8x32": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "core_arch::simd::i8x32": "Constructor"
      }
    },
    "intrinsics::simd::simd_select_bitmask": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Selects elements from a bitmask.\n\n `M` must be an unsigned integer or array of `u8`, matching `simd_bitmask`.\n\n `T` must be a vector.\n\n For each element, if the bit in `mask` is `1`, select the element from\n `if_true`.  If the corresponding bit in `mask` is `0`, select the element from\n `if_false`.\n The remaining bits of the mask are ignored.\n\n The bitmask bit order matches `simd_bitmask`.\n",
      "adt": {}
    }
  },
  "adts": {
    "core_arch::x86::__m256i": [
      "Plain"
    ],
    "core_arch::simd::i8x32": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "core::core_arch::x86::avx512bw::_mm256_movm_epi8"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/../../stdarch/crates/core_arch/src/x86/avx512bw.rs:10237:1: 10244:2",
  "src": "pub fn _mm256_movm_epi8(k: __mmask32) -> __m256i {\n    unsafe {\n        let one =\n            _mm256_set1_epi8(1 << 7 | 1 << 6 | 1 << 5 | 1 << 4 | 1 << 3 | 1 << 2 | 1 << 1 | 1 << 0)\n                .as_i8x32();\n        transmute(simd_select_bitmask(k, one, i8x32::ZERO))\n    }\n}",
  "mir": "fn core_arch::x86::avx512bw::_mm256_movm_epi8(_1: u32) -> core_arch::x86::__m256i {\n    let mut _0: core_arch::x86::__m256i;\n    let  _2: core_arch::simd::i8x32;\n    let mut _3: core_arch::x86::__m256i;\n    let mut _4: i8;\n    let mut _5: i8;\n    let mut _6: i8;\n    let mut _7: i8;\n    let mut _8: i8;\n    let mut _9: i8;\n    let mut _10: i8;\n    let mut _11: i8;\n    let mut _12: u32;\n    let mut _13: bool;\n    let mut _14: i8;\n    let mut _15: u32;\n    let mut _16: bool;\n    let mut _17: i8;\n    let mut _18: u32;\n    let mut _19: bool;\n    let mut _20: i8;\n    let mut _21: u32;\n    let mut _22: bool;\n    let mut _23: i8;\n    let mut _24: u32;\n    let mut _25: bool;\n    let mut _26: i8;\n    let mut _27: u32;\n    let mut _28: bool;\n    let mut _29: i8;\n    let mut _30: u32;\n    let mut _31: bool;\n    let mut _32: i8;\n    let mut _33: u32;\n    let mut _34: bool;\n    let mut _35: core_arch::simd::i8x32;\n    debug k => _1;\n    debug one => _2;\n    bb0: {\n        StorageLive(_3);\n        StorageLive(_4);\n        StorageLive(_5);\n        StorageLive(_6);\n        StorageLive(_7);\n        StorageLive(_8);\n        StorageLive(_9);\n        StorageLive(_10);\n        StorageLive(_11);\n        _12 = 7_i32 as u32;\n        _13 = Lt(move _12, 8_u32);\n        assert(move _13, \"attempt to shift left by `{}`, which would overflow\", 7_i32) -> [success: bb1, unwind unreachable];\n    }\n    bb1: {\n        _11 = Shl(1_i8, 7_i32);\n        StorageLive(_14);\n        _15 = 6_i32 as u32;\n        _16 = Lt(move _15, 8_u32);\n        assert(move _16, \"attempt to shift left by `{}`, which would overflow\", 6_i32) -> [success: bb2, unwind unreachable];\n    }\n    bb2: {\n        _14 = Shl(1_i8, 6_i32);\n        _10 = BitOr(move _11, move _14);\n        StorageDead(_14);\n        StorageDead(_11);\n        StorageLive(_17);\n        _18 = 5_i32 as u32;\n        _19 = Lt(move _18, 8_u32);\n        assert(move _19, \"attempt to shift left by `{}`, which would overflow\", 5_i32) -> [success: bb3, unwind unreachable];\n    }\n    bb3: {\n        _17 = Shl(1_i8, 5_i32);\n        _9 = BitOr(move _10, move _17);\n        StorageDead(_17);\n        StorageDead(_10);\n        StorageLive(_20);\n        _21 = 4_i32 as u32;\n        _22 = Lt(move _21, 8_u32);\n        assert(move _22, \"attempt to shift left by `{}`, which would overflow\", 4_i32) -> [success: bb4, unwind unreachable];\n    }\n    bb4: {\n        _20 = Shl(1_i8, 4_i32);\n        _8 = BitOr(move _9, move _20);\n        StorageDead(_20);\n        StorageDead(_9);\n        StorageLive(_23);\n        _24 = 3_i32 as u32;\n        _25 = Lt(move _24, 8_u32);\n        assert(move _25, \"attempt to shift left by `{}`, which would overflow\", 3_i32) -> [success: bb5, unwind unreachable];\n    }\n    bb5: {\n        _23 = Shl(1_i8, 3_i32);\n        _7 = BitOr(move _8, move _23);\n        StorageDead(_23);\n        StorageDead(_8);\n        StorageLive(_26);\n        _27 = 2_i32 as u32;\n        _28 = Lt(move _27, 8_u32);\n        assert(move _28, \"attempt to shift left by `{}`, which would overflow\", 2_i32) -> [success: bb6, unwind unreachable];\n    }\n    bb6: {\n        _26 = Shl(1_i8, 2_i32);\n        _6 = BitOr(move _7, move _26);\n        StorageDead(_26);\n        StorageDead(_7);\n        StorageLive(_29);\n        _30 = 1_i32 as u32;\n        _31 = Lt(move _30, 8_u32);\n        assert(move _31, \"attempt to shift left by `{}`, which would overflow\", 1_i32) -> [success: bb7, unwind unreachable];\n    }\n    bb7: {\n        _29 = Shl(1_i8, 1_i32);\n        _5 = BitOr(move _6, move _29);\n        StorageDead(_29);\n        StorageDead(_6);\n        StorageLive(_32);\n        _33 = 0_i32 as u32;\n        _34 = Lt(move _33, 8_u32);\n        assert(move _34, \"attempt to shift left by `{}`, which would overflow\", 0_i32) -> [success: bb8, unwind unreachable];\n    }\n    bb8: {\n        _32 = Shl(1_i8, 0_i32);\n        _4 = BitOr(move _5, move _32);\n        StorageDead(_32);\n        StorageDead(_5);\n        _3 = core_arch::x86::avx::_mm256_set1_epi8(move _4) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_4);\n        _2 = core_arch::x86::__m256i::as_i8x32(move _3) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        StorageDead(_3);\n        StorageLive(_35);\n        _35 = intrinsics::simd::simd_select_bitmask::<u32, core_arch::simd::i8x32>(_1, _2, core_arch::simd::i8x32::ZERO) -> [return: bb11, unwind unreachable];\n    }\n    bb11: {\n        _0 = move _35 as core_arch::x86::__m256i;\n        StorageDead(_35);\n        return;\n    }\n}\n",
  "doc": " Set each packed 8-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.\n\n [Intel's documentation](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm256_movm_epi8&expand=3894)\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}