{
  "name": "slice::sort::unstable::quicksort::partition_hoare_branchy_cyclic",
  "safe": true,
  "callees": {
    "slice::<impl [T]>::as_mut_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns an unsafe mutable pointer to the slice's buffer.\n\n The caller must ensure that the slice outlives the pointer this\n function returns, or else it will end up dangling.\n\n Modifying the container referenced by this slice may cause its buffer\n to be reallocated, which would also make any pointers to it invalid.\n\n # Examples\n\n ```\n let x = &mut [1, 2, 4];\n let x_ptr = x.as_mut_ptr();\n\n unsafe {\n     for i in 0..x.len() {\n         *x_ptr.add(i) += 2;\n     }\n }\n assert_eq!(x, &[3, 4, 6]);\n ```\n",
      "adt": {}
    },
    "ptr::mut_ptr::<impl *mut T>::add": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "\n # Examples\n\n ```\n let mut s: String = \"123\".to_string();\n let ptr: *mut u8 = s.as_mut_ptr();\n\n unsafe {\n     assert_eq!('2', *ptr.add(1) as char);\n     assert_eq!('3', *ptr.add(2) as char);\n }\n ```\n",
      "adt": {}
    },
    "ops::function::FnMut::call_mut": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Performs the call operation.\n",
      "adt": {}
    },
    "ptr::mut_ptr::<impl *mut T>::sub": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Subtracts an unsigned offset from a pointer.\n\n This can only move the pointer backward (or not move it). If you need to move forward or\n backward depending on the value, then you might want [`offset`](#method.offset) instead\n which takes a signed offset.\n\n `count` is in units of T; e.g., a `count` of 3 represents a pointer\n offset of `3 * size_of::<T>()` bytes.\n\n # Safety\n\n If any of the following conditions are violated, the result is Undefined Behavior:\n\n * The offset in bytes, `count * size_of::<T>()`, computed on mathematical integers (without\n   \"wrapping around\"), must fit in an `isize`.\n\n * If the computed offset is non-zero, then `self` must be [derived from][crate::ptr#provenance] a pointer to some\n   [allocation], and the entire memory range between `self` and the result must be in\n   bounds of that allocation. In particular, this range must not \"wrap around\" the edge\n   of the address space.\n\n Allocations can never be larger than `isize::MAX` bytes, so if the computed offset\n stays in bounds of the allocation, it is guaranteed to satisfy the first requirement.\n This implies, for instance, that `vec.as_ptr().add(vec.len())` (for `vec: Vec<T>`) is always\n safe.\n\n Consider using [`wrapping_sub`] instead if these constraints are\n difficult to satisfy. The only advantage of this method is that it\n enables more aggressive compiler optimizations.\n\n [`wrapping_sub`]: #method.wrapping_sub\n [allocation]: crate::ptr#allocation\n\n # Examples\n\n ```\n let s: &str = \"123\";\n\n unsafe {\n     let end: *const u8 = s.as_ptr().add(3);\n     assert_eq!('3', *end.sub(1) as char);\n     assert_eq!('2', *end.sub(2) as char);\n }\n ```\n",
      "adt": {}
    },
    "ptr::mut_ptr::<impl *mut T>::offset_from_unsigned": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Calculates the distance between two pointers within the same allocation, *where it's known that\n `self` is equal to or greater than `origin`*. The returned value is in\n units of T: the distance in bytes is divided by `size_of::<T>()`.\n\n This computes the same value that [`offset_from`](#method.offset_from)\n would compute, but with the added precondition that the offset is\n guaranteed to be non-negative.  This method is equivalent to\n `usize::try_from(self.offset_from(origin)).unwrap_unchecked()`,\n but it provides slightly more information to the optimizer, which can\n sometimes allow it to optimize slightly better with some backends.\n\n This method can be thought of as recovering the `count` that was passed\n to [`add`](#method.add) (or, with the parameters in the other order,\n to [`sub`](#method.sub)).  The following are all equivalent, assuming\n that their safety preconditions are met:\n ```rust\n # unsafe fn blah(ptr: *mut i32, origin: *mut i32, count: usize) -> bool { unsafe {\n ptr.offset_from_unsigned(origin) == count\n # &&\n origin.add(count) == ptr\n # &&\n ptr.sub(count) == origin\n # } }\n ```\n\n # Safety\n\n - The distance between the pointers must be non-negative (`self >= origin`)\n\n - *All* the safety conditions of [`offset_from`](#method.offset_from)\n   apply to this method as well; see it for the full details.\n\n Importantly, despite the return type of this method being able to represent\n a larger offset, it's still *not permitted* to pass pointers which differ\n by more than `isize::MAX` *bytes*.  As such, the result of this method will\n always be less than or equal to `isize::MAX as usize`.\n\n # Panics\n\n This function panics if `T` is a Zero-Sized Type (\"ZST\").\n\n # Examples\n\n ```\n let mut a = [0; 5];\n let p: *mut i32 = a.as_mut_ptr();\n unsafe {\n     let ptr1: *mut i32 = p.add(1);\n     let ptr2: *mut i32 = p.add(3);\n\n     assert_eq!(ptr2.offset_from_unsigned(ptr1), 2);\n     assert_eq!(ptr1.add(2), ptr2);\n     assert_eq!(ptr2.sub(2), ptr1);\n     assert_eq!(ptr2.offset_from_unsigned(ptr2), 0);\n }\n\n // This would be incorrect, as the pointers are not correctly ordered:\n // ptr1.offset_from(ptr2)\n ```\n",
      "adt": {}
    },
    "option::Option::<T>::is_none": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns `true` if the option is a [`None`] value.\n\n # Examples\n\n ```\n let x: Option<u32> = Some(2);\n assert_eq!(x.is_none(), false);\n\n let x: Option<u32> = None;\n assert_eq!(x.is_none(), true);\n ```\n",
      "adt": {
        "option::Option": "ImmutableAsArgument"
      }
    },
    "ptr::read": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Reads the value from `src` without moving it. This leaves the\n memory in `src` unchanged.\n\n # Safety\n\n Behavior is undefined if any of the following conditions are violated:\n\n * `src` must be [valid] for reads.\n\n * `src` must be properly aligned. Use [`read_unaligned`] if this is not the\n   case.\n\n * `src` must point to a properly initialized value of type `T`.\n\n Note that even if `T` has size `0`, the pointer must be properly aligned.\n\n # Examples\n\n Basic usage:\n\n ```\n let x = 12;\n let y = &x as *const i32;\n\n unsafe {\n     assert_eq!(std::ptr::read(y), 12);\n }\n ```\n\n Manually implement [`mem::swap`]:\n\n ```\n use std::ptr;\n\n fn swap<T>(a: &mut T, b: &mut T) {\n     unsafe {\n         // Create a bitwise copy of the value at `a` in `tmp`.\n         let tmp = ptr::read(a);\n\n         // Exiting at this point (either by explicitly returning or by\n         // calling a function which panics) would cause the value in `tmp` to\n         // be dropped while the same value is still referenced by `a`. This\n         // could trigger undefined behavior if `T` is not `Copy`.\n\n         // Create a bitwise copy of the value at `b` in `a`.\n         // This is safe because mutable references cannot alias.\n         ptr::copy_nonoverlapping(b, a, 1);\n\n         // As above, exiting here could trigger undefined behavior because\n         // the same value is referenced by `a` and `b`.\n\n         // Move `tmp` into `b`.\n         ptr::write(b, tmp);\n\n         // `tmp` has been moved (`write` takes ownership of its second argument),\n         // so nothing is dropped implicitly here.\n     }\n }\n\n let mut foo = \"foo\".to_owned();\n let mut bar = \"bar\".to_owned();\n\n swap(&mut foo, &mut bar);\n\n assert_eq!(foo, \"bar\");\n assert_eq!(bar, \"foo\");\n ```\n\n ## Ownership of the Returned Value\n\n `read` creates a bitwise copy of `T`, regardless of whether `T` is [`Copy`].\n If `T` is not [`Copy`], using both the returned value and the value at\n `*src` can violate memory safety. Note that assigning to `*src` counts as a\n use because it will attempt to drop the value at `*src`.\n\n [`write()`] can be used to overwrite data without causing it to be dropped.\n\n ```\n use std::ptr;\n\n let mut s = String::from(\"foo\");\n unsafe {\n     // `s2` now points to the same underlying memory as `s`.\n     let mut s2: String = ptr::read(&s);\n\n     assert_eq!(s2, \"foo\");\n\n     // Assigning to `s2` causes its original value to be dropped. Beyond\n     // this point, `s` must no longer be used, as the underlying memory has\n     // been freed.\n     s2 = String::default();\n     assert_eq!(s2, \"\");\n\n     // Assigning to `s` would cause the old value to be dropped again,\n     // resulting in undefined behavior.\n     // s = String::from(\"bar\"); // ERROR\n\n     // `ptr::write` can be used to overwrite a value without dropping it.\n     ptr::write(&mut s, String::from(\"bar\"));\n }\n\n assert_eq!(s, \"bar\");\n ```\n\n [valid]: self#safety\n",
      "adt": {}
    },
    "mem::manually_drop::ManuallyDrop::<T>::new": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Wrap a value to be manually dropped.\n\n # Examples\n\n ```rust\n use std::mem::ManuallyDrop;\n let mut x = ManuallyDrop::new(String::from(\"Hello World!\"));\n x.truncate(5); // You can still safely operate on the value\n assert_eq!(*x, \"Hello\");\n // But `Drop` will not be run here\n # // FIXME(https://github.com/rust-lang/miri/issues/3670):\n # // use -Zmiri-disable-leak-check instead of unleaking in tests meant to leak.\n # let _ = ManuallyDrop::into_inner(x);\n ```\n",
      "adt": {
        "mem::manually_drop::ManuallyDrop": "Constructor"
      }
    },
    "option::Option::<T>::as_mut": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Converts from `&mut Option<T>` to `Option<&mut T>`.\n\n # Examples\n\n ```\n let mut x = Some(2);\n match x.as_mut() {\n     Some(v) => *v = 42,\n     None => {},\n }\n assert_eq!(x, Some(42));\n ```\n",
      "adt": {
        "option::Option": "Constructor"
      }
    },
    "option::Option::<T>::unwrap_unchecked": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the contained [`Some`] value, consuming the `self` value,\n without checking that the value is not [`None`].\n\n # Safety\n\n Calling this method on [`None`] is *[undefined behavior]*.\n\n [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n\n # Examples\n\n ```\n let x = Some(\"air\");\n assert_eq!(unsafe { x.unwrap_unchecked() }, \"air\");\n ```\n\n ```no_run\n let x: Option<&str> = None;\n assert_eq!(unsafe { x.unwrap_unchecked() }, \"air\"); // Undefined behavior!\n ```\n",
      "adt": {}
    },
    "ptr::copy_nonoverlapping": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Copies `count * size_of::<T>()` bytes from `src` to `dst`. The source\n and destination must *not* overlap.\n\n For regions of memory which might overlap, use [`copy`] instead.\n\n `copy_nonoverlapping` is semantically equivalent to C's [`memcpy`], but\n with the source and destination arguments swapped,\n and `count` counting the number of `T`s instead of bytes.\n\n The copy is \"untyped\" in the sense that data may be uninitialized or otherwise violate the\n requirements of `T`. The initialization state is preserved exactly.\n\n [`memcpy`]: https://en.cppreference.com/w/c/string/byte/memcpy\n\n # Safety\n\n Behavior is undefined if any of the following conditions are violated:\n\n * `src` must be [valid] for reads of `count * size_of::<T>()` bytes.\n\n * `dst` must be [valid] for writes of `count * size_of::<T>()` bytes.\n\n * Both `src` and `dst` must be properly aligned.\n\n * The region of memory beginning at `src` with a size of `count *\n   size_of::<T>()` bytes must *not* overlap with the region of memory\n   beginning at `dst` with the same size.\n\n Like [`read`], `copy_nonoverlapping` creates a bitwise copy of `T`, regardless of\n whether `T` is [`Copy`]. If `T` is not [`Copy`], using *both* the values\n in the region beginning at `*src` and the region beginning at `*dst` can\n [violate memory safety][read-ownership].\n\n Note that even if the effectively copied size (`count * size_of::<T>()`) is\n `0`, the pointers must be properly aligned.\n\n [`read`]: crate::ptr::read\n [read-ownership]: crate::ptr::read#ownership-of-the-returned-value\n [valid]: crate::ptr#safety\n\n # Examples\n\n Manually implement [`Vec::append`]:\n\n ```\n use std::ptr;\n\n /// Moves all the elements of `src` into `dst`, leaving `src` empty.\n fn append<T>(dst: &mut Vec<T>, src: &mut Vec<T>) {\n     let src_len = src.len();\n     let dst_len = dst.len();\n\n     // Ensure that `dst` has enough capacity to hold all of `src`.\n     dst.reserve(src_len);\n\n     unsafe {\n         // The call to add is always safe because `Vec` will never\n         // allocate more than `isize::MAX` bytes.\n         let dst_ptr = dst.as_mut_ptr().add(dst_len);\n         let src_ptr = src.as_ptr();\n\n         // Truncate `src` without dropping its contents. We do this first,\n         // to avoid problems in case something further down panics.\n         src.set_len(0);\n\n         // The two regions cannot overlap because mutable references do\n         // not alias, and two different vectors cannot own the same\n         // memory.\n         ptr::copy_nonoverlapping(src_ptr, dst_ptr, src_len);\n\n         // Notify `dst` that it now holds the contents of `src`.\n         dst.set_len(dst_len + src_len);\n     }\n }\n\n let mut a = vec!['r'];\n let mut b = vec!['u', 's', 't'];\n\n append(&mut a, &mut b);\n\n assert_eq!(a, &['r', 'u', 's', 't']);\n assert!(b.is_empty());\n ```\n\n [`Vec::append`]: ../../std/vec/struct.Vec.html#method.append\n",
      "adt": {}
    }
  },
  "adts": {
    "option::Option": [
      "Plain",
      "Ref",
      "MutRef"
    ],
    "mem::manually_drop::ManuallyDrop": [
      "Plain"
    ],
    "slice::sort::unstable::quicksort::GapGuard": [
      "Plain",
      "MutRef",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))"
    ]
  },
  "path": 16734,
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/slice/sort/unstable/quicksort.rs:158:1: 235:2",
  "src": "fn partition_hoare_branchy_cyclic<T, F>(v: &mut [T], pivot: &T, is_less: &mut F) -> usize\nwhere\n    F: FnMut(&T, &T) -> bool,\n{\n    let len = v.len();\n\n    if len == 0 {\n        return 0;\n    }\n\n    // Optimized for large types that are expensive to move. Not optimized for integers. Optimized\n    // for small code-gen, assuming that is_less is an expensive operation that generates\n    // substantial amounts of code or a call. And that copying elements will likely be a call to\n    // memcpy. Using 2 `ptr::copy_nonoverlapping` has the chance to be faster than\n    // `ptr::swap_nonoverlapping` because `memcpy` can use wide SIMD based on runtime feature\n    // detection. Benchmarks support this analysis.\n\n    let mut gap_opt: Option<GapGuard<T>> = None;\n\n    // SAFETY: The left-to-right scanning loop performs a bounds check, where we know that `left >=\n    // v_base && left < right && right <= v_base.add(len)`. The right-to-left scanning loop performs\n    // a bounds check ensuring that `right` is in-bounds. We checked that `len` is more than zero,\n    // which means that unconditional `right = right.sub(1)` is safe to do. The exit check makes\n    // sure that `left` and `right` never alias, making `ptr::copy_nonoverlapping` safe. The\n    // drop-guard `gap` ensures that should `is_less` panic we always overwrite the duplicate in the\n    // input. `gap.pos` stores the previous value of `right` and starts at `right` and so it too is\n    // in-bounds. We never pass the saved `gap.value` to `is_less` while it is inside the `GapGuard`\n    // thus any changes via interior mutability will be observed.\n    unsafe {\n        let v_base = v.as_mut_ptr();\n\n        let mut left = v_base;\n        let mut right = v_base.add(len);\n\n        loop {\n            // Find the first element greater than the pivot.\n            while left < right && is_less(&*left, pivot) {\n                left = left.add(1);\n            }\n\n            // Find the last element equal to the pivot.\n            loop {\n                right = right.sub(1);\n                if left >= right || is_less(&*right, pivot) {\n                    break;\n                }\n            }\n\n            if left >= right {\n                break;\n            }\n\n            // Swap the found pair of out-of-order elements via cyclic permutation.\n            let is_first_swap_pair = gap_opt.is_none();\n\n            if is_first_swap_pair {\n                gap_opt = Some(GapGuard { pos: right, value: ManuallyDrop::new(ptr::read(left)) });\n            }\n\n            let gap = gap_opt.as_mut().unwrap_unchecked();\n\n            // Single place where we instantiate ptr::copy_nonoverlapping in the partition.\n            if !is_first_swap_pair {\n                ptr::copy_nonoverlapping(left, gap.pos, 1);\n            }\n            gap.pos = right;\n            ptr::copy_nonoverlapping(right, left, 1);\n\n            left = left.add(1);\n        }\n\n        left.offset_from_unsigned(v_base)\n\n        // `gap_opt` goes out of scope and overwrites the last wrong-side element on the right side\n        // with the first wrong-side element of the left side that was initially overwritten by the\n        // first wrong-side element on the right side element.\n    }\n}",
  "mir": "fn slice::sort::unstable::quicksort::partition_hoare_branchy_cyclic(_1: &mut [T], _2: &T, _3: &mut F) -> usize {\n    let mut _0: usize;\n    let  _4: usize;\n    let mut _5: &[T];\n    let mut _6: option::Option<slice::sort::unstable::quicksort::GapGuard<T>>;\n    let  _7: *mut T;\n    let mut _8: *mut T;\n    let mut _9: *mut T;\n    let mut _10: bool;\n    let mut _11: *mut T;\n    let mut _12: *mut T;\n    let mut _13: bool;\n    let mut _14: (&T, &T);\n    let  _15: &T;\n    let mut _16: *mut T;\n    let mut _17: *mut T;\n    let mut _18: *mut T;\n    let mut _19: *mut T;\n    let mut _20: bool;\n    let mut _21: *mut T;\n    let mut _22: *mut T;\n    let mut _23: bool;\n    let mut _24: (&T, &T);\n    let  _25: &T;\n    let mut _26: bool;\n    let mut _27: *mut T;\n    let mut _28: *mut T;\n    let  _29: bool;\n    let mut _30: &option::Option<slice::sort::unstable::quicksort::GapGuard<T>>;\n    let mut _31: option::Option<slice::sort::unstable::quicksort::GapGuard<T>>;\n    let mut _32: slice::sort::unstable::quicksort::GapGuard<T>;\n    let mut _33: *mut T;\n    let mut _34: mem::manually_drop::ManuallyDrop<T>;\n    let mut _35: T;\n    let mut _36: *const T;\n    let mut _37: *mut T;\n    let  _38: &mut slice::sort::unstable::quicksort::GapGuard<T>;\n    let mut _39: option::Option<&mut slice::sort::unstable::quicksort::GapGuard<T>>;\n    let mut _40: &mut option::Option<slice::sort::unstable::quicksort::GapGuard<T>>;\n    let  _41: ();\n    let mut _42: *const T;\n    let mut _43: *mut T;\n    let mut _44: *mut T;\n    let mut _45: *mut T;\n    let  _46: ();\n    let mut _47: *const T;\n    let mut _48: *mut T;\n    let mut _49: *mut T;\n    let mut _50: *mut T;\n    let mut _51: *mut T;\n    let mut _52: *mut T;\n    let mut _53: *const T;\n    debug v => _1;\n    debug pivot => _2;\n    debug is_less => _3;\n    debug len => _4;\n    debug gap_opt => _6;\n    debug v_base => _7;\n    debug left => _8;\n    debug right => _9;\n    debug is_first_swap_pair => _29;\n    debug gap => _38;\n    bb0: {\n        StorageLive(_5);\n        _5 = &(*_1);\n        _4 = PtrMetadata(move _5);\n        StorageDead(_5);\n        switchInt(_4) -> [0: bb1, otherwise: bb2];\n    }\n    bb1: {\n        _0 = 0_usize;\n        goto -> bb38;\n    }\n    bb2: {\n        StorageLive(_6);\n        _6 = option::Option::None;\n        _7 = slice::<impl [T]>::as_mut_ptr(_1) -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        StorageLive(_8);\n        _8 = _7;\n        StorageLive(_9);\n        _9 = ptr::mut_ptr::<impl *mut T>::add(_7, _4) -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        goto -> bb5;\n    }\n    bb5: {\n        StorageLive(_10);\n        StorageLive(_11);\n        _11 = _8;\n        StorageLive(_12);\n        _12 = _9;\n        _10 = Lt(move _11, move _12);\n        switchInt(move _10) -> [0: bb11, otherwise: bb6];\n    }\n    bb6: {\n        StorageDead(_12);\n        StorageDead(_11);\n        StorageLive(_13);\n        StorageLive(_14);\n        _15 = &(*_8);\n        _14 = (_15, _2);\n        _13 = <F as ops::function::FnMut<(&T, &T)>>::call_mut(_3, move _14) -> [return: bb7, unwind unreachable];\n    }\n    bb7: {\n        switchInt(move _13) -> [0: bb10, otherwise: bb8];\n    }\n    bb8: {\n        StorageDead(_14);\n        StorageLive(_16);\n        StorageLive(_17);\n        _17 = _8;\n        _16 = ptr::mut_ptr::<impl *mut T>::add(move _17, 1_usize) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_17);\n        _8 = move _16;\n        StorageDead(_16);\n        StorageDead(_13);\n        StorageDead(_10);\n        goto -> bb5;\n    }\n    bb10: {\n        StorageDead(_14);\n        goto -> bb12;\n    }\n    bb11: {\n        StorageDead(_12);\n        StorageDead(_11);\n        goto -> bb12;\n    }\n    bb12: {\n        StorageDead(_13);\n        StorageDead(_10);\n        goto -> bb13;\n    }\n    bb13: {\n        StorageLive(_18);\n        StorageLive(_19);\n        _19 = _9;\n        _18 = ptr::mut_ptr::<impl *mut T>::sub(move _19, 1_usize) -> [return: bb14, unwind unreachable];\n    }\n    bb14: {\n        StorageDead(_19);\n        _9 = move _18;\n        StorageDead(_18);\n        StorageLive(_20);\n        StorageLive(_21);\n        _21 = _8;\n        StorageLive(_22);\n        _22 = _9;\n        _20 = Ge(move _21, move _22);\n        switchInt(move _20) -> [0: bb16, otherwise: bb15];\n    }\n    bb15: {\n        StorageDead(_22);\n        StorageDead(_21);\n        goto -> bb19;\n    }\n    bb16: {\n        StorageDead(_22);\n        StorageDead(_21);\n        StorageLive(_23);\n        StorageLive(_24);\n        _25 = &(*_9);\n        _24 = (_25, _2);\n        _23 = <F as ops::function::FnMut<(&T, &T)>>::call_mut(_3, move _24) -> [return: bb17, unwind unreachable];\n    }\n    bb17: {\n        switchInt(move _23) -> [0: bb20, otherwise: bb18];\n    }\n    bb18: {\n        StorageDead(_24);\n        goto -> bb19;\n    }\n    bb19: {\n        StorageDead(_23);\n        StorageDead(_20);\n        StorageLive(_26);\n        StorageLive(_27);\n        _27 = _8;\n        StorageLive(_28);\n        _28 = _9;\n        _26 = Ge(move _27, move _28);\n        switchInt(move _26) -> [0: bb22, otherwise: bb21];\n    }\n    bb20: {\n        StorageDead(_24);\n        StorageDead(_23);\n        StorageDead(_20);\n        goto -> bb13;\n    }\n    bb21: {\n        StorageDead(_28);\n        StorageDead(_27);\n        StorageDead(_26);\n        StorageLive(_52);\n        _52 = _8;\n        StorageLive(_53);\n        _53 = _7 as *const T;\n        _0 = ptr::mut_ptr::<impl *mut T>::offset_from_unsigned(move _52, move _53) -> [return: bb36, unwind unreachable];\n    }\n    bb22: {\n        StorageDead(_28);\n        StorageDead(_27);\n        StorageDead(_26);\n        StorageLive(_30);\n        _30 = &_6;\n        _29 = option::Option::<slice::sort::unstable::quicksort::GapGuard<T>>::is_none(move _30) -> [return: bb23, unwind unreachable];\n    }\n    bb23: {\n        StorageDead(_30);\n        switchInt(_29) -> [0: bb28, otherwise: bb24];\n    }\n    bb24: {\n        StorageLive(_31);\n        StorageLive(_32);\n        StorageLive(_33);\n        _33 = _9;\n        StorageLive(_34);\n        StorageLive(_35);\n        StorageLive(_36);\n        StorageLive(_37);\n        _37 = _8;\n        _36 = move _37 as *const T;\n        StorageDead(_37);\n        _35 = ptr::read::<T>(move _36) -> [return: bb25, unwind unreachable];\n    }\n    bb25: {\n        StorageDead(_36);\n        _34 = mem::manually_drop::ManuallyDrop::<T>::new(move _35) -> [return: bb26, unwind unreachable];\n    }\n    bb26: {\n        StorageDead(_35);\n        _32 = GapGuard(move _33, move _34);\n        StorageDead(_34);\n        StorageDead(_33);\n        _31 = option::Option::Some(move _32);\n        StorageDead(_32);\n        drop(_6) -> [return: bb27, unwind unreachable];\n    }\n    bb27: {\n        _6 = move _31;\n        StorageDead(_31);\n        goto -> bb28;\n    }\n    bb28: {\n        StorageLive(_38);\n        StorageLive(_39);\n        StorageLive(_40);\n        _40 = &mut _6;\n        _39 = option::Option::<slice::sort::unstable::quicksort::GapGuard<T>>::as_mut(move _40) -> [return: bb29, unwind unreachable];\n    }\n    bb29: {\n        StorageDead(_40);\n        _38 = option::Option::<&mut slice::sort::unstable::quicksort::GapGuard<T>>::unwrap_unchecked(move _39) -> [return: bb30, unwind unreachable];\n    }\n    bb30: {\n        StorageDead(_39);\n        switchInt(_29) -> [0: bb31, otherwise: bb33];\n    }\n    bb31: {\n        StorageLive(_42);\n        StorageLive(_43);\n        _43 = _8;\n        _42 = move _43 as *const T;\n        StorageDead(_43);\n        StorageLive(_44);\n        _44 = ((*_38).0: *mut T);\n        _41 = ptr::copy_nonoverlapping::<T>(move _42, move _44, 1_usize) -> [return: bb32, unwind unreachable];\n    }\n    bb32: {\n        StorageDead(_44);\n        StorageDead(_42);\n        goto -> bb33;\n    }\n    bb33: {\n        StorageLive(_45);\n        _45 = _9;\n        ((*_38).0: *mut T) = move _45;\n        StorageDead(_45);\n        StorageLive(_47);\n        StorageLive(_48);\n        _48 = _9;\n        _47 = move _48 as *const T;\n        StorageDead(_48);\n        StorageLive(_49);\n        _49 = _8;\n        _46 = ptr::copy_nonoverlapping::<T>(move _47, move _49, 1_usize) -> [return: bb34, unwind unreachable];\n    }\n    bb34: {\n        StorageDead(_49);\n        StorageDead(_47);\n        StorageLive(_50);\n        StorageLive(_51);\n        _51 = _8;\n        _50 = ptr::mut_ptr::<impl *mut T>::add(move _51, 1_usize) -> [return: bb35, unwind unreachable];\n    }\n    bb35: {\n        StorageDead(_51);\n        _8 = move _50;\n        StorageDead(_50);\n        StorageDead(_38);\n        goto -> bb5;\n    }\n    bb36: {\n        StorageDead(_53);\n        StorageDead(_52);\n        StorageDead(_9);\n        StorageDead(_8);\n        drop(_6) -> [return: bb37, unwind unreachable];\n    }\n    bb37: {\n        StorageDead(_6);\n        goto -> bb38;\n    }\n    bb38: {\n        return;\n    }\n}\n",
  "doc": " See [`partition`].\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}