{
  "name": "core::str::count::do_count_chars",
  "span": "$library/core/src/str/count.rs:39:1: 39:36",
  "src": "fn do_count_chars(s: &str) -> usize {\n    // For correctness, `CHUNK_SIZE` must be:\n    //\n    // - Less than or equal to 255, otherwise we'll overflow bytes in `counts`.\n    // - A multiple of `UNROLL_INNER`, otherwise our `break` inside the\n    //   `body.chunks(CHUNK_SIZE)` loop is incorrect.\n    //\n    // For performance, `CHUNK_SIZE` should be:\n    // - Relatively cheap to `/` against (so some simple sum of powers of two).\n    // - Large enough to avoid paying for the cost of the `sum_bytes_in_usize`\n    //   too often.\n    const CHUNK_SIZE: usize = 192;\n\n    // Check the properties of `CHUNK_SIZE` and `UNROLL_INNER` that are required\n    // for correctness.\n    const _: () = assert!(CHUNK_SIZE < 256);\n    const _: () = assert!(CHUNK_SIZE.is_multiple_of(UNROLL_INNER));\n\n    // SAFETY: transmuting `[u8]` to `[usize]` is safe except for size\n    // differences which are handled by `align_to`.\n    let (head, body, tail) = unsafe { s.as_bytes().align_to::<usize>() };\n\n    // This should be quite rare, and basically exists to handle the degenerate\n    // cases where align_to fails (as well as miri under symbolic alignment\n    // mode).\n    //\n    // The `unlikely` helps discourage LLVM from inlining the body, which is\n    // nice, as we would rather not mark the `char_count_general_case` function\n    // as cold.\n    if unlikely(body.is_empty() || head.len() > USIZE_SIZE || tail.len() > USIZE_SIZE) {\n        return char_count_general_case(s.as_bytes());\n    }\n\n    let mut total = char_count_general_case(head) + char_count_general_case(tail);\n    // Split `body` into `CHUNK_SIZE` chunks to reduce the frequency with which\n    // we call `sum_bytes_in_usize`.\n    for chunk in body.chunks(CHUNK_SIZE) {\n        // We accumulate intermediate sums in `counts`, where each byte contains\n        // a subset of the sum of this chunk, like a `[u8; size_of::<usize>()]`.\n        let mut counts = 0;\n\n        let (unrolled_chunks, remainder) = chunk.as_chunks::<UNROLL_INNER>();\n        for unrolled in unrolled_chunks {\n            for &word in unrolled {\n                // Because `CHUNK_SIZE` is < 256, this addition can't cause the\n                // count in any of the bytes to overflow into a subsequent byte.\n                counts += contains_non_continuation_byte(word);\n            }\n        }\n\n        // Sum the values in `counts` (which, again, is conceptually a `[u8;\n        // size_of::<usize>()]`), and accumulate the result into `total`.\n        total += sum_bytes_in_usize(counts);\n\n        // If there's any data in `remainder`, then handle it. This will only\n        // happen for the last `chunk` in `body.chunks()` (because `CHUNK_SIZE`\n        // is divisible by `UNROLL_INNER`), so we explicitly break at the end\n        // (which seems to help LLVM out).\n        if !remainder.is_empty() {\n            // Accumulate all the data in the remainder.\n            let mut counts = 0;\n            for &word in remainder {\n                counts += contains_non_continuation_byte(word);\n            }\n            total += sum_bytes_in_usize(counts);\n            break;\n        }\n    }\n    total\n}"
}