{
  "name": "core::sync::atomic::compiler_fence",
  "span": "$library/core/src/sync/atomic.rs:4566:1: 4566:39",
  "doc": " A \"compiler-only\" atomic fence.\n\n Like [`fence`], this function establishes synchronization with other atomic operations and\n fences. However, unlike [`fence`], `compiler_fence` only establishes synchronization with\n operations *in the same thread*. This may at first sound rather useless, since code within a\n thread is typically already totally ordered and does not need any further synchronization.\n However, there are cases where code can run on the same thread without being ordered:\n - The most common case is that of a *signal handler*: a signal handler runs in the same thread\n   as the code it interrupted, but it is not ordered with respect to that code. `compiler_fence`\n   can be used to establish synchronization between a thread and its signal handler, the same way\n   that `fence` can be used to establish synchronization across threads.\n - Similar situations can arise in embedded programming with interrupt handlers, or in custom\n   implementations of preemptive green threads. In general, `compiler_fence` can establish\n   synchronization with code that is guaranteed to run on the same hardware CPU.\n\n See [`fence`] for how a fence can be used to achieve synchronization. Note that just like\n [`fence`], synchronization still requires atomic operations to be used in both threads -- it is\n not possible to perform synchronization entirely with fences and non-atomic operations.\n\n `compiler_fence` does not emit any machine code, but restricts the kinds of memory re-ordering\n the compiler is allowed to do. `compiler_fence` corresponds to [`atomic_signal_fence`] in C and\n C++.\n\n [`atomic_signal_fence`]: https://en.cppreference.com/w/cpp/atomic/atomic_signal_fence\n\n # Panics\n\n Panics if `order` is [`Relaxed`].\n\n # Examples\n\n Without the two `compiler_fence` calls, the read of `IMPORTANT_VARIABLE` in `signal_handler`\n is *undefined behavior* due to a data race, despite everything happening in a single thread.\n This is because the signal handler is considered to run concurrently with its associated\n thread, and explicit synchronization is required to pass data between a thread and its\n signal handler. The code below uses two `compiler_fence` calls to establish the usual\n release-acquire synchronization pattern (see [`fence`] for an image).\n\n ```\n use std::sync::atomic::AtomicBool;\n use std::sync::atomic::Ordering;\n use std::sync::atomic::compiler_fence;\n\n static mut IMPORTANT_VARIABLE: usize = 0;\n static IS_READY: AtomicBool = AtomicBool::new(false);\n\n fn main() {\n     unsafe { IMPORTANT_VARIABLE = 42 };\n     // Marks earlier writes as being released with future relaxed stores.\n     compiler_fence(Ordering::Release);\n     IS_READY.store(true, Ordering::Relaxed);\n }\n\n fn signal_handler() {\n     if IS_READY.load(Ordering::Relaxed) {\n         // Acquires writes that were released with relaxed stores that we read from.\n         compiler_fence(Ordering::Acquire);\n         assert_eq!(unsafe { IMPORTANT_VARIABLE }, 42);\n     }\n }\n ```\n"
}