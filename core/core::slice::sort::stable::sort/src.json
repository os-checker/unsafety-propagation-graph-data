{
  "name": "core::slice::sort::stable::sort",
  "span": "$library/core/src/slice/sort/stable/mod.rs:29:1: 29:90",
  "src": "pub fn sort<T, F: FnMut(&T, &T) -> bool, BufT: BufGuard<T>>(v: &mut [T], is_less: &mut F) {\n    // Arrays of zero-sized types are always all-equal, and thus sorted.\n    if T::IS_ZST {\n        return;\n    }\n\n    // Instrumenting the standard library showed that 90+% of the calls to sort\n    // by rustc are either of size 0 or 1.\n    let len = v.len();\n    if intrinsics::likely(len < 2) {\n        return;\n    }\n\n    cfg_select! {\n        any(feature = \"optimize_for_size\", target_pointer_width = \"16\") => {\n            // Unlike driftsort, mergesort only requires len / 2,\n            // not len - len / 2.\n            let alloc_len = len / 2;\n\n            cfg_select! {\n                target_pointer_width = \"16\" => {\n                    let mut heap_buf = BufT::with_capacity(alloc_len);\n                    let scratch = heap_buf.as_uninit_slice_mut();\n                }\n                _ => {\n                    // For small inputs 4KiB of stack storage suffices, which allows us to avoid\n                    // calling the (de-)allocator. Benchmarks showed this was quite beneficial.\n                    let mut stack_buf = AlignedStorage::<T, 4096>::new();\n                    let stack_scratch = stack_buf.as_uninit_slice_mut();\n                    let mut heap_buf;\n                    let scratch = if stack_scratch.len() >= alloc_len {\n                        stack_scratch\n                    } else {\n                        heap_buf = BufT::with_capacity(alloc_len);\n                        heap_buf.as_uninit_slice_mut()\n                    };\n                }\n            }\n\n            tiny::mergesort(v, scratch, is_less);\n        }\n        _ => {\n            // More advanced sorting methods than insertion sort are faster if called in\n            // a hot loop for small inputs, but for general-purpose code the small\n            // binary size of insertion sort is more important. The instruction cache in\n            // modern processors is very valuable, and for a single sort call in general\n            // purpose code any gains from an advanced method are cancelled by i-cache\n            // misses during the sort, and thrashing the i-cache for surrounding code.\n            const MAX_LEN_ALWAYS_INSERTION_SORT: usize = 20;\n            if intrinsics::likely(len <= MAX_LEN_ALWAYS_INSERTION_SORT) {\n                insertion_sort_shift_left(v, 1, is_less);\n                return;\n            }\n\n            driftsort_main::<T, F, BufT>(v, is_less);\n        }\n    }\n}"
}