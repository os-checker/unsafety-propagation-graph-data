{
  "name": "core::slice::sort::stable::quicksort::stable_partition",
  "span": "$library/core/src/slice/sort/stable/quicksort.rs:86:1: 92:11",
  "src": "fn stable_partition<T, F: FnMut(&T, &T) -> bool>(\n    v: &mut [T],\n    scratch: &mut [MaybeUninit<T>],\n    pivot_pos: usize,\n    pivot_goes_left: bool,\n    is_less: &mut F,\n) -> usize {\n    let len = v.len();\n\n    if intrinsics::unlikely(scratch.len() < len || pivot_pos >= len) {\n        core::intrinsics::abort()\n    }\n\n    let v_base = v.as_ptr();\n    let scratch_base = scratch.as_mut_ptr().cast_init();\n\n    // The core idea is to write the values that compare as less-than to the left\n    // side of `scratch`, while the values that compared as greater or equal than\n    // `v[pivot_pos]` go to the right side of `scratch` in reverse. See\n    // PartitionState for details.\n\n    // SAFETY: see individual comments.\n    unsafe {\n        // SAFETY: we made sure the scratch has length >= len and that pivot_pos\n        // is in-bounds. v and scratch are disjoint slices.\n        let pivot = v_base.add(pivot_pos);\n        let mut state = PartitionState::new(v_base, scratch_base, len);\n\n        let mut pivot_in_scratch = ptr::null_mut();\n        let mut loop_end_pos = pivot_pos;\n\n        // SAFETY: this loop is equivalent to calling state.partition_one\n        // exactly len times.\n        loop {\n            // Ideally the outer loop won't be unrolled, to save binary size,\n            // but we do want the inner loop to be unrolled for small types, as\n            // this gave significant performance boosts in benchmarks. Unrolling\n            // through for _ in 0..UNROLL_LEN { .. } instead of manually improves\n            // compile times but has a ~10-20% performance penalty on opt-level=s.\n            if const { size_of::<T>() <= 16 } {\n                const UNROLL_LEN: usize = 4;\n                let unroll_end = v_base.add(loop_end_pos.saturating_sub(UNROLL_LEN - 1));\n                while state.scan < unroll_end {\n                    state.partition_one(is_less(&*state.scan, &*pivot));\n                    state.partition_one(is_less(&*state.scan, &*pivot));\n                    state.partition_one(is_less(&*state.scan, &*pivot));\n                    state.partition_one(is_less(&*state.scan, &*pivot));\n                }\n            }\n\n            let loop_end = v_base.add(loop_end_pos);\n            while state.scan < loop_end {\n                state.partition_one(is_less(&*state.scan, &*pivot));\n            }\n\n            if loop_end_pos == len {\n                break;\n            }\n\n            // We avoid comparing pivot with itself, as this could create deadlocks for\n            // certain comparison operators. We also store its location later for later.\n            pivot_in_scratch = state.partition_one(pivot_goes_left);\n\n            loop_end_pos = len;\n        }\n\n        // `pivot` must be copied into its correct position again, because a\n        // comparison operator might have modified it.\n        if has_direct_interior_mutability::<T>() {\n            ptr::copy_nonoverlapping(pivot, pivot_in_scratch, 1);\n        }\n\n        // SAFETY: partition_one being called exactly len times guarantees that scratch\n        // is initialized with a permuted copy of `v`, and that num_left <= v.len().\n        // Copying scratch[0..num_left] and scratch[num_left..v.len()] back is thus\n        // sound, as the values in scratch will never be read again, meaning our copies\n        // semantically act as moves, permuting `v`.\n\n        // Copy all the elements < p directly from swap to v.\n        let v_base = v.as_mut_ptr();\n        ptr::copy_nonoverlapping(scratch_base, v_base, state.num_left);\n\n        // Copy the elements >= p in reverse order.\n        for i in 0..len - state.num_left {\n            ptr::copy_nonoverlapping(\n                scratch_base.add(len - 1 - i),\n                v_base.add(state.num_left + i),\n                1,\n            );\n        }\n\n        state.num_left\n    }\n}"
}