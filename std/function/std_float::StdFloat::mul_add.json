{
  "name": "std_float::StdFloat::mul_add",
  "safe": true,
  "callees": {
    "core::intrinsics::simd::simd_fma": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Computes `(x*y) + z` for each element, but without any intermediate rounding.\n\n `T` must be a vector of floats.\n",
      "adt": {}
    }
  },
  "adts": {},
  "path": "std_float::StdFloat::mul_add",
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/../../portable-simd/crates/std_float/src/lib.rs:55:5: 57:6",
  "src": "fn mul_add(self, a: Self, b: Self) -> Self {\n        unsafe { intrinsics::simd_fma(self, a, b) }\n    }",
  "mir": "fn std_float::StdFloat::mul_add(_1: Self, _2: Self, _3: Self) -> Self {\n    let mut _0: Self;\n    debug self => _1;\n    debug a => _2;\n    debug b => _3;\n    bb0: {\n        _0 = core::intrinsics::simd::simd_fma::<Self>(_1, _2, _3) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        return;\n    }\n}\n",
  "doc": " Elementwise fused multiply-add. Computes `(self * a) + b` with only one rounding error,\n yielding a more accurate result than an unfused multiply-add.\n\n Using `mul_add` *may* be more performant than an unfused multiply-add if the target\n architecture has a dedicated `fma` CPU instruction.  However, this is not always\n true, and will be heavily dependent on designing algorithms with specific target\n hardware in mind.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}