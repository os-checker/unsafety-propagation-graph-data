{
  "name": "thread::scoped::ScopeData::increment_num_running_threads",
  "safe": true,
  "callees": {
    "core::sync::atomic::AtomicUsize::fetch_add": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Adds to the current value, returning the previous value.\n\n This operation wraps around on overflow.\n\n `fetch_add` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. All ordering modes are possible. Note that using\n [`Acquire`] makes the store part of this operation [`Relaxed`], and\n using [`Release`] makes the load part [`Relaxed`].\n\n **Note**: This method is only available on platforms that support atomic operations on\n\n # Examples\n\n ```\n\n assert_eq!(foo.fetch_add(10, Ordering::SeqCst), 0);\n assert_eq!(foo.load(Ordering::SeqCst), 10);\n ```\n",
      "adt": {}
    },
    "thread::scoped::ScopeData::overflow": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "thread::scoped::ScopeData": "ImmutableAsArgument"
      }
    }
  },
  "adts": {
    "core::sync::atomic::AtomicUsize": [
      "Ref"
    ],
    "thread::scoped::ScopeData": [
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "std::thread::scoped::ScopeData::increment_num_running_threads"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/thread/scoped.rs:48:5: 55:6",
  "src": "pub(super) fn increment_num_running_threads(&self) {\n        // We check for 'overflow' with usize::MAX / 2, to make sure there's no\n        // chance it overflows to 0, which would result in unsoundness.\n        if self.num_running_threads.fetch_add(1, Ordering::Relaxed) > usize::MAX / 2 {\n            // This can only reasonably happen by mem::forget()'ing a lot of ScopedJoinHandles.\n            self.overflow();\n        }\n    }",
  "mir": "fn thread::scoped::ScopeData::increment_num_running_threads(_1: &thread::scoped::ScopeData) -> () {\n    let mut _0: ();\n    let mut _2: bool;\n    let mut _3: usize;\n    let mut _4: &core::sync::atomic::AtomicUsize;\n    let mut _5: core::sync::atomic::Ordering;\n    let mut _6: usize;\n    let mut _7: bool;\n    let  _8: ();\n    debug self => _1;\n    bb0: {\n        StorageLive(_2);\n        StorageLive(_3);\n        StorageLive(_4);\n        _4 = &((*_1).0: core::sync::atomic::AtomicUsize);\n        StorageLive(_5);\n        _5 = core::sync::atomic::Ordering::Relaxed;\n        _3 = core::sync::atomic::AtomicUsize::fetch_add(move _4, 1_usize, move _5) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_5);\n        StorageDead(_4);\n        StorageLive(_6);\n        _7 = Eq(2_usize, 0_usize);\n        assert(!move _7, \"attempt to divide `{}` by zero\", core::num::<impl usize>::MAX) -> [success: bb2, unwind unreachable];\n    }\n    bb2: {\n        _6 = Div(core::num::<impl usize>::MAX, 2_usize);\n        _2 = Gt(move _3, move _6);\n        switchInt(move _2) -> [0: bb5, otherwise: bb3];\n    }\n    bb3: {\n        StorageDead(_6);\n        StorageDead(_3);\n        _8 = thread::scoped::ScopeData::overflow(_1) -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        goto -> bb6;\n    }\n    bb5: {\n        StorageDead(_6);\n        StorageDead(_3);\n        goto -> bb6;\n    }\n    bb6: {\n        StorageDead(_2);\n        return;\n    }\n}\n",
  "doc": "",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}