{
  "name": "thread::functions::park",
  "safe": true,
  "callees": {
    "thread::current::current": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Gets a handle to the thread that invokes it.\n\n # Examples\n\n Getting a handle to the current thread with `thread::current()`:\n\n ```\n use std::thread;\n\n let handler = thread::Builder::new()\n     .name(\"named thread\".into())\n     .spawn(|| {\n         let handle = thread::current();\n         assert_eq!(handle.name(), Some(\"named thread\"));\n     })\n     .unwrap();\n\n handler.join().unwrap();\n ```\n",
      "adt": {
        "thread::thread::Thread": "Constructor"
      }
    },
    "thread::thread::Thread::park": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Like the public [`park`], but callable on any handle. This is used to\n allow parking in TLS destructors.\n\n # Safety\n May only be called from the thread to which this handle belongs.\n\n [`park`]: super::park\n",
      "adt": {
        "thread::thread::Thread": "ImmutableAsArgument"
      }
    },
    "core::mem::forget": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Takes ownership and \"forgets\" about the value **without running its destructor**.\n\n Any resources the value manages, such as heap memory or a file handle, will linger\n forever in an unreachable state. However, it does not guarantee that pointers\n to this memory will remain valid.\n\n * If you want to leak memory, see [`Box::leak`].\n * If you want to obtain a raw pointer to the memory, see [`Box::into_raw`].\n * If you want to dispose of a value properly, running its destructor, see\n   [`mem::drop`].\n\n # Safety\n\n `forget` is not marked as `unsafe`, because Rust's safety guarantees\n do not include a guarantee that destructors will always run. For example,\n a program can create a reference cycle using [`Rc`][rc], or call\n [`process::exit`][exit] to exit without running destructors. Thus, allowing\n `mem::forget` from safe code does not fundamentally change Rust's safety\n guarantees.\n\n That said, leaking resources such as memory or I/O objects is usually undesirable.\n The need comes up in some specialized use cases for FFI or unsafe code, but even\n then, [`ManuallyDrop`] is typically preferred.\n\n Because forgetting a value is allowed, any `unsafe` code you write must\n allow for this possibility. You cannot return a value and expect that the\n caller will necessarily run the value's destructor.\n\n [rc]: ../../std/rc/struct.Rc.html\n [exit]: ../../std/process/fn.exit.html\n\n # Examples\n\n The canonical safe use of `mem::forget` is to circumvent a value's destructor\n implemented by the `Drop` trait. For example, this will leak a `File`, i.e. reclaim\n the space taken by the variable but never close the underlying system resource:\n\n ```no_run\n use std::mem;\n use std::fs::File;\n\n let file = File::open(\"foo.txt\").unwrap();\n mem::forget(file);\n ```\n\n This is useful when the ownership of the underlying resource was previously\n transferred to code outside of Rust, for example by transmitting the raw\n file descriptor to C code.\n\n # Relationship with `ManuallyDrop`\n\n While `mem::forget` can also be used to transfer *memory* ownership, doing so is error-prone.\n [`ManuallyDrop`] should be used instead. Consider, for example, this code:\n\n ```\n use std::mem;\n\n let mut v = vec![65, 122];\n // Build a `String` using the contents of `v`\n let s = unsafe { String::from_raw_parts(v.as_mut_ptr(), v.len(), v.capacity()) };\n // leak `v` because its memory is now managed by `s`\n mem::forget(v);  // ERROR - v is invalid and must not be passed to a function\n assert_eq!(s, \"Az\");\n // `s` is implicitly dropped and its memory deallocated.\n ```\n\n There are two issues with the above example:\n\n * If more code were added between the construction of `String` and the invocation of\n   `mem::forget()`, a panic within it would cause a double free because the same memory\n   is handled by both `v` and `s`.\n * After calling `v.as_mut_ptr()` and transmitting the ownership of the data to `s`,\n   the `v` value is invalid. Even when a value is just moved to `mem::forget` (which won't\n   inspect it), some types have strict requirements on their values that\n   make them invalid when dangling or no longer owned. Using invalid values in any\n   way, including passing them to or returning them from functions, constitutes\n   undefined behavior and may break the assumptions made by the compiler.\n\n Switching to `ManuallyDrop` avoids both issues:\n\n ```\n use std::mem::ManuallyDrop;\n\n let v = vec![65, 122];\n // Before we disassemble `v` into its raw parts, make sure it\n // does not get dropped!\n let mut v = ManuallyDrop::new(v);\n // Now disassemble `v`. These operations cannot panic, so there cannot be a leak.\n let (ptr, len, cap) = (v.as_mut_ptr(), v.len(), v.capacity());\n // Finally, build a `String`.\n let s = unsafe { String::from_raw_parts(ptr, len, cap) };\n assert_eq!(s, \"Az\");\n // `s` is implicitly dropped and its memory deallocated.\n ```\n\n `ManuallyDrop` robustly prevents double-free because we disable `v`'s destructor\n before doing anything else. `mem::forget()` doesn't allow this because it consumes its\n argument, forcing us to call it only after extracting anything we need from `v`. Even\n if a panic were introduced between construction of `ManuallyDrop` and building the\n string (which cannot happen in the code as shown), it would result in a leak and not a\n double free. In other words, `ManuallyDrop` errs on the side of leaking instead of\n erring on the side of (double-)dropping.\n\n Also, `ManuallyDrop` prevents us from having to \"touch\" `v` after transferring the\n ownership to `s` â€” the final step of interacting with `v` to dispose of it without\n running its destructor is entirely avoided.\n\n [`Box`]: ../../std/boxed/struct.Box.html\n [`Box::leak`]: ../../std/boxed/struct.Box.html#method.leak\n [`Box::into_raw`]: ../../std/boxed/struct.Box.html#method.into_raw\n [`mem::drop`]: drop\n [ub]: ../../reference/behavior-considered-undefined.html\n",
      "adt": {}
    }
  },
  "adts": {
    "thread::thread::Thread": [
      "Plain",
      "Ref"
    ]
  },
  "path": 4461,
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/thread/functions.rs:525:1: 533:2",
  "src": "pub fn park() {\n    let guard = PanicGuard;\n    // SAFETY: park_timeout is called on the parker owned by this thread.\n    unsafe {\n        current().park();\n    }\n    // No panic occurred, do not abort.\n    forget(guard);\n}",
  "mir": "fn thread::functions::park() -> () {\n    let mut _0: ();\n    let  _1: ();\n    let mut _2: &thread::thread::Thread;\n    let  _3: thread::thread::Thread;\n    let  _4: ();\n    debug guard => thread::functions::PanicGuard;\n    bb0: {\n        StorageLive(_2);\n        StorageLive(_3);\n        _3 = thread::current::current() -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        _2 = &_3;\n        _1 = thread::thread::Thread::park(move _2) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_2);\n        drop(_3) -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        StorageDead(_3);\n        _4 = core::mem::forget::<thread::functions::PanicGuard>(thread::functions::PanicGuard) -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        return;\n    }\n}\n",
  "doc": " Blocks unless or until the current thread's token is made available.\n\n A call to `park` does not guarantee that the thread will remain parked\n forever, and callers should be prepared for this possibility. However,\n it is guaranteed that this function will not panic (it may abort the\n process if the implementation encounters some rare errors).\n\n # `park` and `unpark`\n\n Every thread is equipped with some basic low-level blocking support, via the\n [`thread::park`][`park`] function and [`thread::Thread::unpark`][`unpark`]\n method. [`park`] blocks the current thread, which can then be resumed from\n another thread by calling the [`unpark`] method on the blocked thread's\n handle.\n\n Conceptually, each [`Thread`] handle has an associated token, which is\n initially not present:\n\n * The [`thread::park`][`park`] function blocks the current thread unless or\n   until the token is available for its thread handle, at which point it\n   atomically consumes the token. It may also return *spuriously*, without\n   consuming the token. [`thread::park_timeout`] does the same, but allows\n   specifying a maximum time to block the thread for.\n\n * The [`unpark`] method on a [`Thread`] atomically makes the token available\n   if it wasn't already. Because the token can be held by a thread even if it is currently not\n   parked, [`unpark`] followed by [`park`] will result in the second call returning immediately.\n   However, note that to rely on this guarantee, you need to make sure that your `unpark` happens\n   after all `park` that may be done by other data structures!\n\n The API is typically used by acquiring a handle to the current thread, placing that handle in a\n shared data structure so that other threads can find it, and then `park`ing in a loop. When some\n desired condition is met, another thread calls [`unpark`] on the handle. The last bullet point\n above guarantees that even if the `unpark` occurs before the thread is finished `park`ing, it\n will be woken up properly.\n\n Note that the coordination via the shared data structure is crucial: If you `unpark` a thread\n without first establishing that it is about to be `park`ing within your code, that `unpark` may\n get consumed by a *different* `park` in the same thread, leading to a deadlock. This also means\n you must not call unknown code between setting up for parking and calling `park`; for instance,\n if you invoke `println!`, that may itself call `park` and thus consume your `unpark` and cause a\n deadlock.\n\n The motivation for this design is twofold:\n\n * It avoids the need to allocate mutexes and condvars when building new\n   synchronization primitives; the threads already provide basic\n   blocking/signaling.\n\n * It can be implemented very efficiently on many platforms.\n\n # Memory Ordering\n\n Calls to `unpark` _synchronize-with_ calls to `park`, meaning that memory\n operations performed before a call to `unpark` are made visible to the thread that\n consumes the token and returns from `park`. Note that all `park` and `unpark`\n operations for a given thread form a total order and _all_ prior `unpark` operations\n synchronize-with `park`.\n\n In atomic ordering terms, `unpark` performs a `Release` operation and `park`\n performs the corresponding `Acquire` operation. Calls to `unpark` for the same\n thread form a [release sequence].\n\n Note that being unblocked does not imply a call was made to `unpark`, because\n wakeups can also be spurious. For example, a valid, but inefficient,\n implementation could have `park` and `unpark` return immediately without doing anything,\n making *all* wakeups spurious.\n\n # Examples\n\n ```\n use std::thread;\n use std::sync::atomic::{Ordering, AtomicBool};\n use std::time::Duration;\n\n static QUEUED: AtomicBool = AtomicBool::new(false);\n static FLAG: AtomicBool = AtomicBool::new(false);\n\n let parked_thread = thread::spawn(move || {\n     println!(\"Thread spawned\");\n     // Signal that we are going to `park`. Between this store and our `park`, there may\n     // be no other `park`, or else that `park` could consume our `unpark` token!\n     QUEUED.store(true, Ordering::Release);\n     // We want to wait until the flag is set. We *could* just spin, but using\n     // park/unpark is more efficient.\n     while !FLAG.load(Ordering::Acquire) {\n         // We can *not* use `println!` here since that could use thread parking internally.\n         thread::park();\n         // We *could* get here spuriously, i.e., way before the 10ms below are over!\n         // But that is no problem, we are in a loop until the flag is set anyway.\n     }\n     println!(\"Flag received\");\n });\n\n // Let some time pass for the thread to be spawned.\n thread::sleep(Duration::from_millis(10));\n\n // Ensure the thread is about to park.\n // This is crucial! It guarantees that the `unpark` below is not consumed\n // by some other code in the parked thread (e.g. inside `println!`).\n while !QUEUED.load(Ordering::Acquire) {\n     // Spinning is of course inefficient; in practice, this would more likely be\n     // a dequeue where we have no work to do if there's nobody queued.\n     std::hint::spin_loop();\n }\n\n // Set the flag, and let the thread wake up.\n // There is no race condition here: if `unpark`\n // happens first, `park` will return immediately.\n // There is also no other `park` that could consume this token,\n // since we waited until the other thread got queued.\n // Hence there is no risk of a deadlock.\n FLAG.store(true, Ordering::Release);\n println!(\"Unpark the thread\");\n parked_thread.thread().unpark();\n\n parked_thread.join().unwrap();\n ```\n\n [`Thread`]: super::Thread\n [`unpark`]: super::Thread::unpark\n [`thread::park_timeout`]: park_timeout\n [release sequence]: https://en.cppreference.com/w/cpp/atomic/memory_order#Release_sequence\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}