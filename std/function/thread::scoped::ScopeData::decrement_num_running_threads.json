{
  "name": "thread::scoped::ScopeData::decrement_num_running_threads",
  "safe": true,
  "callees": {
    "core::sync::atomic::AtomicBool::store": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Stores a value into the bool.\n\n `store` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. Possible values are [`SeqCst`], [`Release`] and [`Relaxed`].\n\n # Panics\n\n Panics if `order` is [`Acquire`] or [`AcqRel`].\n\n # Examples\n\n ```\n use std::sync::atomic::{AtomicBool, Ordering};\n\n let some_bool = AtomicBool::new(true);\n\n some_bool.store(false, Ordering::Relaxed);\n assert_eq!(some_bool.load(Ordering::Relaxed), false);\n ```\n",
      "adt": {}
    },
    "core::sync::atomic::AtomicUsize::fetch_sub": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Subtracts from the current value, returning the previous value.\n\n This operation wraps around on overflow.\n\n `fetch_sub` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. All ordering modes are possible. Note that using\n [`Acquire`] makes the store part of this operation [`Relaxed`], and\n using [`Release`] makes the load part [`Relaxed`].\n\n **Note**: This method is only available on platforms that support atomic operations on\n\n # Examples\n\n ```\n\n assert_eq!(foo.fetch_sub(10, Ordering::SeqCst), 20);\n assert_eq!(foo.load(Ordering::SeqCst), 10);\n ```\n",
      "adt": {}
    },
    "thread::thread::Thread::unpark": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Atomically makes the handle's token available if it is not already.\n\n Every thread is equipped with some basic low-level blocking support, via\n the [`park`] function and the `unpark()` method. These can be used as a\n more CPU-efficient implementation of a spinlock.\n\n See the [park documentation] for more details.\n\n # Examples\n\n ```\n use std::thread;\n use std::time::Duration;\n use std::sync::atomic::{AtomicBool, Ordering};\n\n static QUEUED: AtomicBool = AtomicBool::new(false);\n\n let parked_thread = thread::Builder::new()\n     .spawn(|| {\n         println!(\"Parking thread\");\n         QUEUED.store(true, Ordering::Release);\n         thread::park();\n         println!(\"Thread unparked\");\n     })\n     .unwrap();\n\n // Let some time pass for the thread to be spawned.\n thread::sleep(Duration::from_millis(10));\n\n // Wait until the other thread is queued.\n // This is crucial! It guarantees that the `unpark` below is not consumed\n // by some other code in the parked thread (e.g. inside `println!`).\n while !QUEUED.load(Ordering::Acquire) {\n     // Spinning is of course inefficient; in practice, this would more likely be\n     // a dequeue where we have no work to do if there's nobody queued.\n     std::hint::spin_loop();\n }\n\n println!(\"Unpark the thread\");\n parked_thread.thread().unpark();\n\n parked_thread.join().unwrap();\n ```\n\n [`park`]: super::park\n [park documentation]: super::park\n",
      "adt": {
        "thread::thread::Thread": "ImmutableAsArgument"
      }
    }
  },
  "adts": {
    "core::sync::atomic::AtomicBool": [
      "Ref"
    ],
    "thread::scoped::ScopeData": [
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(1)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(2)))",
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ],
    "core::sync::atomic::AtomicUsize": [
      "Ref"
    ],
    "thread::thread::Thread": [
      "Ref"
    ]
  },
  "path": 4539,
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/thread/scoped.rs:63:5: 70:6",
  "src": "pub(super) fn decrement_num_running_threads(&self, panic: bool) {\n        if panic {\n            self.a_thread_panicked.store(true, Ordering::Relaxed);\n        }\n        if self.num_running_threads.fetch_sub(1, Ordering::Release) == 1 {\n            self.main_thread.unpark();\n        }\n    }",
  "mir": "fn thread::scoped::ScopeData::decrement_num_running_threads(_1: &thread::scoped::ScopeData, _2: bool) -> () {\n    let mut _0: ();\n    let  _3: ();\n    let mut _4: &core::sync::atomic::AtomicBool;\n    let mut _5: core::sync::atomic::Ordering;\n    let mut _6: usize;\n    let mut _7: &core::sync::atomic::AtomicUsize;\n    let mut _8: core::sync::atomic::Ordering;\n    let  _9: ();\n    let mut _10: &thread::thread::Thread;\n    debug self => _1;\n    debug panic => _2;\n    bb0: {\n        switchInt(_2) -> [0: bb3, otherwise: bb1];\n    }\n    bb1: {\n        StorageLive(_4);\n        _4 = &((*_1).1: core::sync::atomic::AtomicBool);\n        StorageLive(_5);\n        _5 = core::sync::atomic::Ordering::Relaxed;\n        _3 = core::sync::atomic::AtomicBool::store(move _4, true, move _5) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_5);\n        StorageDead(_4);\n        goto -> bb3;\n    }\n    bb3: {\n        StorageLive(_6);\n        StorageLive(_7);\n        _7 = &((*_1).0: core::sync::atomic::AtomicUsize);\n        StorageLive(_8);\n        _8 = core::sync::atomic::Ordering::Release;\n        _6 = core::sync::atomic::AtomicUsize::fetch_sub(move _7, 1_usize, move _8) -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        StorageDead(_8);\n        StorageDead(_7);\n        switchInt(move _6) -> [1: bb5, otherwise: bb7];\n    }\n    bb5: {\n        StorageDead(_6);\n        StorageLive(_10);\n        _10 = &((*_1).2: thread::thread::Thread);\n        _9 = thread::thread::Thread::unpark(move _10) -> [return: bb6, unwind unreachable];\n    }\n    bb6: {\n        StorageDead(_10);\n        goto -> bb8;\n    }\n    bb7: {\n        StorageDead(_6);\n        goto -> bb8;\n    }\n    bb8: {\n        return;\n    }\n}\n",
  "doc": "",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}