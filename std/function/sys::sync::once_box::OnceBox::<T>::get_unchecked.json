{
  "name": "sys::sync::once_box::OnceBox::<T>::get_unchecked",
  "safe": false,
  "callees": {
    "core::sync::atomic::AtomicPtr::<T>::load": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Loads a value from the pointer.\n\n `load` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. Possible values are [`SeqCst`], [`Acquire`] and [`Relaxed`].\n\n # Panics\n\n Panics if `order` is [`Release`] or [`AcqRel`].\n\n # Examples\n\n ```\n use std::sync::atomic::{AtomicPtr, Ordering};\n\n let ptr = &mut 5;\n let some_ptr = AtomicPtr::new(ptr);\n\n let value = some_ptr.load(Ordering::Relaxed);\n ```\n",
      "adt": {}
    },
    "core::pin::Pin::<Ptr>::new_unchecked": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Constructs a new `Pin<Ptr>` around a reference to some data of a type that\n may or may not implement [`Unpin`].\n\n If `pointer` dereferences to an [`Unpin`] type, [`Pin::new`] should be used\n instead.\n\n # Safety\n\n This constructor is unsafe because we cannot guarantee that the data\n pointed to by `pointer` is pinned. At its core, pinning a value means making the\n guarantee that the value's data will not be moved nor have its storage invalidated until\n it gets dropped. For a more thorough explanation of pinning, see the [`pin` module docs].\n\n If the caller that is constructing this `Pin<Ptr>` does not ensure that the data `Ptr`\n points to is pinned, that is a violation of the API contract and may lead to undefined\n behavior in later (even safe) operations.\n\n By using this method, you are also making a promise about the [`Deref`],\n [`DerefMut`], and [`Drop`] implementations of `Ptr`, if they exist. Most importantly, they\n must not move out of their `self` arguments: `Pin::as_mut` and `Pin::as_ref`\n will call `DerefMut::deref_mut` and `Deref::deref` *on the pointer type `Ptr`*\n and expect these methods to uphold the pinning invariants.\n Moreover, by calling this method you promise that the reference `Ptr`\n dereferences to will not be moved out of again; in particular, it\n must not be possible to obtain a `&mut Ptr::Target` and then\n move out of that reference (using, for example [`mem::swap`]).\n\n For example, calling `Pin::new_unchecked` on an `&'a mut T` is unsafe because\n while you are able to pin it for the given lifetime `'a`, you have no control\n over whether it is kept pinned once `'a` ends, and therefore cannot uphold the\n guarantee that a value, once pinned, remains pinned until it is dropped:\n\n ```\n use std::mem;\n use std::pin::Pin;\n\n fn move_pinned_ref<T>(mut a: T, mut b: T) {\n     unsafe {\n         let p: Pin<&mut T> = Pin::new_unchecked(&mut a);\n         // This should mean the pointee `a` can never move again.\n     }\n     mem::swap(&mut a, &mut b); // Potential UB down the road ⚠️\n     // The address of `a` changed to `b`'s stack slot, so `a` got moved even\n     // though we have previously pinned it! We have violated the pinning API contract.\n }\n ```\n A value, once pinned, must remain pinned until it is dropped (unless its type implements\n `Unpin`). Because `Pin<&mut T>` does not own the value, dropping the `Pin` will not drop\n the value and will not end the pinning contract. So moving the value after dropping the\n `Pin<&mut T>` is still a violation of the API contract.\n\n Similarly, calling `Pin::new_unchecked` on an `Rc<T>` is unsafe because there could be\n aliases to the same data that are not subject to the pinning restrictions:\n ```\n use std::rc::Rc;\n use std::pin::Pin;\n\n fn move_pinned_rc<T>(mut x: Rc<T>) {\n     // This should mean the pointee can never move again.\n     let pin = unsafe { Pin::new_unchecked(Rc::clone(&x)) };\n     {\n         let p: Pin<&T> = pin.as_ref();\n         // ...\n     }\n     drop(pin);\n\n     let content = Rc::get_mut(&mut x).unwrap(); // Potential UB down the road ⚠️\n     // Now, if `x` was the only reference, we have a mutable reference to\n     // data that we pinned above, which we could use to move it as we have\n     // seen in the previous example. We have violated the pinning API contract.\n }\n ```\n\n ## Pinning of closure captures\n\n Particular care is required when using `Pin::new_unchecked` in a closure:\n `Pin::new_unchecked(&mut var)` where `var` is a by-value (moved) closure capture\n implicitly makes the promise that the closure itself is pinned, and that *all* uses\n of this closure capture respect that pinning.\n ```\n use std::pin::Pin;\n use std::task::Context;\n use std::future::Future;\n\n fn move_pinned_closure(mut x: impl Future, cx: &mut Context<'_>) {\n     // Create a closure that moves `x`, and then internally uses it in a pinned way.\n     let mut closure = move || unsafe {\n         let _ignore = Pin::new_unchecked(&mut x).poll(cx);\n     };\n     // Call the closure, so the future can assume it has been pinned.\n     closure();\n     // Move the closure somewhere else. This also moves `x`!\n     let mut moved = closure;\n     // Calling it again means we polled the future from two different locations,\n     // violating the pinning API contract.\n     moved(); // Potential UB ⚠️\n }\n ```\n When passing a closure to another API, it might be moving the closure any time, so\n `Pin::new_unchecked` on closure captures may only be used if the API explicitly documents\n that the closure is pinned.\n\n The better alternative is to avoid all that trouble and do the pinning in the outer function\n instead (here using the [`pin!`][crate::pin::pin] macro):\n ```\n use std::pin::pin;\n use std::task::Context;\n use std::future::Future;\n\n fn move_pinned_closure(mut x: impl Future, cx: &mut Context<'_>) {\n     let mut x = pin!(x);\n     // Create a closure that captures `x: Pin<&mut _>`, which is safe to move.\n     let mut closure = move || {\n         let _ignore = x.as_mut().poll(cx);\n     };\n     // Call the closure, so the future can assume it has been pinned.\n     closure();\n     // Move the closure somewhere else.\n     let mut moved = closure;\n     // Calling it again here is fine (except that we might be polling a future that already\n     // returned `Poll::Ready`, but that is a separate problem).\n     moved();\n }\n ```\n\n [`mem::swap`]: crate::mem::swap\n [`pin` module docs]: self\n",
      "adt": {}
    }
  },
  "adts": {
    "core::sync::atomic::AtomicPtr": [
      "Ref"
    ],
    "sys::sync::once_box::OnceBox": [
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ],
    "core::pin::Pin": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "std::sys::sync::once_box::OnceBox::<T>::get_unchecked"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/sys/sync/once_box.rs:42:5: 44:6",
  "src": "pub unsafe fn get_unchecked(&self) -> Pin<&T> {\n        unsafe { Pin::new_unchecked(&*self.ptr.load(Relaxed)) }\n    }",
  "mir": "fn sys::sync::once_box::OnceBox::<T>::get_unchecked(_1: &sys::sync::once_box::OnceBox<T>) -> core::pin::Pin<&T> {\n    let mut _0: core::pin::Pin<&T>;\n    let  _2: &T;\n    let  _3: *mut T;\n    let mut _4: &core::sync::atomic::AtomicPtr<T>;\n    let mut _5: core::sync::atomic::Ordering;\n    let mut _6: *const ();\n    let mut _7: usize;\n    let mut _8: usize;\n    let mut _9: usize;\n    let mut _10: bool;\n    let mut _11: *const ();\n    let mut _12: usize;\n    let mut _13: bool;\n    let mut _14: bool;\n    let mut _15: bool;\n    debug self => _1;\n    bb0: {\n        StorageLive(_3);\n        StorageLive(_4);\n        _4 = &((*_1).0: core::sync::atomic::AtomicPtr<T>);\n        StorageLive(_5);\n        _5 = core::sync::atomic::Ordering::Relaxed;\n        _3 = core::sync::atomic::AtomicPtr::<T>::load(move _4, move _5) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_5);\n        StorageDead(_4);\n        _6 = _3 as *const ();\n        _7 = _6 as usize;\n        _8 = Sub(<T as core::mem::SizedTypeProperties>::ALIGN, 1_usize);\n        _9 = BitAnd(_7, _8);\n        _10 = Eq(_9, 0_usize);\n        assert(_10, \"misaligned pointer dereference: address must be a multiple of {} but is {}\",<T as core::mem::SizedTypeProperties>::ALIGN, _7) -> [success: bb3, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_3);\n        return;\n    }\n    bb3: {\n        _11 = _3 as *const ();\n        _12 = _11 as usize;\n        _13 = Eq(_12, 0_usize);\n        _14 = BitAnd(_13, true);\n        _15 = Not(_14);\n        assert(_15, \"null pointer dereference occurred\") -> [success: bb4, unwind unreachable];\n    }\n    bb4: {\n        _2 = &(*_3);\n        _0 = core::pin::Pin::<&T>::new_unchecked(_2) -> [return: bb2, unwind unreachable];\n    }\n}\n",
  "doc": " Gets access to the value, assuming it is already initialized and this\n initialization has been observed by the current thread.\n\n Since all modifications to the pointer have already been observed, the\n pointer load in this function can be performed with relaxed ordering,\n potentially allowing the optimizer to turn code like this:\n ```rust, ignore\n once_box.get_or_init(|| Box::pin(42));\n unsafe { once_box.get_unchecked() }\n ```\n into\n ```rust, ignore\n once_box.get_or_init(|| Box::pin(42))\n ```\n\n # Safety\n This causes undefined behavior if the assumption above is violated.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}