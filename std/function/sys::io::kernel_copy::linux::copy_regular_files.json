{
  "name": "sys::io::kernel_copy::linux::copy_regular_files",
  "safe": true,
  "callees": {
    "core::sync::atomic::AtomicU8::load": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Loads a value from the atomic integer.\n\n `load` takes an [`Ordering`] argument which describes the memory ordering of this operation.\n Possible values are [`SeqCst`], [`Acquire`] and [`Relaxed`].\n\n # Panics\n\n Panics if `order` is [`Release`] or [`AcqRel`].\n\n # Examples\n\n ```\n\n\n assert_eq!(some_var.load(Ordering::Relaxed), 5);\n ```\n",
      "adt": {}
    },
    "core::cmp::min": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Compares and returns the minimum of two values.\n\n Returns the first argument if the comparison determines them to be equal.\n\n Internally uses an alias to [`Ord::min`].\n\n # Examples\n\n ```\n use std::cmp;\n\n assert_eq!(cmp::min(1, 2), 1);\n assert_eq!(cmp::min(2, 2), 2);\n ```\n ```\n use std::cmp::{self, Ordering};\n\n #[derive(Eq)]\n struct Equal(&'static str);\n\n impl PartialEq for Equal {\n     fn eq(&self, other: &Self) -> bool { true }\n }\n impl PartialOrd for Equal {\n     fn partial_cmp(&self, other: &Self) -> Option<Ordering> { Some(Ordering::Equal) }\n }\n impl Ord for Equal {\n     fn cmp(&self, other: &Self) -> Ordering { Ordering::Equal }\n }\n\n assert_eq!(cmp::min(Equal(\"v1\"), Equal(\"v2\")).0, \"v1\");\n ```\n",
      "adt": {}
    },
    "core::ptr::null_mut": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates a null mutable raw pointer.\n\n This function is equivalent to zero-initializing the pointer:\n `MaybeUninit::<*mut T>::zeroed().assume_init()`.\n The resulting pointer has the address 0.\n\n # Examples\n\n ```\n use std::ptr;\n\n let p: *mut i32 = ptr::null_mut();\n assert!(p.is_null());\n assert_eq!(p as usize, 0); // this pointer has the address 0\n ```\n",
      "adt": {}
    },
    "sys::io::kernel_copy::linux::copy_regular_files::copy_file_range": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {}
    },
    "sys::pal::unix::cvt": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Converts native return values to Result using the *-1 means error is in `errno`*  convention.\n Non-error values are `Ok`-wrapped.\n",
      "adt": {
        "core::result::Result": "Constructor",
        "io::error::Error": "Constructor"
      }
    },
    "core::result::Result::<T, E>::is_ok": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns `true` if the result is [`Ok`].\n\n # Examples\n\n ```\n let x: Result<i32, &str> = Ok(-3);\n assert_eq!(x.is_ok(), true);\n\n let x: Result<i32, &str> = Err(\"Some error message\");\n assert_eq!(x.is_ok(), false);\n ```\n",
      "adt": {}
    },
    "core::sync::atomic::AtomicU8::store": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Stores a value into the atomic integer.\n\n `store` takes an [`Ordering`] argument which describes the memory ordering of this operation.\n  Possible values are [`SeqCst`], [`Release`] and [`Relaxed`].\n\n # Panics\n\n Panics if `order` is [`Acquire`] or [`AcqRel`].\n\n # Examples\n\n ```\n\n\n some_var.store(10, Ordering::Relaxed);\n assert_eq!(some_var.load(Ordering::Relaxed), 10);\n ```\n",
      "adt": {}
    },
    "io::error::Error::raw_os_error": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the OS error that this error represents (if any).\n\n If this [`Error`] was constructed via [`last_os_error`] or\n [`from_raw_os_error`], then this function will return [`Some`], otherwise\n it will return [`None`].\n\n [`last_os_error`]: Error::last_os_error\n [`from_raw_os_error`]: Error::from_raw_os_error\n\n # Examples\n\n ```\n use std::io::{Error, ErrorKind};\n\n fn print_os_error(err: &Error) {\n     if let Some(raw_os_err) = err.raw_os_error() {\n         println!(\"raw OS error: {raw_os_err:?}\");\n     } else {\n         println!(\"Not an OS error\");\n     }\n }\n\n fn main() {\n     // Will print \"raw OS error: ...\".\n     print_os_error(&Error::last_os_error());\n     // Will print \"Not an OS error\".\n     print_os_error(&Error::new(ErrorKind::Other, \"oh no!\"));\n }\n ```\n",
      "adt": {
        "io::error::Error": "ImmutableAsArgument",
        "core::option::Option": "Constructor"
      }
    },
    "sys::io::kernel_copy::linux::copy_regular_files::probe_copy_file_range_support": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {}
    }
  },
  "adts": {
    "core::sync::atomic::AtomicU8": [
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ],
    "sys::io::kernel_copy::linux::CopyResult": [
      "Plain"
    ],
    "core::result::Result": [
      "Plain",
      "Ref",
      "Unknown([Downcast(VariantIdx(0, ThreadLocalIndex)), Field(0, Ty { id: 12, kind: RigidTy(Int(Isize)) })])",
      "Unknown([Downcast(VariantIdx(1, ThreadLocalIndex)), Field(0, Ty { id: 20, kind: RigidTy(Adt(AdtDef(DefId { id: 4564, name: \"io::error::Error\" }), GenericArgs([]))) })])"
    ],
    "io::error::Error": [
      "Plain",
      "Ref"
    ],
    "core::option::Option": [
      "Plain",
      "Unknown([Downcast(VariantIdx(1, ThreadLocalIndex)), Field(0, Ty { id: 44, kind: RigidTy(Int(I32)) })])"
    ]
  },
  "path": {
    "type": "Local",
    "path": "std::sys::io::kernel_copy::linux::copy_regular_files"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/sys/io/kernel_copy/linux.rs:593:1: 716:2",
  "src": "fn copy_regular_files(reader: RawFd, writer: RawFd, max_len: u64) -> CopyResult {\n    use crate::cmp;\n\n    const NOT_PROBED: u8 = 0;\n    const UNAVAILABLE: u8 = 1;\n    const AVAILABLE: u8 = 2;\n\n    // Kernel prior to 4.5 don't have copy_file_range\n    // We store the availability in a global to avoid unnecessary syscalls\n    static HAS_COPY_FILE_RANGE: Atomic<u8> = AtomicU8::new(NOT_PROBED);\n\n    let mut have_probed = match HAS_COPY_FILE_RANGE.load(Ordering::Relaxed) {\n        NOT_PROBED => false,\n        UNAVAILABLE => return CopyResult::Fallback(0),\n        _ => true,\n    };\n\n    syscall!(\n        fn copy_file_range(\n            fd_in: libc::c_int,\n            off_in: *mut libc::loff_t,\n            fd_out: libc::c_int,\n            off_out: *mut libc::loff_t,\n            len: libc::size_t,\n            flags: libc::c_uint,\n        ) -> libc::ssize_t;\n    );\n\n    fn probe_copy_file_range_support() -> u8 {\n        // In some cases, we cannot determine availability from the first\n        // `copy_file_range` call. In this case, we probe with an invalid file\n        // descriptor so that the results are easily interpretable.\n        match unsafe {\n            cvt(copy_file_range(INVALID_FD, ptr::null_mut(), INVALID_FD, ptr::null_mut(), 1, 0))\n                .map_err(|e| e.raw_os_error())\n        } {\n            Err(Some(EPERM | ENOSYS)) => UNAVAILABLE,\n            Err(Some(EBADF)) => AVAILABLE,\n            Ok(_) => panic!(\"unexpected copy_file_range probe success\"),\n            // Treat other errors as the syscall\n            // being unavailable.\n            Err(_) => UNAVAILABLE,\n        }\n    }\n\n    let mut written = 0u64;\n    while written < max_len {\n        let bytes_to_copy = cmp::min(max_len - written, usize::MAX as u64);\n        // cap to 1GB chunks in case u64::MAX is passed as max_len and the file has a non-zero seek position\n        // this allows us to copy large chunks without hitting EOVERFLOW,\n        // unless someone sets a file offset close to u64::MAX - 1GB, in which case a fallback would be required\n        let bytes_to_copy = cmp::min(bytes_to_copy as usize, 0x4000_0000usize);\n        let copy_result = unsafe {\n            // We actually don't have to adjust the offsets,\n            // because copy_file_range adjusts the file offset automatically\n            cvt(copy_file_range(reader, ptr::null_mut(), writer, ptr::null_mut(), bytes_to_copy, 0))\n        };\n\n        if !have_probed && copy_result.is_ok() {\n            have_probed = true;\n            HAS_COPY_FILE_RANGE.store(AVAILABLE, Ordering::Relaxed);\n        }\n\n        match copy_result {\n            Ok(0) if written == 0 => {\n                // fallback to work around several kernel bugs where copy_file_range will fail to\n                // copy any bytes and return 0 instead of an error if\n                // - reading virtual files from the proc filesystem which appear to have 0 size\n                //   but are not empty. noted in coreutils to affect kernels at least up to 5.6.19.\n                // - copying from an overlay filesystem in docker. reported to occur on fedora 32.\n                return CopyResult::Fallback(0);\n            }\n            Ok(0) => return CopyResult::Ended(written), // reached EOF\n            Ok(ret) => written += ret as u64,\n            Err(err) => {\n                return match err.raw_os_error() {\n                    // when file offset + max_length > u64::MAX\n                    Some(EOVERFLOW) => CopyResult::Fallback(written),\n                    Some(raw_os_error @ (ENOSYS | EXDEV | EINVAL | EPERM | EOPNOTSUPP | EBADF))\n                        if written == 0 =>\n                    {\n                        if !have_probed {\n                            let available = if matches!(raw_os_error, ENOSYS | EOPNOTSUPP | EPERM) {\n                                // EPERM can indicate seccomp filters or an\n                                // immutable file. To distinguish these\n                                // cases we probe with invalid file\n                                // descriptors which should result in EBADF\n                                // if the syscall is supported and EPERM or\n                                // ENOSYS if it's not available.\n                                //\n                                // For EOPNOTSUPP, see below. In the case of\n                                // ENOSYS, we try to cover for faulty FUSE\n                                // drivers.\n                                probe_copy_file_range_support()\n                            } else {\n                                AVAILABLE\n                            };\n                            HAS_COPY_FILE_RANGE.store(available, Ordering::Relaxed);\n                        }\n\n                        // Try fallback io::copy if either:\n                        // - Kernel version is < 4.5 (ENOSYS¹)\n                        // - Files are mounted on different fs (EXDEV)\n                        // - copy_file_range is broken in various ways on RHEL/CentOS 7 (EOPNOTSUPP)\n                        // - copy_file_range file is immutable or syscall is blocked by seccomp¹ (EPERM)\n                        // - copy_file_range cannot be used with pipes or device nodes (EINVAL)\n                        // - the writer fd was opened with O_APPEND (EBADF²)\n                        // and no bytes were written successfully yet. (All these errnos should\n                        // not be returned if something was already written, but they happen in\n                        // the wild, see #91152.)\n                        //\n                        // ¹ these cases should be detected by the initial probe but we handle them here\n                        //   anyway in case syscall interception changes during runtime\n                        // ² actually invalid file descriptors would cause this too, but in that case\n                        //   the fallback code path is expected to encounter the same error again\n                        CopyResult::Fallback(0)\n                    }\n                    _ => CopyResult::Error(err, written),\n                };\n            }\n        }\n    }\n    CopyResult::Ended(written)\n}",
  "mir": "fn sys::io::kernel_copy::linux::copy_regular_files(_1: i32, _2: i32, _3: u64) -> sys::io::kernel_copy::linux::CopyResult {\n    let mut _0: sys::io::kernel_copy::linux::CopyResult;\n    let mut _4: bool;\n    let mut _5: u8;\n    let mut _6: &core::sync::atomic::AtomicU8;\n    let mut _7: core::sync::atomic::Ordering;\n    let mut _8: u64;\n    let mut _9: bool;\n    let mut _10: u64;\n    let  _11: u64;\n    let mut _12: u64;\n    let mut _13: u64;\n    let mut _14: (u64, bool);\n    let mut _15: u64;\n    let  _16: usize;\n    let mut _17: usize;\n    let  _18: core::result::Result<isize, io::error::Error>;\n    let mut _19: isize;\n    let mut _20: *mut i64;\n    let mut _21: *mut i64;\n    let mut _22: bool;\n    let mut _23: bool;\n    let mut _24: &core::result::Result<isize, io::error::Error>;\n    let  _25: ();\n    let mut _26: &core::sync::atomic::AtomicU8;\n    let mut _27: core::sync::atomic::Ordering;\n    let mut _28: isize;\n    let mut _29: u64;\n    let mut _30: u64;\n    let  _31: isize;\n    let mut _32: u64;\n    let mut _33: (u64, bool);\n    let  _34: io::error::Error;\n    let mut _35: core::option::Option<i32>;\n    let mut _36: &io::error::Error;\n    let mut _37: isize;\n    let mut _38: u64;\n    let  _39: i32;\n    let  _40: &i32;\n    let mut _41: u64;\n    let mut _42: u64;\n    let mut _43: u64;\n    let mut _44: u64;\n    let mut _45: u64;\n    let mut _46: u64;\n    let mut _47: bool;\n    let  _48: u8;\n    let mut _49: bool;\n    let  _50: ();\n    let mut _51: &core::sync::atomic::AtomicU8;\n    let mut _52: u8;\n    let mut _53: core::sync::atomic::Ordering;\n    let mut _54: io::error::Error;\n    let mut _55: u64;\n    let mut _56: u64;\n    let mut _57: bool;\n    debug reader => _1;\n    debug writer => _2;\n    debug max_len => _3;\n    debug have_probed => _4;\n    debug written => _8;\n    debug bytes_to_copy => _11;\n    debug bytes_to_copy => _16;\n    debug copy_result => _18;\n    debug ret => _31;\n    debug err => _34;\n    debug raw_os_error => _39;\n    debug raw_os_error => _40;\n    debug available => _48;\n    bb0: {\n        _57 = false;\n        StorageLive(_4);\n        StorageLive(_5);\n        StorageLive(_6);\n        _6 = {alloc421: &core::sync::atomic::AtomicU8};\n        StorageLive(_7);\n        _7 = core::sync::atomic::Ordering::Relaxed;\n        _5 = core::sync::atomic::AtomicU8::load(move _6, move _7) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_7);\n        StorageDead(_6);\n        switchInt(_5) -> [0: bb4, 1: bb3, otherwise: bb2];\n    }\n    bb2: {\n        _4 = true;\n        goto -> bb5;\n    }\n    bb3: {\n        _0 = sys::io::kernel_copy::linux::CopyResult::Fallback(0_u64);\n        StorageDead(_5);\n        goto -> bb64;\n    }\n    bb4: {\n        _4 = false;\n        goto -> bb5;\n    }\n    bb5: {\n        StorageDead(_5);\n        StorageLive(_8);\n        _8 = 0_u64;\n        goto -> bb6;\n    }\n    bb6: {\n        StorageLive(_9);\n        StorageLive(_10);\n        _10 = _8;\n        _9 = Lt(move _10, _3);\n        switchInt(move _9) -> [0: bb61, otherwise: bb7];\n    }\n    bb7: {\n        StorageDead(_10);\n        StorageLive(_12);\n        StorageLive(_13);\n        _13 = _8;\n        _14 = CheckedSub(_3, _13);\n        assert(!move (_14.1: bool), \"attempt to compute `{} - {}`, which would overflow\", _3, move _13) -> [success: bb8, unwind unreachable];\n    }\n    bb8: {\n        _12 = move (_14.0: u64);\n        StorageDead(_13);\n        StorageLive(_15);\n        _15 = core::num::<impl usize>::MAX as u64;\n        _11 = core::cmp::min::<u64>(move _12, move _15) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_15);\n        StorageDead(_12);\n        StorageLive(_17);\n        _17 = _11 as usize;\n        _16 = core::cmp::min::<usize>(move _17, 1073741824_usize) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        StorageDead(_17);\n        StorageLive(_18);\n        StorageLive(_19);\n        StorageLive(_20);\n        _20 = core::ptr::null_mut::<i64>() -> [return: bb11, unwind unreachable];\n    }\n    bb11: {\n        StorageLive(_21);\n        _21 = core::ptr::null_mut::<i64>() -> [return: bb12, unwind unreachable];\n    }\n    bb12: {\n        _19 = sys::io::kernel_copy::linux::copy_regular_files::copy_file_range(_1, move _20, _2, move _21, _16, 0_u32) -> [return: bb13, unwind unreachable];\n    }\n    bb13: {\n        StorageDead(_21);\n        StorageDead(_20);\n        _18 = sys::pal::unix::cvt::<isize>(move _19) -> [return: bb14, unwind unreachable];\n    }\n    bb14: {\n        StorageDead(_19);\n        StorageLive(_22);\n        _22 = _4;\n        switchInt(move _22) -> [0: bb15, otherwise: bb20];\n    }\n    bb15: {\n        StorageLive(_23);\n        StorageLive(_24);\n        _24 = &_18;\n        _23 = core::result::Result::<isize, io::error::Error>::is_ok(move _24) -> [return: bb16, unwind unreachable];\n    }\n    bb16: {\n        switchInt(move _23) -> [0: bb19, otherwise: bb17];\n    }\n    bb17: {\n        StorageDead(_24);\n        _4 = true;\n        StorageLive(_26);\n        _26 = {alloc421: &core::sync::atomic::AtomicU8};\n        StorageLive(_27);\n        _27 = core::sync::atomic::Ordering::Relaxed;\n        _25 = core::sync::atomic::AtomicU8::store(move _26, sys::io::kernel_copy::linux::copy_regular_files::AVAILABLE, move _27) -> [return: bb18, unwind unreachable];\n    }\n    bb18: {\n        StorageDead(_27);\n        StorageDead(_26);\n        goto -> bb20;\n    }\n    bb19: {\n        StorageDead(_24);\n        goto -> bb20;\n    }\n    bb20: {\n        StorageDead(_23);\n        StorageDead(_22);\n        _28 = discriminant(_18);\n        switchInt(move _28) -> [0: bb22, 1: bb23, otherwise: bb21];\n    }\n    bb21: {\n        unreachable;\n    }\n    bb22: {\n        switchInt(((_18 as variant#0).0: isize)) -> [0: bb25, otherwise: bb24];\n    }\n    bb23: {\n        StorageLive(_34);\n        _57 = true;\n        _34 = move ((_18 as variant#1).0: io::error::Error);\n        StorageLive(_35);\n        StorageLive(_36);\n        _36 = &_34;\n        _35 = io::error::Error::raw_os_error(move _36) -> [return: bb29, unwind unreachable];\n    }\n    bb24: {\n        _31 = ((_18 as variant#0).0: isize);\n        StorageLive(_32);\n        _32 = _31 as u64;\n        _33 = CheckedAdd(_8, _32);\n        assert(!move (_33.1: bool), \"attempt to compute `{} + {}`, which would overflow\", _8, move _32) -> [success: bb28, unwind unreachable];\n    }\n    bb25: {\n        StorageLive(_29);\n        _29 = _8;\n        switchInt(move _29) -> [0: bb26, otherwise: bb27];\n    }\n    bb26: {\n        StorageDead(_29);\n        _0 = sys::io::kernel_copy::linux::CopyResult::Fallback(0_u64);\n        goto -> bb67;\n    }\n    bb27: {\n        StorageDead(_29);\n        StorageLive(_30);\n        _30 = _8;\n        _0 = sys::io::kernel_copy::linux::CopyResult::Ended(move _30);\n        StorageDead(_30);\n        goto -> bb67;\n    }\n    bb28: {\n        _8 = move (_33.0: u64);\n        StorageDead(_32);\n        StorageDead(_18);\n        StorageDead(_9);\n        goto -> bb6;\n    }\n    bb29: {\n        StorageDead(_36);\n        _37 = discriminant(_35);\n        switchInt(move _37) -> [1: bb31, 0: bb30, otherwise: bb21];\n    }\n    bb30: {\n        StorageLive(_54);\n        _57 = false;\n        _54 = move _34;\n        StorageLive(_55);\n        _55 = _8;\n        _0 = sys::io::kernel_copy::linux::CopyResult::Error(move _54, move _55);\n        StorageDead(_55);\n        StorageDead(_54);\n        goto -> bb62;\n    }\n    bb31: {\n        switchInt(((_35 as variant#1).0: i32)) -> [75: bb38, 38: bb37, 18: bb36, 22: bb35, 1: bb34, 95: bb33, 9: bb32, otherwise: bb30];\n    }\n    bb32: {\n        StorageLive(_40);\n        _40 = &((_35 as variant#1).0: i32);\n        StorageLive(_41);\n        _41 = _8;\n        switchInt(move _41) -> [0: bb40, otherwise: bb41];\n    }\n    bb33: {\n        StorageLive(_40);\n        _40 = &((_35 as variant#1).0: i32);\n        StorageLive(_42);\n        _42 = _8;\n        switchInt(move _42) -> [0: bb42, otherwise: bb43];\n    }\n    bb34: {\n        StorageLive(_40);\n        _40 = &((_35 as variant#1).0: i32);\n        StorageLive(_43);\n        _43 = _8;\n        switchInt(move _43) -> [0: bb44, otherwise: bb45];\n    }\n    bb35: {\n        StorageLive(_40);\n        _40 = &((_35 as variant#1).0: i32);\n        StorageLive(_44);\n        _44 = _8;\n        switchInt(move _44) -> [0: bb46, otherwise: bb47];\n    }\n    bb36: {\n        StorageLive(_40);\n        _40 = &((_35 as variant#1).0: i32);\n        StorageLive(_45);\n        _45 = _8;\n        switchInt(move _45) -> [0: bb48, otherwise: bb49];\n    }\n    bb37: {\n        StorageLive(_40);\n        _40 = &((_35 as variant#1).0: i32);\n        StorageLive(_46);\n        _46 = _8;\n        switchInt(move _46) -> [0: bb50, otherwise: bb51];\n    }\n    bb38: {\n        StorageLive(_38);\n        _38 = _8;\n        _0 = sys::io::kernel_copy::linux::CopyResult::Fallback(move _38);\n        StorageDead(_38);\n        goto -> bb62;\n    }\n    bb39: {\n        StorageLive(_47);\n        _47 = _4;\n        switchInt(move _47) -> [0: bb52, otherwise: bb60];\n    }\n    bb40: {\n        StorageDead(_41);\n        StorageLive(_39);\n        _39 = ((_35 as variant#1).0: i32);\n        goto -> bb39;\n    }\n    bb41: {\n        StorageDead(_41);\n        StorageDead(_40);\n        goto -> bb30;\n    }\n    bb42: {\n        StorageDead(_42);\n        StorageLive(_39);\n        _39 = ((_35 as variant#1).0: i32);\n        goto -> bb39;\n    }\n    bb43: {\n        StorageDead(_42);\n        StorageDead(_40);\n        goto -> bb30;\n    }\n    bb44: {\n        StorageDead(_43);\n        StorageLive(_39);\n        _39 = ((_35 as variant#1).0: i32);\n        goto -> bb39;\n    }\n    bb45: {\n        StorageDead(_43);\n        StorageDead(_40);\n        goto -> bb30;\n    }\n    bb46: {\n        StorageDead(_44);\n        StorageLive(_39);\n        _39 = ((_35 as variant#1).0: i32);\n        goto -> bb39;\n    }\n    bb47: {\n        StorageDead(_44);\n        StorageDead(_40);\n        goto -> bb30;\n    }\n    bb48: {\n        StorageDead(_45);\n        StorageLive(_39);\n        _39 = ((_35 as variant#1).0: i32);\n        goto -> bb39;\n    }\n    bb49: {\n        StorageDead(_45);\n        StorageDead(_40);\n        goto -> bb30;\n    }\n    bb50: {\n        StorageDead(_46);\n        StorageLive(_39);\n        _39 = ((_35 as variant#1).0: i32);\n        goto -> bb39;\n    }\n    bb51: {\n        StorageDead(_46);\n        StorageDead(_40);\n        goto -> bb30;\n    }\n    bb52: {\n        StorageLive(_48);\n        StorageLive(_49);\n        switchInt(_39) -> [38: bb54, 95: bb54, 1: bb54, otherwise: bb53];\n    }\n    bb53: {\n        _49 = false;\n        goto -> bb55;\n    }\n    bb54: {\n        _49 = true;\n        goto -> bb55;\n    }\n    bb55: {\n        switchInt(move _49) -> [0: bb57, otherwise: bb56];\n    }\n    bb56: {\n        _48 = sys::io::kernel_copy::linux::copy_regular_files::probe_copy_file_range_support() -> [return: bb58, unwind unreachable];\n    }\n    bb57: {\n        _48 = sys::io::kernel_copy::linux::copy_regular_files::AVAILABLE;\n        goto -> bb58;\n    }\n    bb58: {\n        StorageDead(_49);\n        StorageLive(_51);\n        _51 = {alloc421: &core::sync::atomic::AtomicU8};\n        StorageLive(_52);\n        _52 = _48;\n        StorageLive(_53);\n        _53 = core::sync::atomic::Ordering::Relaxed;\n        _50 = core::sync::atomic::AtomicU8::store(move _51, move _52, move _53) -> [return: bb59, unwind unreachable];\n    }\n    bb59: {\n        StorageDead(_53);\n        StorageDead(_52);\n        StorageDead(_51);\n        StorageDead(_48);\n        goto -> bb60;\n    }\n    bb60: {\n        StorageDead(_47);\n        _0 = sys::io::kernel_copy::linux::CopyResult::Fallback(0_u64);\n        StorageDead(_39);\n        StorageDead(_40);\n        goto -> bb62;\n    }\n    bb61: {\n        StorageDead(_10);\n        StorageDead(_9);\n        StorageLive(_56);\n        _56 = _8;\n        _0 = sys::io::kernel_copy::linux::CopyResult::Ended(move _56);\n        StorageDead(_56);\n        StorageDead(_8);\n        StorageDead(_4);\n        goto -> bb65;\n    }\n    bb62: {\n        StorageDead(_35);\n        switchInt(_57) -> [0: bb63, otherwise: bb66];\n    }\n    bb63: {\n        _57 = false;\n        StorageDead(_34);\n        goto -> bb67;\n    }\n    bb64: {\n        StorageDead(_4);\n        goto -> bb65;\n    }\n    bb65: {\n        return;\n    }\n    bb66: {\n        drop(_34) -> [return: bb63, unwind unreachable];\n    }\n    bb67: {\n        StorageDead(_18);\n        StorageDead(_9);\n        StorageDead(_8);\n        goto -> bb64;\n    }\n}\n",
  "doc": " Linux-specific implementation that will attempt to use copy_file_range for copy offloading.\n As the name says, it only works on regular files.\n\n Callers must handle fallback to a generic copy loop.\n `Fallback` may indicate non-zero number of bytes already written\n if one of the files' cursor +`max_len` would exceed u64::MAX (`EOVERFLOW`).\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}