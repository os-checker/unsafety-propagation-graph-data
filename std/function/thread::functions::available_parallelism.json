{
  "name": "thread::functions::available_parallelism",
  "safe": true,
  "callees": {
    "sys::thread::unix::available_parallelism": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "core::result::Result": "Constructor"
      }
    }
  },
  "adts": {
    "core::result::Result": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "std::thread::functions::available_parallelism"
  },
  "span": "/home/gh-zjp-CN/.rustup/toolchains/nightly-2025-12-06-aarch64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/thread/functions.rs:690:1: 692:2",
  "src": "pub fn available_parallelism() -> io::Result<NonZero<usize>> {\n    imp::available_parallelism()\n}",
  "mir": "fn thread::functions::available_parallelism() -> core::result::Result<core::num::NonZero<usize>, io::error::Error> {\n    let mut _0: core::result::Result<core::num::NonZero<usize>, io::error::Error>;\n    bb0: {\n        _0 = sys::thread::unix::available_parallelism() -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        return;\n    }\n}\n",
  "doc": " Returns an estimate of the default amount of parallelism a program should use.\n\n Parallelism is a resource. A given machine provides a certain capacity for\n parallelism, i.e., a bound on the number of computations it can perform\n simultaneously. This number often corresponds to the amount of CPUs a\n computer has, but it may diverge in various cases.\n\n Host environments such as VMs or container orchestrators may want to\n restrict the amount of parallelism made available to programs in them. This\n is often done to limit the potential impact of (unintentionally)\n resource-intensive programs on other programs running on the same machine.\n\n # Limitations\n\n The purpose of this API is to provide an easy and portable way to query\n the default amount of parallelism the program should use. Among other things it\n does not expose information on NUMA regions, does not account for\n differences in (co)processor capabilities or current system load,\n and will not modify the program's global state in order to more accurately\n query the amount of available parallelism.\n\n Where both fixed steady-state and burst limits are available the steady-state\n capacity will be used to ensure more predictable latencies.\n\n Resource limits can be changed during the runtime of a program, therefore the value is\n not cached and instead recomputed every time this function is called. It should not be\n called from hot code.\n\n The value returned by this function should be considered a simplified\n approximation of the actual amount of parallelism available at any given\n time. To get a more detailed or precise overview of the amount of\n parallelism available to the program, you may wish to use\n platform-specific APIs as well. The following platform limitations currently\n apply to `available_parallelism`:\n\n On Windows:\n - It may undercount the amount of parallelism available on systems with more\n   than 64 logical CPUs. However, programs typically need specific support to\n   take advantage of more than 64 logical CPUs, and in the absence of such\n   support, the number returned by this function accurately reflects the\n   number of logical CPUs the program can use by default.\n - It may overcount the amount of parallelism available on systems limited by\n   process-wide affinity masks, or job object limitations.\n\n On Linux:\n - It may overcount the amount of parallelism available when limited by a\n   process-wide affinity mask or cgroup quotas and `sched_getaffinity()` or cgroup fs can't be\n   queried, e.g. due to sandboxing.\n - It may undercount the amount of parallelism if the current thread's affinity mask\n   does not reflect the process' cpuset, e.g. due to pinned threads.\n - If the process is in a cgroup v1 cpu controller, this may need to\n   scan mountpoints to find the corresponding cgroup v1 controller,\n   which may take time on systems with large numbers of mountpoints.\n   (This does not apply to cgroup v2, or to processes not in a\n   cgroup.)\n - It does not attempt to take `ulimit` into account. If there is a limit set on the number of\n   threads, `available_parallelism` cannot know how much of that limit a Rust program should\n   take, or know in a reliable and race-free way how much of that limit is already taken.\n\n On all targets:\n - It may overcount the amount of parallelism available when running in a VM\n with CPU usage limits (e.g. an overcommitted host).\n\n # Errors\n\n This function will, but is not limited to, return errors in the following\n cases:\n\n - If the amount of parallelism is not known for the target platform.\n - If the program lacks permission to query the amount of parallelism made\n   available to it.\n\n # Examples\n\n ```\n # #![allow(dead_code)]\n use std::{io, thread};\n\n fn main() -> io::Result<()> {\n     let count = thread::available_parallelism()?.get();\n     assert!(count >= 1_usize);\n     Ok(())\n }\n ```\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}