{
  "name": "std::sync::mpmc::list::Channel::<T>::discard_all_messages",
  "span": "$library/std/src/sync/mpmc/list.rs:542:5: 542:35",
  "src": "fn discard_all_messages(&self) {\n        let backoff = Backoff::new();\n        let mut tail = self.tail.index.load(Ordering::Acquire);\n        loop {\n            let offset = (tail >> SHIFT) % LAP;\n            if offset != BLOCK_CAP {\n                break;\n            }\n\n            // New updates to tail will be rejected by MARK_BIT and aborted unless it's\n            // at boundary. We need to wait for the updates take affect otherwise there\n            // can be memory leaks.\n            backoff.spin_heavy();\n            tail = self.tail.index.load(Ordering::Acquire);\n        }\n\n        let mut head = self.head.index.load(Ordering::Acquire);\n        // The channel may be uninitialized, so we have to swap to avoid overwriting any sender's attempts\n        // to initialize the first block before noticing that the receivers disconnected. Late allocations\n        // will be deallocated by the sender in Drop.\n        let mut block = self.head.block.swap(ptr::null_mut(), Ordering::AcqRel);\n\n        // If we're going to be dropping messages we need to synchronize with initialization\n        if head >> SHIFT != tail >> SHIFT {\n            // The block can be null here only if a sender is in the process of initializing the\n            // channel while another sender managed to send a message by inserting it into the\n            // semi-initialized channel and advanced the tail.\n            // In that case, just wait until it gets initialized.\n            while block.is_null() {\n                backoff.spin_heavy();\n                block = self.head.block.swap(ptr::null_mut(), Ordering::AcqRel);\n            }\n        }\n        // After this point `head.block` is not modified again and it will be deallocated if it's\n        // non-null. The `Drop` code of the channel, which runs after this function, also attempts\n        // to deallocate `head.block` if it's non-null. Therefore this function must maintain the\n        // invariant that if a deallocation of head.block is attempted then it must also be set to\n        // NULL. Failing to do so will lead to the Drop code attempting a double free. For this\n        // reason both reads above do an atomic swap instead of a simple atomic load.\n\n        unsafe {\n            // Drop all messages between head and tail and deallocate the heap-allocated blocks.\n            while head >> SHIFT != tail >> SHIFT {\n                let offset = (head >> SHIFT) % LAP;\n\n                if offset < BLOCK_CAP {\n                    // Drop the message in the slot.\n                    let slot = (*block).slots.get_unchecked(offset);\n                    slot.wait_write();\n                    let p = &mut *slot.msg.get();\n                    p.as_mut_ptr().drop_in_place();\n                } else {\n                    (*block).wait_next();\n                    // Deallocate the block and move to the next one.\n                    let next = (*block).next.load(Ordering::Acquire);\n                    drop(Box::from_raw(block));\n                    block = next;\n                }\n\n                head = head.wrapping_add(1 << SHIFT);\n            }\n\n            // Deallocate the last remaining block.\n            if !block.is_null() {\n                drop(Box::from_raw(block));\n            }\n        }\n\n        head &= !MARK_BIT;\n        self.head.index.store(head, Ordering::Release);\n    }"
}