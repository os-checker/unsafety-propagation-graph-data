{
  "name": "collections::hash::set::HashSet",
  "constructors": [
    "collections::hash::set::HashSet::<T>::new",
    "collections::hash::set::HashSet::<T>::with_capacity",
    "collections::hash::set::HashSet::<T, S>::with_hasher",
    "collections::hash::set::HashSet::<T, S>::with_capacity_and_hasher",
    "<collections::hash::set::HashSet<T, S> as core::clone::Clone>::clone",
    "<collections::hash::set::HashSet<T, S> as core::iter::FromIterator<T>>::from_iter",
    "<collections::hash::set::HashSet<T> as core::convert::From<[T; N]>>::from",
    "<collections::hash::set::HashSet<T, S> as core::default::Default>::default",
    "<&collections::hash::set::HashSet<T, S> as core::ops::BitOr<&collections::hash::set::HashSet<T, S>>>::bitor",
    "<&collections::hash::set::HashSet<T, S> as core::ops::BitAnd<&collections::hash::set::HashSet<T, S>>>::bitand",
    "<&collections::hash::set::HashSet<T, S> as core::ops::BitXor<&collections::hash::set::HashSet<T, S>>>::bitxor",
    "<&collections::hash::set::HashSet<T, S> as core::ops::Sub<&collections::hash::set::HashSet<T, S>>>::sub",
    "collections::hash::set::assert_covariance::set"
  ],
  "access_self_as_arg": {
    "read": [
      "collections::hash::set::HashSet::<T, S>::capacity",
      "collections::hash::set::HashSet::<T, S>::iter",
      "collections::hash::set::HashSet::<T, S>::len",
      "collections::hash::set::HashSet::<T, S>::is_empty",
      "collections::hash::set::HashSet::<T, S>::hasher",
      "collections::hash::set::HashSet::<T, S>::difference",
      "collections::hash::set::HashSet::<T, S>::symmetric_difference",
      "collections::hash::set::HashSet::<T, S>::intersection",
      "collections::hash::set::HashSet::<T, S>::union",
      "collections::hash::set::HashSet::<T, S>::contains",
      "collections::hash::set::HashSet::<T, S>::get",
      "collections::hash::set::HashSet::<T, S>::is_disjoint",
      "collections::hash::set::HashSet::<T, S>::is_subset",
      "collections::hash::set::HashSet::<T, S>::is_superset",
      "<collections::hash::set::HashSet<T, S> as core::clone::Clone>::clone",
      "<collections::hash::set::HashSet<T, S> as core::clone::Clone>::clone_from",
      "<collections::hash::set::HashSet<T, S> as core::cmp::PartialEq>::eq",
      "<collections::hash::set::HashSet<T, S> as core::fmt::Debug>::fmt",
      "<&collections::hash::set::HashSet<T, S> as core::ops::BitOr<&collections::hash::set::HashSet<T, S>>>::bitor",
      "<&collections::hash::set::HashSet<T, S> as core::ops::BitAnd<&collections::hash::set::HashSet<T, S>>>::bitand",
      "<&collections::hash::set::HashSet<T, S> as core::ops::BitXor<&collections::hash::set::HashSet<T, S>>>::bitxor",
      "<&collections::hash::set::HashSet<T, S> as core::ops::Sub<&collections::hash::set::HashSet<T, S>>>::sub",
      "<&'a collections::hash::set::HashSet<T, S> as core::iter::IntoIterator>::into_iter"
    ],
    "write": [
      "collections::hash::set::HashSet::<T, S>::drain",
      "collections::hash::set::HashSet::<T, S>::extract_if",
      "collections::hash::set::HashSet::<T, S>::retain",
      "collections::hash::set::HashSet::<T, S>::clear",
      "collections::hash::set::HashSet::<T, S>::reserve",
      "collections::hash::set::HashSet::<T, S>::try_reserve",
      "collections::hash::set::HashSet::<T, S>::shrink_to_fit",
      "collections::hash::set::HashSet::<T, S>::shrink_to",
      "collections::hash::set::HashSet::<T, S>::get_or_insert",
      "collections::hash::set::HashSet::<T, S>::get_or_insert_with",
      "collections::hash::set::HashSet::<T, S>::entry",
      "collections::hash::set::HashSet::<T, S>::insert",
      "collections::hash::set::HashSet::<T, S>::replace",
      "collections::hash::set::HashSet::<T, S>::remove",
      "collections::hash::set::HashSet::<T, S>::take",
      "<collections::hash::set::HashSet<T, S> as core::clone::Clone>::clone_from",
      "<collections::hash::set::HashSet<T, S> as core::iter::Extend<T>>::extend",
      "<collections::hash::set::HashSet<T, S> as core::iter::Extend<T>>::extend_one",
      "<collections::hash::set::HashSet<T, S> as core::iter::Extend<T>>::extend_reserve",
      "<collections::hash::set::HashSet<T, S> as core::iter::Extend<&'a T>>::extend",
      "<collections::hash::set::HashSet<T, S> as core::iter::Extend<&'a T>>::extend_one",
      "<collections::hash::set::HashSet<T, S> as core::iter::Extend<&'a T>>::extend_reserve"
    ],
    "other": [
      "<collections::hash::set::HashSet<T, S> as core::clone::Clone>::clone",
      "<&collections::hash::set::HashSet<T, S> as core::ops::BitOr<&collections::hash::set::HashSet<T, S>>>::bitor",
      "<&collections::hash::set::HashSet<T, S> as core::ops::BitAnd<&collections::hash::set::HashSet<T, S>>>::bitand",
      "<&collections::hash::set::HashSet<T, S> as core::ops::BitXor<&collections::hash::set::HashSet<T, S>>>::bitxor",
      "<&collections::hash::set::HashSet<T, S> as core::ops::Sub<&collections::hash::set::HashSet<T, S>>>::sub",
      "<collections::hash::set::HashSet<T, S> as core::iter::IntoIterator>::into_iter",
      "collections::hash::set::assert_covariance::set",
      "<collections::hash::set::HashSet<T, S> as core::iter::IntoIterator>::into_iter"
    ]
  },
  "access_self_as_locals": {
    "read": [
      "<collections::hash::set::Intersection<'a, T, S> as core::iter::Iterator>::next",
      "<collections::hash::set::Intersection<'a, T, S> as core::iter::Iterator>::fold",
      "<collections::hash::set::Difference<'a, T, S> as core::iter::Iterator>::next",
      "<collections::hash::set::Difference<'a, T, S> as core::iter::Iterator>::fold"
    ],
    "write": [
      "<collections::hash::set::HashSet<T, S> as core::iter::FromIterator<T>>::from_iter"
    ],
    "other": [
      "collections::hash::set::HashSet::<T>::new",
      "collections::hash::set::HashSet::<T>::with_capacity",
      "collections::hash::set::HashSet::<T, S>::with_hasher",
      "collections::hash::set::HashSet::<T, S>::with_capacity_and_hasher",
      "<collections::hash::set::HashSet<T, S> as core::iter::FromIterator<T>>::from_iter",
      "<collections::hash::set::HashSet<T> as core::convert::From<[T; N]>>::from",
      "<collections::hash::set::HashSet<T, S> as core::default::Default>::default"
    ]
  },
  "access_field": [
    {
      "read": [
        "collections::hash::set::HashSet::<T, S>::capacity",
        "collections::hash::set::HashSet::<T, S>::iter",
        "collections::hash::set::HashSet::<T, S>::len",
        "collections::hash::set::HashSet::<T, S>::is_empty",
        "collections::hash::set::HashSet::<T, S>::hasher",
        "collections::hash::set::HashSet::<T, S>::contains",
        "collections::hash::set::HashSet::<T, S>::get",
        "<collections::hash::set::HashSet<T, S> as core::clone::Clone>::clone",
        "<collections::hash::set::HashSet<T, S> as core::clone::Clone>::clone_from"
      ],
      "write": [
        "collections::hash::set::HashSet::<T, S>::drain",
        "collections::hash::set::HashSet::<T, S>::extract_if",
        "collections::hash::set::HashSet::<T, S>::retain",
        "collections::hash::set::HashSet::<T, S>::clear",
        "collections::hash::set::HashSet::<T, S>::reserve",
        "collections::hash::set::HashSet::<T, S>::try_reserve",
        "collections::hash::set::HashSet::<T, S>::shrink_to_fit",
        "collections::hash::set::HashSet::<T, S>::shrink_to",
        "collections::hash::set::HashSet::<T, S>::get_or_insert",
        "collections::hash::set::HashSet::<T, S>::get_or_insert_with",
        "collections::hash::set::HashSet::<T, S>::entry",
        "collections::hash::set::HashSet::<T, S>::insert",
        "collections::hash::set::HashSet::<T, S>::replace",
        "collections::hash::set::HashSet::<T, S>::remove",
        "collections::hash::set::HashSet::<T, S>::take",
        "<collections::hash::set::HashSet<T, S> as core::clone::Clone>::clone_from",
        "<collections::hash::set::HashSet<T, S> as core::iter::Extend<T>>::extend",
        "<collections::hash::set::HashSet<T, S> as core::iter::Extend<T>>::extend_one",
        "<collections::hash::set::HashSet<T, S> as core::iter::Extend<T>>::extend_reserve",
        "<collections::hash::set::HashSet<T, S> as core::iter::Extend<&'a T>>::extend_one"
      ],
      "other": []
    }
  ],
  "span": "$library/std/src/collections/hash/set.rs:125:1: 125:39",
  "src": "pub struct HashSet<T, S = RandomState>",
  "kind": "Struct",
  "doc_adt": " A [hash set] implemented as a `HashMap` where the value is `()`.\n\n As with the [`HashMap`] type, a `HashSet` requires that the elements\n implement the [`Eq`] and [`Hash`] traits. This can frequently be achieved by\n using `#[derive(PartialEq, Eq, Hash)]`. If you implement these yourself,\n it is important that the following property holds:\n\n ```text\n k1 == k2 -> hash(k1) == hash(k2)\n ```\n\n In other words, if two keys are equal, their hashes must be equal.\n Violating this property is a logic error.\n\n It is also a logic error for a key to be modified in such a way that the key's\n hash, as determined by the [`Hash`] trait, or its equality, as determined by\n the [`Eq`] trait, changes while it is in the map. This is normally only\n possible through [`Cell`], [`RefCell`], global state, I/O, or unsafe code.\n\n The behavior resulting from either logic error is not specified, but will\n be encapsulated to the `HashSet` that observed the logic error and not\n result in undefined behavior. This could include panics, incorrect results,\n aborts, memory leaks, and non-termination.\n\n # Examples\n\n ```\n use std::collections::HashSet;\n // Type inference lets us omit an explicit type signature (which\n // would be `HashSet<String>` in this example).\n let mut books = HashSet::new();\n\n // Add some books.\n books.insert(\"A Dance With Dragons\".to_string());\n books.insert(\"To Kill a Mockingbird\".to_string());\n books.insert(\"The Odyssey\".to_string());\n books.insert(\"The Great Gatsby\".to_string());\n\n // Check for a specific one.\n if !books.contains(\"The Winds of Winter\") {\n     println!(\"We have {} books, but The Winds of Winter ain't one.\",\n              books.len());\n }\n\n // Remove a book.\n books.remove(\"The Odyssey\");\n\n // Iterate over everything.\n for book in &books {\n     println!(\"{book}\");\n }\n ```\n\n The easiest way to use `HashSet` with a custom type is to derive\n [`Eq`] and [`Hash`]. We must also derive [`PartialEq`],\n which is required if [`Eq`] is derived.\n\n ```\n use std::collections::HashSet;\n #[derive(Hash, Eq, PartialEq, Debug)]\n struct Viking {\n     name: String,\n     power: usize,\n }\n\n let mut vikings = HashSet::new();\n\n vikings.insert(Viking { name: \"Einar\".to_string(), power: 9 });\n vikings.insert(Viking { name: \"Einar\".to_string(), power: 9 });\n vikings.insert(Viking { name: \"Olaf\".to_string(), power: 4 });\n vikings.insert(Viking { name: \"Harald\".to_string(), power: 8 });\n\n // Use derived implementation to print the vikings.\n for x in &vikings {\n     println!(\"{x:?}\");\n }\n ```\n\n A `HashSet` with a known list of items can be initialized from an array:\n\n ```\n use std::collections::HashSet;\n\n let viking_names = HashSet::from([\"Einar\", \"Olaf\", \"Harald\"]);\n ```\n\n [hash set]: crate::collections#use-the-set-variant-of-any-of-these-maps-when\n [`HashMap`]: crate::collections::HashMap\n [`RefCell`]: crate::cell::RefCell\n [`Cell`]: crate::cell::Cell\n\n # Usage in `const` and `static`\n\n Like `HashMap`, `HashSet` is randomly seeded: each `HashSet` instance uses a different seed,\n which means that `HashSet::new` cannot be used in const context. To construct a `HashSet` in the\n initializer of a `const` or `static` item, you will have to use a different hasher that does not\n involve a random seed, as demonstrated in the following example. **A `HashSet` constructed this\n way is not resistant against HashDoS!**\n\n ```rust\n use std::collections::HashSet;\n use std::hash::{BuildHasherDefault, DefaultHasher};\n use std::sync::Mutex;\n\n const EMPTY_SET: HashSet<String, BuildHasherDefault<DefaultHasher>> =\n     HashSet::with_hasher(BuildHasherDefault::new());\n static SET: Mutex<HashSet<String, BuildHasherDefault<DefaultHasher>>> =\n     Mutex::new(HashSet::with_hasher(BuildHasherDefault::new()));\n ```\n",
  "variant_fields": {
    "VariantIdx(None)-FieldIdx(Some(0))": {
      "name": "base",
      "doc": ""
    }
  }
}