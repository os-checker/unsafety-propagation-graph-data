{
  "name": "std::sync::mpmc::list::Channel::<T>::start_recv",
  "span": "$library/std/src/sync/mpmc/list.rs:284:5: 284:52",
  "src": "fn start_recv(&self, token: &mut Token) -> bool {\n        let backoff = Backoff::new();\n        let mut head = self.head.index.load(Ordering::Acquire);\n        let mut block = self.head.block.load(Ordering::Acquire);\n\n        loop {\n            // Calculate the offset of the index into the block.\n            let offset = (head >> SHIFT) % LAP;\n\n            // If we reached the end of the block, wait until the next one is installed.\n            if offset == BLOCK_CAP {\n                backoff.spin_heavy();\n                head = self.head.index.load(Ordering::Acquire);\n                block = self.head.block.load(Ordering::Acquire);\n                continue;\n            }\n\n            let mut new_head = head + (1 << SHIFT);\n\n            if new_head & MARK_BIT == 0 {\n                atomic::fence(Ordering::SeqCst);\n                let tail = self.tail.index.load(Ordering::Relaxed);\n\n                // If the tail equals the head, that means the channel is empty.\n                if head >> SHIFT == tail >> SHIFT {\n                    // If the channel is disconnected...\n                    if tail & MARK_BIT != 0 {\n                        // ...then receive an error.\n                        token.list.block = ptr::null();\n                        return true;\n                    } else {\n                        // Otherwise, the receive operation is not ready.\n                        return false;\n                    }\n                }\n\n                // If head and tail are not in the same block, set `MARK_BIT` in head.\n                if (head >> SHIFT) / LAP != (tail >> SHIFT) / LAP {\n                    new_head |= MARK_BIT;\n                }\n            }\n\n            // The block can be null here only if the first message is being sent into the channel.\n            // In that case, just wait until it gets initialized.\n            if block.is_null() {\n                backoff.spin_heavy();\n                head = self.head.index.load(Ordering::Acquire);\n                block = self.head.block.load(Ordering::Acquire);\n                continue;\n            }\n\n            // Try moving the head index forward.\n            match self.head.index.compare_exchange_weak(\n                head,\n                new_head,\n                Ordering::SeqCst,\n                Ordering::Acquire,\n            ) {\n                Ok(_) => unsafe {\n                    // If we've reached the end of the block, move to the next one.\n                    if offset + 1 == BLOCK_CAP {\n                        let next = (*block).wait_next();\n                        let mut next_index = (new_head & !MARK_BIT).wrapping_add(1 << SHIFT);\n                        if !(*next).next.load(Ordering::Relaxed).is_null() {\n                            next_index |= MARK_BIT;\n                        }\n\n                        self.head.block.store(next, Ordering::Release);\n                        self.head.index.store(next_index, Ordering::Release);\n                    }\n\n                    token.list.block = block as *const u8;\n                    token.list.offset = offset;\n                    return true;\n                },\n                Err(_) => {\n                    backoff.spin_light();\n                    head = self.head.index.load(Ordering::Acquire);\n                    block = self.head.block.load(Ordering::Acquire);\n                }\n            }\n        }\n    }"
}