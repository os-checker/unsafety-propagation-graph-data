{
  "name": "task::processor::after_switching_to",
  "safe": false,
  "callees": {
    "cpu::local::cell::CpuLocalCell::<T>::load": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Gets the value of the per-CPU object in a single instruction.\n\n Note that this memory operation will not be elided or reordered by the\n compiler since it is a black-box.\n",
      "adt": {
        "cpu::local::cell::CpuLocalCell": "MutableAsArgument"
      }
    },
    "core::ptr::const_ptr::<impl *const T>::is_null": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "\n # Examples\n\n ```\n let s: &str = \"Follow the rabbit\";\n let ptr: *const u8 = s.as_ptr();\n assert!(!ptr.is_null());\n ```\n",
      "adt": {}
    },
    "core::ptr::null": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates a null raw pointer.\n\n This function is equivalent to zero-initializing the pointer:\n `MaybeUninit::<*const T>::zeroed().assume_init()`.\n The resulting pointer has the address 0.\n\n # Examples\n\n ```\n use std::ptr;\n\n let p: *const i32 = ptr::null();\n assert!(p.is_null());\n assert_eq!(p as usize, 0); // this pointer has the address 0\n ```\n",
      "adt": {}
    },
    "cpu::local::cell::CpuLocalCell::<T>::store": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Writes a value to the per-CPU object in a single instruction.\n\n Note that this memory operation will not be elided or reordered by the\n compiler since it is a black-box.\n",
      "adt": {
        "cpu::local::cell::CpuLocalCell": "MutableAsArgument"
      }
    },
    "alloc::sync::Arc::<T>::from_raw": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Constructs an `Arc<T>` from a raw pointer.\n\n The raw pointer must have been previously returned by a call to\n [`Arc<U>::into_raw`][into_raw] with the following requirements:\n\n * If `U` is sized, it must have the same size and alignment as `T`. This\n   is trivially true if `U` is `T`.\n * If `U` is unsized, its data pointer must have the same size and\n   alignment as `T`. This is trivially true if `Arc<U>` was constructed\n   through `Arc<T>` and then converted to `Arc<U>` through an [unsized\n   coercion].\n\n Note that if `U` or `U`'s data pointer is not `T` but has the same size\n and alignment, this is basically like transmuting references of\n different types. See [`mem::transmute`][transmute] for more information\n on what restrictions apply in this case.\n\n The raw pointer must point to a block of memory allocated by the global allocator.\n\n The user of `from_raw` has to make sure a specific value of `T` is only\n dropped once.\n\n This function is unsafe because improper use may lead to memory unsafety,\n even if the returned `Arc<T>` is never accessed.\n\n [into_raw]: Arc::into_raw\n [transmute]: core::mem::transmute\n [unsized coercion]: https://doc.rust-lang.org/reference/type-coercions.html#unsized-coercions\n\n # Examples\n\n ```\n use std::sync::Arc;\n\n let x = Arc::new(\"hello\".to_owned());\n let x_ptr = Arc::into_raw(x);\n\n unsafe {\n     // Convert back to an `Arc` to prevent leak.\n     let x = Arc::from_raw(x_ptr);\n     assert_eq!(&*x, \"hello\");\n\n     // Further calls to `Arc::from_raw(x_ptr)` would be memory-unsafe.\n }\n\n // The memory was freed when `x` went out of scope above, so `x_ptr` is now dangling!\n ```\n\n Convert a slice back into its original array:\n\n ```\n use std::sync::Arc;\n\n let x: Arc<[u32]> = Arc::new([1, 2, 3]);\n let x_ptr: *const [u32] = Arc::into_raw(x);\n\n unsafe {\n     let x: Arc<[u32; 3]> = Arc::from_raw(x_ptr.cast::<[u32; 3]>());\n     assert_eq!(&*x, &[1, 2, 3]);\n }\n ```\n",
      "adt": {}
    },
    "core::ops::Deref::deref": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Dereferences the value.\n",
      "adt": {}
    },
    "core::sync::atomic::AtomicBool::store": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Stores a value into the bool.\n\n `store` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. Possible values are [`SeqCst`], [`Release`] and [`Relaxed`].\n\n # Panics\n\n Panics if `order` is [`Acquire`] or [`AcqRel`].\n\n # Examples\n\n ```\n use std::sync::atomic::{AtomicBool, Ordering};\n\n let some_bool = AtomicBool::new(true);\n\n some_bool.store(false, Ordering::Relaxed);\n assert_eq!(some_bool.load(Ordering::Relaxed), false);\n ```\n",
      "adt": {}
    },
    "spin::once::Once::<T, R>::get": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns a reference to the inner value if the [`Once`] has been initialized.\n",
      "adt": {}
    },
    "arch::irq::ops::enable_local": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {}
    },
    "core::mem::drop": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Disposes of a value.\n\n This effectively does nothing for types which implement `Copy`, e.g.\n integers. Such values are copied and _then_ moved into the function, so the\n value persists after this function call.\n\n This function is not magic; it is literally defined as\n\n ```\n pub fn drop<T>(_x: T) {}\n ```\n\n Because `_x` is moved into the function, it is automatically [dropped][drop] before\n the function returns.\n\n [drop]: Drop\n\n # Examples\n\n Basic usage:\n\n ```\n let v = vec![1, 2, 3];\n\n drop(v); // explicitly drop the vector\n ```\n\n Since [`RefCell`] enforces the borrow rules at runtime, `drop` can\n release a [`RefCell`] borrow:\n\n ```\n use std::cell::RefCell;\n\n let x = RefCell::new(1);\n\n let mut mutable_borrow = x.borrow_mut();\n *mutable_borrow = 1;\n\n drop(mutable_borrow); // relinquish the mutable borrow on this slot\n\n let borrow = x.borrow();\n println!(\"{}\", *borrow);\n ```\n\n Integers and other types implementing [`Copy`] are unaffected by `drop`.\n\n ```\n # #![allow(dropping_copy_types)]\n #[derive(Copy, Clone)]\n struct Foo(u8);\n\n let x = 1;\n let y = Foo(2);\n drop(x); // a copy of `x` is moved and dropped\n drop(y); // a copy of `y` is moved and dropped\n\n println!(\"x: {}, y: {}\", x, y.0); // still available\n ```\n\n [`RefCell`]: crate::cell::RefCell\n",
      "adt": {}
    }
  },
  "adts": {
    "cpu::local::cell::CpuLocalCell": [
      "Ref"
    ],
    "core::option::Option": [
      "Plain",
      "Unknown([Downcast(VariantIdx(1, ThreadLocalIndex)), Field(0, Ty { id: 3121, kind: RigidTy(Ref(Region { kind: ReErased }, Ty { id: 3120, kind: RigidTy(FnPtr(Binder { value: FnSig { inputs_and_output: [Ty { id: 107, kind: RigidTy(Tuple([])) }], c_variadic: false, safety: Safe, abi: Rust }, bound_vars: [] })) }, Not)) })])"
    ],
    "alloc::sync::Arc": [
      "Plain",
      "Ref"
    ],
    "task::Task": [
      "Ref",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(5)))"
    ],
    "core::sync::atomic::AtomicBool": [
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ],
    "spin::once::Once": [
      "Ref"
    ]
  },
  "path": {
    "type": "Local",
    "path": "ostd::task::processor::after_switching_to"
  },
  "span": "ostd/src/task/processor.rs:119:1: 149:2",
  "src": "pub(super) unsafe fn after_switching_to() {\n    // Release the previous task.\n    let prev = PREVIOUS_TASK_PTR.load();\n    let prev = if !prev.is_null() {\n        PREVIOUS_TASK_PTR.store(core::ptr::null());\n\n        // SAFETY: The pointer is set by `switch_to_task` and is guaranteed to\n        // be built with `Arc::into_raw`. We couldn't do it twice since we set\n        // it to NULL after the read.\n        let prev_task = unsafe { Arc::from_raw(prev) };\n\n        // Allows it to be switched on a CPU again, if anyone wants to.\n        prev_task.switched_to_cpu.store(false, Ordering::Release);\n\n        Some(prev_task)\n    } else {\n        None\n    };\n\n    if let Some(handler) = POST_SCHEDULE_HANDLER.get() {\n        handler();\n    }\n\n    // See `switch_to_task`, where we forgot an IRQ guard.\n    crate::arch::irq::enable_local();\n\n    // It was forgotten using `Arc::into_raw` at `switch_to_task`.\n    // We drop it after enabling the IRQ in case dropping user-provided\n    // resources would violate the atomic mode.\n    drop(prev);\n}",
  "mir": "fn task::processor::after_switching_to() -> () {\n    let mut _0: ();\n    let  _1: *const task::Task;\n    let mut _2: &cpu::local::cell::CpuLocalCell<*const task::Task>;\n    let  _3: core::option::Option<alloc::sync::Arc<task::Task>>;\n    let mut _4: bool;\n    let  _5: ();\n    let mut _6: &cpu::local::cell::CpuLocalCell<*const task::Task>;\n    let mut _7: *const task::Task;\n    let  _8: alloc::sync::Arc<task::Task>;\n    let  _9: ();\n    let mut _10: &core::sync::atomic::AtomicBool;\n    let  _11: &task::Task;\n    let mut _12: &alloc::sync::Arc<task::Task>;\n    let mut _13: core::sync::atomic::Ordering;\n    let mut _14: core::option::Option<&fn()>;\n    let mut _15: &spin::once::Once<fn()>;\n    let mut _16: isize;\n    let  _17: &fn();\n    let  _18: ();\n    let mut _19: fn();\n    let  _20: ();\n    let  _21: ();\n    let mut _22: core::option::Option<alloc::sync::Arc<task::Task>>;\n    debug prev => _1;\n    debug prev => _3;\n    debug prev_task => _8;\n    debug handler => _17;\n    bb0: {\n        StorageLive(_2);\n        _2 = {alloc1522: &cpu::local::cell::CpuLocalCell<*const task::Task>};\n        _1 = cpu::local::cell::CpuLocalCell::<*const task::Task>::load(move _2) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_2);\n        StorageLive(_3);\n        StorageLive(_4);\n        _4 = core::ptr::const_ptr::<impl *const task::Task>::is_null(_1) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        switchInt(move _4) -> [0: bb4, otherwise: bb3];\n    }\n    bb3: {\n        _3 = core::option::Option::None;\n        goto -> bb10;\n    }\n    bb4: {\n        StorageLive(_6);\n        _6 = {alloc1522: &cpu::local::cell::CpuLocalCell<*const task::Task>};\n        StorageLive(_7);\n        _7 = core::ptr::null::<task::Task>() -> [return: bb5, unwind unreachable];\n    }\n    bb5: {\n        _5 = cpu::local::cell::CpuLocalCell::<*const task::Task>::store(move _6, move _7) -> [return: bb6, unwind unreachable];\n    }\n    bb6: {\n        StorageDead(_7);\n        StorageDead(_6);\n        _8 = alloc::sync::Arc::<task::Task>::from_raw(_1) -> [return: bb7, unwind unreachable];\n    }\n    bb7: {\n        StorageLive(_10);\n        StorageLive(_11);\n        StorageLive(_12);\n        _12 = &_8;\n        _11 = <alloc::sync::Arc<task::Task> as core::ops::Deref>::deref(move _12) -> [return: bb8, unwind unreachable];\n    }\n    bb8: {\n        StorageDead(_12);\n        _10 = &((*_11).5: core::sync::atomic::AtomicBool);\n        StorageLive(_13);\n        _13 = core::sync::atomic::Ordering::Release;\n        _9 = core::sync::atomic::AtomicBool::store(move _10, false, move _13) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_13);\n        StorageDead(_10);\n        StorageDead(_11);\n        _3 = core::option::Option::Some(_8);\n        goto -> bb10;\n    }\n    bb10: {\n        StorageDead(_4);\n        StorageLive(_14);\n        StorageLive(_15);\n        _15 = {alloc1546: &spin::once::Once<fn()>};\n        _14 = spin::once::Once::<fn()>::get(move _15) -> [return: bb11, unwind unreachable];\n    }\n    bb11: {\n        StorageDead(_15);\n        _16 = discriminant(_14);\n        switchInt(move _16) -> [1: bb12, 0: bb14, otherwise: bb18];\n    }\n    bb12: {\n        StorageLive(_17);\n        _17 = ((_14 as variant#1).0: &fn());\n        StorageLive(_19);\n        _19 = (*_17);\n        _18 = move _19() -> [return: bb13, unwind unreachable];\n    }\n    bb13: {\n        StorageDead(_19);\n        StorageDead(_17);\n        StorageDead(_14);\n        goto -> bb15;\n    }\n    bb14: {\n        StorageDead(_14);\n        goto -> bb15;\n    }\n    bb15: {\n        _20 = arch::irq::ops::enable_local() -> [return: bb16, unwind unreachable];\n    }\n    bb16: {\n        StorageLive(_22);\n        _22 = move _3;\n        _21 = core::mem::drop::<core::option::Option<alloc::sync::Arc<task::Task>>>(move _22) -> [return: bb17, unwind unreachable];\n    }\n    bb17: {\n        StorageDead(_22);\n        StorageDead(_3);\n        return;\n    }\n    bb18: {\n        unreachable;\n    }\n}\n",
  "doc": " Does cleanups after switching to a task.\n\n # Safety\n\n This function must be called only once after switching to a task.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}