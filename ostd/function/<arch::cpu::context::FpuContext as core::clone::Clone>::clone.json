{
  "name": "<arch::cpu::context::FpuContext as core::clone::Clone>::clone",
  "safe": true,
  "callees": {
    "arch::cpu::context::XSaveArea::new": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "arch::cpu::context::XSaveArea": "Constructor"
      }
    },
    "alloc::boxed::Box::<T>::new": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Allocates memory on the heap and then places `x` into it.\n\n This doesn't actually allocate if `T` is zero-sized.\n\n # Examples\n\n ```\n let five = Box::new(5);\n ```\n",
      "adt": {}
    },
    "core::mem::size_of": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the size of a type in bytes.\n\n More specifically, this is the offset in bytes between successive elements\n in an array with that item type including alignment padding. Thus, for any\n type `T` and length `n`, `[T; n]` has a size of `n * size_of::<T>()`.\n\n In general, the size of a type is not stable across compilations, but\n specific types such as primitives are.\n\n The following table gives the size for primitives.\n\n Type | `size_of::<Type>()`\n ---- | ---------------\n () | 0\n bool | 1\n u8 | 1\n u16 | 2\n u32 | 4\n u64 | 8\n u128 | 16\n i8 | 1\n i16 | 2\n i32 | 4\n i64 | 8\n i128 | 16\n f32 | 4\n f64 | 8\n char | 4\n\n Furthermore, `usize` and `isize` have the same size.\n\n The types [`*const T`], `&T`, [`Box<T>`], [`Option<&T>`], and `Option<Box<T>>` all have\n the same size. If `T` is `Sized`, all of those types have the same size as `usize`.\n\n The mutability of a pointer does not change its size. As such, `&T` and `&mut T`\n have the same size. Likewise for `*const T` and `*mut T`.\n\n # Size of `#[repr(C)]` items\n\n The `C` representation for items has a defined layout. With this layout,\n the size of items is also stable as long as all fields have a stable size.\n\n ## Size of Structs\n\n For `struct`s, the size is determined by the following algorithm.\n\n For each field in the struct ordered by declaration order:\n\n 1. Add the size of the field.\n 2. Round up the current size to the nearest multiple of the next field's [alignment].\n\n Finally, round the size of the struct to the nearest multiple of its [alignment].\n The alignment of the struct is usually the largest alignment of all its\n fields; this can be changed with the use of `repr(align(N))`.\n\n Unlike `C`, zero sized structs are not rounded up to one byte in size.\n\n ## Size of Enums\n\n Enums that carry no data other than the discriminant have the same size as C enums\n on the platform they are compiled for.\n\n ## Size of Unions\n\n The size of a union is the size of its largest field.\n\n Unlike `C`, zero sized unions are not rounded up to one byte in size.\n\n # Examples\n\n ```\n // Some primitives\n assert_eq!(4, size_of::<i32>());\n assert_eq!(8, size_of::<f64>());\n assert_eq!(0, size_of::<()>());\n\n // Some arrays\n assert_eq!(8, size_of::<[i32; 2]>());\n assert_eq!(12, size_of::<[i32; 3]>());\n assert_eq!(0, size_of::<[i32; 0]>());\n\n\n // Pointer size equality\n assert_eq!(size_of::<&i32>(), size_of::<*const i32>());\n assert_eq!(size_of::<&i32>(), size_of::<Box<i32>>());\n assert_eq!(size_of::<&i32>(), size_of::<Option<&i32>>());\n assert_eq!(size_of::<Box<i32>>(), size_of::<Option<Box<i32>>>());\n ```\n\n Using `#[repr(C)]`.\n\n ```\n #[repr(C)]\n struct FieldStruct {\n     first: u8,\n     second: u16,\n     third: u8\n }\n\n // The size of the first field is 1, so add 1 to the size. Size is 1.\n // The alignment of the second field is 2, so add 1 to the size for padding. Size is 2.\n // The size of the second field is 2, so add 2 to the size. Size is 4.\n // The alignment of the third field is 1, so add 0 to the size for padding. Size is 4.\n // The size of the third field is 1, so add 1 to the size. Size is 5.\n // Finally, the alignment of the struct is 2 (because the largest alignment amongst its\n // fields is 2), so add 1 to the size for padding. Size is 6.\n assert_eq!(6, size_of::<FieldStruct>());\n\n #[repr(C)]\n struct TupleStruct(u8, u16, u8);\n\n // Tuple structs follow the same rules.\n assert_eq!(6, size_of::<TupleStruct>());\n\n // Note that reordering the fields can lower the size. We can remove both padding bytes\n // by putting `third` before `second`.\n #[repr(C)]\n struct FieldStructOptimized {\n     first: u8,\n     third: u8,\n     second: u16\n }\n\n assert_eq!(4, size_of::<FieldStructOptimized>());\n\n // Union size is the size of the largest field.\n #[repr(C)]\n union ExampleUnion {\n     smaller: u8,\n     larger: u16\n }\n\n assert_eq!(2, size_of::<ExampleUnion>());\n ```\n\n [alignment]: align_of\n [`*const T`]: primitive@pointer\n [`Box<T>`]: ../../std/boxed/struct.Box.html\n [`Option<&T>`]: crate::option::Option\n\n",
      "adt": {}
    },
    "core::ops::IndexMut::index_mut": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Performs the mutable indexing (`container[index]`) operation.\n\n # Panics\n\n May panic if the index is out of bounds.\n",
      "adt": {}
    },
    "core::ops::Index::index": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Performs the indexing (`container[index]`) operation.\n\n # Panics\n\n May panic if the index is out of bounds.\n",
      "adt": {}
    },
    "core::slice::<impl [T]>::copy_from_slice": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Copies all elements from `src` into `self`, using a memcpy.\n\n The length of `src` must be the same as `self`.\n\n If `T` does not implement `Copy`, use [`clone_from_slice`].\n\n # Panics\n\n This function will panic if the two slices have different lengths.\n\n # Examples\n\n Copying two elements from a slice into another:\n\n ```\n let src = [1, 2, 3, 4];\n let mut dst = [0, 0];\n\n // Because the slices have to be the same length,\n // we slice the source slice from four elements\n // to two. It will panic if we don't do this.\n dst.copy_from_slice(&src[2..]);\n\n assert_eq!(src, [1, 2, 3, 4]);\n assert_eq!(dst, [3, 4]);\n ```\n\n Rust enforces that there can only be one mutable reference with no\n immutable references to a particular piece of data in a particular\n scope. Because of this, attempting to use `copy_from_slice` on a\n single slice will result in a compile failure:\n\n ```compile_fail\n let mut slice = [1, 2, 3, 4, 5];\n\n slice[..2].copy_from_slice(&slice[3..]); // compile fail!\n ```\n\n To work around this, we can use [`split_at_mut`] to create two distinct\n sub-slices from a slice:\n\n ```\n let mut slice = [1, 2, 3, 4, 5];\n\n {\n     let (left, right) = slice.split_at_mut(2);\n     left.copy_from_slice(&right[1..]);\n }\n\n assert_eq!(slice, [4, 5, 3, 4, 5]);\n ```\n\n [`clone_from_slice`]: slice::clone_from_slice\n [`split_at_mut`]: slice::split_at_mut\n",
      "adt": {}
    }
  },
  "adts": {
    "arch::cpu::context::XSaveArea": [
      "Plain"
    ],
    "alloc::boxed::Box": [
      "Plain",
      "Unknown([Field(0, Ty { id: 722, kind: RigidTy(Adt(AdtDef(DefId { id: 3281, name: \"core::ptr::Unique\" }), GenericArgs([Type(Ty { id: 654, kind: RigidTy(Adt(AdtDef(DefId { id: 3235, name: \"arch::cpu::context::XSaveArea\" }), GenericArgs([]))) })]))) }), Field(0, Ty { id: 723, kind: RigidTy(Adt(AdtDef(DefId { id: 3282, name: \"core::ptr::NonNull\" }), GenericArgs([Type(Ty { id: 654, kind: RigidTy(Adt(AdtDef(DefId { id: 3235, name: \"arch::cpu::context::XSaveArea\" }), GenericArgs([]))) })]))) })])"
    ],
    "arch::cpu::context::FpuContext": [
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(1)))",
      "Plain",
      "Ref"
    ],
    "arch::cpu::context::FxSaveArea": [
      "Plain"
    ],
    "core::ops::RangeTo": [
      "Plain"
    ]
  },
  "path": {
    "type": "Local",
    "path": "ostd::<arch::cpu::context::FpuContext as core::clone::Clone>::clone"
  },
  "span": "ostd/src/arch/x86/cpu/context/mod.rs:565:5: 580:6",
  "src": "fn clone(&self) -> Self {\n        let mut xsave_area = Box::new(XSaveArea::new());\n        xsave_area.fxsave_area = self.xsave_area.fxsave_area;\n        xsave_area.features = self.xsave_area.features;\n        xsave_area.compaction = self.xsave_area.compaction;\n        if self.area_size > size_of::<FxSaveArea>() {\n            let len = self.area_size - size_of::<FxSaveArea>() - 64;\n            xsave_area.extended_state_area[..len]\n                .copy_from_slice(&self.xsave_area.extended_state_area[..len]);\n        }\n\n        Self {\n            xsave_area,\n            area_size: self.area_size,\n        }\n    }",
  "mir": "fn <arch::cpu::context::FpuContext as core::clone::Clone>::clone(_1: &arch::cpu::context::FpuContext) -> arch::cpu::context::FpuContext {\n    let mut _0: arch::cpu::context::FpuContext;\n    let mut _2: alloc::boxed::Box<arch::cpu::context::XSaveArea>;\n    let mut _3: arch::cpu::context::XSaveArea;\n    let mut _4: arch::cpu::context::FxSaveArea;\n    let mut _5: u64;\n    let mut _6: u64;\n    let mut _7: bool;\n    let mut _8: usize;\n    let mut _9: usize;\n    let  _10: usize;\n    let mut _11: usize;\n    let mut _12: usize;\n    let mut _13: usize;\n    let mut _14: (usize, bool);\n    let mut _15: (usize, bool);\n    let  _16: ();\n    let mut _17: &mut [u8];\n    let mut _18: &mut [u8; 3520];\n    let mut _19: core::ops::RangeTo<usize>;\n    let  _20: &[u8];\n    let mut _21: &[u8; 3520];\n    let mut _22: core::ops::RangeTo<usize>;\n    let mut _23: usize;\n    let mut _24: alloc::boxed::Box<arch::cpu::context::XSaveArea>;\n    let mut _25: alloc::boxed::Box<arch::cpu::context::XSaveArea>;\n    let mut _26: alloc::boxed::Box<arch::cpu::context::XSaveArea>;\n    let mut _27: alloc::boxed::Box<arch::cpu::context::XSaveArea>;\n    let mut _28: *const arch::cpu::context::XSaveArea;\n    let mut _29: *const arch::cpu::context::XSaveArea;\n    let mut _30: *const arch::cpu::context::XSaveArea;\n    let mut _31: *const arch::cpu::context::XSaveArea;\n    let mut _32: *const arch::cpu::context::XSaveArea;\n    let mut _33: *const arch::cpu::context::XSaveArea;\n    let mut _34: *const arch::cpu::context::XSaveArea;\n    let mut _35: *const arch::cpu::context::XSaveArea;\n    debug self => _1;\n    debug xsave_area => _2;\n    debug len => _10;\n    bb0: {\n        StorageLive(_3);\n        _3 = arch::cpu::context::XSaveArea::new() -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        _2 = alloc::boxed::Box::<arch::cpu::context::XSaveArea>::new(move _3) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_3);\n        StorageLive(_4);\n        _24 = ((*_1).0: alloc::boxed::Box<arch::cpu::context::XSaveArea>);\n        _28 = ((_24.0: core::ptr::Unique<arch::cpu::context::XSaveArea>).0: core::ptr::NonNull<arch::cpu::context::XSaveArea>) as *const arch::cpu::context::XSaveArea;\n        _4 = ((*_28).0: arch::cpu::context::FxSaveArea);\n        _29 = ((_2.0: core::ptr::Unique<arch::cpu::context::XSaveArea>).0: core::ptr::NonNull<arch::cpu::context::XSaveArea>) as *const arch::cpu::context::XSaveArea;\n        ((*_29).0: arch::cpu::context::FxSaveArea) = move _4;\n        StorageDead(_4);\n        StorageLive(_5);\n        _25 = ((*_1).0: alloc::boxed::Box<arch::cpu::context::XSaveArea>);\n        _30 = ((_25.0: core::ptr::Unique<arch::cpu::context::XSaveArea>).0: core::ptr::NonNull<arch::cpu::context::XSaveArea>) as *const arch::cpu::context::XSaveArea;\n        _5 = ((*_30).1: u64);\n        _31 = ((_2.0: core::ptr::Unique<arch::cpu::context::XSaveArea>).0: core::ptr::NonNull<arch::cpu::context::XSaveArea>) as *const arch::cpu::context::XSaveArea;\n        ((*_31).1: u64) = move _5;\n        StorageDead(_5);\n        StorageLive(_6);\n        _26 = ((*_1).0: alloc::boxed::Box<arch::cpu::context::XSaveArea>);\n        _32 = ((_26.0: core::ptr::Unique<arch::cpu::context::XSaveArea>).0: core::ptr::NonNull<arch::cpu::context::XSaveArea>) as *const arch::cpu::context::XSaveArea;\n        _6 = ((*_32).2: u64);\n        _33 = ((_2.0: core::ptr::Unique<arch::cpu::context::XSaveArea>).0: core::ptr::NonNull<arch::cpu::context::XSaveArea>) as *const arch::cpu::context::XSaveArea;\n        ((*_33).2: u64) = move _6;\n        StorageDead(_6);\n        StorageLive(_7);\n        StorageLive(_8);\n        _8 = ((*_1).1: usize);\n        StorageLive(_9);\n        _9 = core::mem::size_of::<arch::cpu::context::FxSaveArea>() -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        _7 = Gt(move _8, move _9);\n        switchInt(move _7) -> [0: bb11, otherwise: bb4];\n    }\n    bb4: {\n        StorageDead(_9);\n        StorageDead(_8);\n        StorageLive(_11);\n        StorageLive(_12);\n        _12 = ((*_1).1: usize);\n        StorageLive(_13);\n        _13 = core::mem::size_of::<arch::cpu::context::FxSaveArea>() -> [return: bb5, unwind unreachable];\n    }\n    bb5: {\n        _14 = CheckedSub(_12, _13);\n        assert(!move (_14.1: bool), \"attempt to compute `{} - {}`, which would overflow\", move _12, move _13) -> [success: bb6, unwind unreachable];\n    }\n    bb6: {\n        _11 = move (_14.0: usize);\n        StorageDead(_13);\n        StorageDead(_12);\n        _15 = CheckedSub(_11, 64_usize);\n        assert(!move (_15.1: bool), \"attempt to compute `{} - {}`, which would overflow\", move _11, 64_usize) -> [success: bb7, unwind unreachable];\n    }\n    bb7: {\n        _10 = move (_15.0: usize);\n        StorageDead(_11);\n        StorageLive(_18);\n        _34 = ((_2.0: core::ptr::Unique<arch::cpu::context::XSaveArea>).0: core::ptr::NonNull<arch::cpu::context::XSaveArea>) as *const arch::cpu::context::XSaveArea;\n        _18 = &mut ((*_34).4: [u8; 3520]);\n        StorageLive(_19);\n        _19 = RangeTo(_10);\n        _17 = <[u8; 3520] as core::ops::IndexMut<core::ops::RangeTo<usize>>>::index_mut(move _18, move _19) -> [return: bb8, unwind unreachable];\n    }\n    bb8: {\n        StorageDead(_19);\n        StorageDead(_18);\n        StorageLive(_21);\n        _27 = ((*_1).0: alloc::boxed::Box<arch::cpu::context::XSaveArea>);\n        _35 = ((_27.0: core::ptr::Unique<arch::cpu::context::XSaveArea>).0: core::ptr::NonNull<arch::cpu::context::XSaveArea>) as *const arch::cpu::context::XSaveArea;\n        _21 = &((*_35).4: [u8; 3520]);\n        StorageLive(_22);\n        _22 = RangeTo(_10);\n        _20 = <[u8; 3520] as core::ops::Index<core::ops::RangeTo<usize>>>::index(move _21, move _22) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_22);\n        StorageDead(_21);\n        _16 = core::slice::<impl [u8]>::copy_from_slice(_17, _20) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        goto -> bb12;\n    }\n    bb11: {\n        StorageDead(_9);\n        StorageDead(_8);\n        goto -> bb12;\n    }\n    bb12: {\n        StorageDead(_7);\n        StorageLive(_23);\n        _23 = ((*_1).1: usize);\n        _0 = FpuContext(_2, move _23);\n        StorageDead(_23);\n        return;\n    }\n}\n",
  "doc": "",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}