{
  "name": "mm::vm_space::VmSpace::activate",
  "safe": true,
  "callees": {
    "task::preempt::guard::disable_preempt": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Disables preemption.\n",
      "adt": {
        "task::preempt::guard::DisabledPreemptGuard": "Constructor"
      }
    },
    "cpu::id::current::PinCurrentCpu::current_cpu": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the ID of the current CPU.\n",
      "adt": {
        "cpu::id::CpuId": "Constructor"
      }
    },
    "cpu::local::cell::CpuLocalCell::<T>::load": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Gets the value of the per-CPU object in a single instruction.\n\n Note that this memory operation will not be elided or reordered by the\n compiler since it is a black-box.\n",
      "adt": {
        "cpu::local::cell::CpuLocalCell": "MutableAsArgument"
      }
    },
    "alloc::sync::Arc::<T, A>::as_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Provides a raw pointer to the data.\n\n The counts are not affected in any way and the `Arc` is not consumed. The pointer is valid for\n as long as there are strong counts in the `Arc`.\n\n # Examples\n\n ```\n use std::sync::Arc;\n\n let x = Arc::new(\"hello\".to_owned());\n let y = Arc::clone(&x);\n let x_ptr = Arc::as_ptr(&x);\n assert_eq!(x_ptr, Arc::as_ptr(&y));\n assert_eq!(unsafe { &*x_ptr }, \"hello\");\n ```\n",
      "adt": {}
    },
    "core::ops::Deref::deref": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Dereferences the value.\n",
      "adt": {}
    },
    "util::id_set::AtomicIdSet::<I>::add": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Atomically adds an ID with the given ordering.\n",
      "adt": {
        "util::id_set::AtomicIdSet": "ImmutableAsArgument"
      }
    },
    "core::clone::Clone::clone": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns a duplicate of the value.\n\n Note that what \"duplicate\" means varies by type:\n - For most types, this creates a deep, independent copy\n - For reference types like `&T`, this creates another reference to the same value\n - For smart pointers like [`Arc`] or [`Rc`], this increments the reference count\n   but still points to the same underlying data\n\n [`Arc`]: ../../std/sync/struct.Arc.html\n [`Rc`]: ../../std/rc/struct.Rc.html\n\n # Examples\n\n ```\n # #![allow(noop_method_call)]\n let hello = \"Hello\"; // &str implements Clone\n\n assert_eq!(\"Hello\", hello.clone());\n ```\n\n Example with a reference-counted type:\n\n ```\n use std::sync::{Arc, Mutex};\n\n let data = Arc::new(Mutex::new(vec![1, 2, 3]));\n let data_clone = data.clone(); // Creates another Arc pointing to the same Mutex\n\n {\n     let mut lock = data.lock().unwrap();\n     lock.push(4);\n }\n\n // Changes are visible through the clone because they share the same underlying data\n assert_eq!(*data_clone.lock().unwrap(), vec![1, 2, 3, 4]);\n ```\n",
      "adt": {}
    },
    "alloc::sync::Arc::<T>::into_raw": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Consumes the `Arc`, returning the wrapped pointer.\n\n To avoid a memory leak the pointer must be converted back to an `Arc` using\n [`Arc::from_raw`].\n\n # Examples\n\n ```\n use std::sync::Arc;\n\n let x = Arc::new(\"hello\".to_owned());\n let x_ptr = Arc::into_raw(x);\n assert_eq!(unsafe { &*x_ptr }, \"hello\");\n # // Prevent leaks for Miri.\n # drop(unsafe { Arc::from_raw(x_ptr) });\n ```\n",
      "adt": {}
    },
    "cpu::local::cell::CpuLocalCell::<T>::store": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Writes a value to the per-CPU object in a single instruction.\n\n Note that this memory operation will not be elided or reordered by the\n compiler since it is a black-box.\n",
      "adt": {
        "cpu::local::cell::CpuLocalCell": "MutableAsArgument"
      }
    },
    "core::ptr::const_ptr::<impl *const T>::is_null": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "\n # Examples\n\n ```\n let s: &str = \"Follow the rabbit\";\n let ptr: *const u8 = s.as_ptr();\n assert!(!ptr.is_null());\n ```\n",
      "adt": {}
    },
    "alloc::sync::Arc::<T>::from_raw": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Constructs an `Arc<T>` from a raw pointer.\n\n The raw pointer must have been previously returned by a call to\n [`Arc<U>::into_raw`][into_raw] with the following requirements:\n\n * If `U` is sized, it must have the same size and alignment as `T`. This\n   is trivially true if `U` is `T`.\n * If `U` is unsized, its data pointer must have the same size and\n   alignment as `T`. This is trivially true if `Arc<U>` was constructed\n   through `Arc<T>` and then converted to `Arc<U>` through an [unsized\n   coercion].\n\n Note that if `U` or `U`'s data pointer is not `T` but has the same size\n and alignment, this is basically like transmuting references of\n different types. See [`mem::transmute`][transmute] for more information\n on what restrictions apply in this case.\n\n The raw pointer must point to a block of memory allocated by the global allocator.\n\n The user of `from_raw` has to make sure a specific value of `T` is only\n dropped once.\n\n This function is unsafe because improper use may lead to memory unsafety,\n even if the returned `Arc<T>` is never accessed.\n\n [into_raw]: Arc::into_raw\n [transmute]: core::mem::transmute\n [unsized coercion]: https://doc.rust-lang.org/reference/type-coercions.html#unsized-coercions\n\n # Examples\n\n ```\n use std::sync::Arc;\n\n let x = Arc::new(\"hello\".to_owned());\n let x_ptr = Arc::into_raw(x);\n\n unsafe {\n     // Convert back to an `Arc` to prevent leak.\n     let x = Arc::from_raw(x_ptr);\n     assert_eq!(&*x, \"hello\");\n\n     // Further calls to `Arc::from_raw(x_ptr)` would be memory-unsafe.\n }\n\n // The memory was freed when `x` went out of scope above, so `x_ptr` is now dangling!\n ```\n\n Convert a slice back into its original array:\n\n ```\n use std::sync::Arc;\n\n let x: Arc<[u32]> = Arc::new([1, 2, 3]);\n let x_ptr: *const [u32] = Arc::into_raw(x);\n\n unsafe {\n     let x: Arc<[u32; 3]> = Arc::from_raw(x_ptr.cast::<[u32; 3]>());\n     assert_eq!(&*x, &[1, 2, 3]);\n }\n ```\n",
      "adt": {}
    },
    "util::id_set::AtomicIdSet::<I>::remove": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Atomically removes an ID with the given ordering.\n",
      "adt": {
        "util::id_set::AtomicIdSet": "ImmutableAsArgument"
      }
    },
    "mm::page_table::PageTable::<mm::vm_space::UserPtConfig>::activate": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "mm::page_table::PageTable": "ImmutableAsArgument"
      }
    }
  },
  "adts": {
    "task::preempt::guard::DisabledPreemptGuard": [
      "Plain",
      "Ref"
    ],
    "cpu::id::CpuId": [
      "Plain"
    ],
    "cpu::local::cell::CpuLocalCell": [
      "Ref"
    ],
    "alloc::sync::Arc": [
      "Ref",
      "Plain"
    ],
    "mm::vm_space::VmSpace": [
      "Ref",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(1)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(0)))"
    ],
    "util::id_set::AtomicIdSet": [
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ],
    "mm::page_table::PageTable": [
      "Ref"
    ]
  },
  "path": 2496,
  "span": "ostd/src/mm/vm_space.rs:125:5: 150:6",
  "src": "pub fn activate(self: &Arc<Self>) {\n        let preempt_guard = disable_preempt();\n        let cpu = preempt_guard.current_cpu();\n\n        let last_ptr = ACTIVATED_VM_SPACE.load();\n\n        if last_ptr == Arc::as_ptr(self) {\n            return;\n        }\n\n        // Record ourselves in the CPU set and the activated VM space pointer.\n        // `Acquire` to ensure the modification to the PT is visible by this CPU.\n        self.cpus.add(cpu, Ordering::Acquire);\n\n        let self_ptr = Arc::into_raw(Arc::clone(self)) as *mut VmSpace;\n        ACTIVATED_VM_SPACE.store(self_ptr);\n\n        if !last_ptr.is_null() {\n            // SAFETY: The pointer is cast from an `Arc` when it's activated\n            // the last time, so it can be restored and only restored once.\n            let last = unsafe { Arc::from_raw(last_ptr) };\n            last.cpus.remove(cpu, Ordering::Relaxed);\n        }\n\n        self.pt.activate();\n    }",
  "mir": "fn mm::vm_space::VmSpace::activate(_1: &alloc::sync::Arc<mm::vm_space::VmSpace>) -> () {\n    let mut _0: ();\n    let  _2: task::preempt::guard::DisabledPreemptGuard;\n    let  _3: cpu::id::CpuId;\n    let mut _4: &task::preempt::guard::DisabledPreemptGuard;\n    let  _5: *const mm::vm_space::VmSpace;\n    let mut _6: &cpu::local::cell::CpuLocalCell<*const mm::vm_space::VmSpace>;\n    let mut _7: bool;\n    let mut _8: *const mm::vm_space::VmSpace;\n    let  _9: ();\n    let mut _10: &util::id_set::AtomicIdSet<cpu::id::CpuId>;\n    let  _11: &mm::vm_space::VmSpace;\n    let mut _12: core::sync::atomic::Ordering;\n    let  _13: *mut mm::vm_space::VmSpace;\n    let mut _14: *const mm::vm_space::VmSpace;\n    let mut _15: alloc::sync::Arc<mm::vm_space::VmSpace>;\n    let  _16: ();\n    let mut _17: &cpu::local::cell::CpuLocalCell<*const mm::vm_space::VmSpace>;\n    let mut _18: *const mm::vm_space::VmSpace;\n    let mut _19: bool;\n    let  _20: alloc::sync::Arc<mm::vm_space::VmSpace>;\n    let  _21: ();\n    let mut _22: &util::id_set::AtomicIdSet<cpu::id::CpuId>;\n    let  _23: &mm::vm_space::VmSpace;\n    let mut _24: &alloc::sync::Arc<mm::vm_space::VmSpace>;\n    let mut _25: core::sync::atomic::Ordering;\n    let  _26: ();\n    let mut _27: &mm::page_table::PageTable<mm::vm_space::UserPtConfig>;\n    let  _28: &mm::vm_space::VmSpace;\n    debug self => _1;\n    debug preempt_guard => task::preempt::guard::DisabledPreemptGuard {{ _private: () }};\n    debug cpu => _3;\n    debug last_ptr => _5;\n    debug self_ptr => _13;\n    debug last => _20;\n    bb0: {\n        _2 = task::preempt::guard::disable_preempt() -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageLive(_4);\n        _4 = &_2;\n        _3 = <task::preempt::guard::DisabledPreemptGuard as cpu::id::current::PinCurrentCpu>::current_cpu(move _4) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_4);\n        StorageLive(_6);\n        _6 = {alloc1381: &cpu::local::cell::CpuLocalCell<*const mm::vm_space::VmSpace>};\n        _5 = cpu::local::cell::CpuLocalCell::<*const mm::vm_space::VmSpace>::load(move _6) -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        StorageDead(_6);\n        StorageLive(_7);\n        StorageLive(_8);\n        _8 = alloc::sync::Arc::<mm::vm_space::VmSpace>::as_ptr(_1) -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        _7 = Eq(_5, move _8);\n        switchInt(move _7) -> [0: bb6, otherwise: bb5];\n    }\n    bb5: {\n        StorageDead(_8);\n        StorageDead(_7);\n        drop(_2) -> [return: bb22, unwind unreachable];\n    }\n    bb6: {\n        StorageDead(_8);\n        StorageDead(_7);\n        StorageLive(_10);\n        StorageLive(_11);\n        _11 = <alloc::sync::Arc<mm::vm_space::VmSpace> as core::ops::Deref>::deref(_1) -> [return: bb7, unwind unreachable];\n    }\n    bb7: {\n        _10 = &((*_11).1: util::id_set::AtomicIdSet<cpu::id::CpuId>);\n        StorageLive(_12);\n        _12 = core::sync::atomic::Ordering::Acquire;\n        _9 = util::id_set::AtomicIdSet::<cpu::id::CpuId>::add(move _10, _3, move _12) -> [return: bb8, unwind unreachable];\n    }\n    bb8: {\n        StorageDead(_12);\n        StorageDead(_10);\n        StorageDead(_11);\n        StorageLive(_14);\n        StorageLive(_15);\n        _15 = <alloc::sync::Arc<mm::vm_space::VmSpace> as core::clone::Clone>::clone(_1) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        _14 = alloc::sync::Arc::<mm::vm_space::VmSpace>::into_raw(move _15) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        StorageDead(_15);\n        _13 = move _14 as *mut mm::vm_space::VmSpace;\n        StorageDead(_14);\n        StorageLive(_17);\n        _17 = {alloc1381: &cpu::local::cell::CpuLocalCell<*const mm::vm_space::VmSpace>};\n        StorageLive(_18);\n        _18 = _13 as *const mm::vm_space::VmSpace;\n        _16 = cpu::local::cell::CpuLocalCell::<*const mm::vm_space::VmSpace>::store(move _17, move _18) -> [return: bb11, unwind unreachable];\n    }\n    bb11: {\n        StorageDead(_18);\n        StorageDead(_17);\n        StorageLive(_19);\n        _19 = core::ptr::const_ptr::<impl *const mm::vm_space::VmSpace>::is_null(_5) -> [return: bb12, unwind unreachable];\n    }\n    bb12: {\n        switchInt(move _19) -> [0: bb14, otherwise: bb13];\n    }\n    bb13: {\n        goto -> bb19;\n    }\n    bb14: {\n        StorageLive(_20);\n        _20 = alloc::sync::Arc::<mm::vm_space::VmSpace>::from_raw(_5) -> [return: bb15, unwind unreachable];\n    }\n    bb15: {\n        StorageLive(_22);\n        StorageLive(_23);\n        StorageLive(_24);\n        _24 = &_20;\n        _23 = <alloc::sync::Arc<mm::vm_space::VmSpace> as core::ops::Deref>::deref(move _24) -> [return: bb16, unwind unreachable];\n    }\n    bb16: {\n        StorageDead(_24);\n        _22 = &((*_23).1: util::id_set::AtomicIdSet<cpu::id::CpuId>);\n        StorageLive(_25);\n        _25 = core::sync::atomic::Ordering::Relaxed;\n        _21 = util::id_set::AtomicIdSet::<cpu::id::CpuId>::remove(move _22, _3, move _25) -> [return: bb17, unwind unreachable];\n    }\n    bb17: {\n        StorageDead(_25);\n        StorageDead(_22);\n        StorageDead(_23);\n        drop(_20) -> [return: bb18, unwind unreachable];\n    }\n    bb18: {\n        StorageDead(_20);\n        goto -> bb19;\n    }\n    bb19: {\n        StorageDead(_19);\n        StorageLive(_27);\n        StorageLive(_28);\n        _28 = <alloc::sync::Arc<mm::vm_space::VmSpace> as core::ops::Deref>::deref(_1) -> [return: bb20, unwind unreachable];\n    }\n    bb20: {\n        _27 = &((*_28).0: mm::page_table::PageTable<mm::vm_space::UserPtConfig>);\n        _26 = mm::page_table::PageTable::<mm::vm_space::UserPtConfig>::activate(move _27) -> [return: bb21, unwind unreachable];\n    }\n    bb21: {\n        StorageDead(_27);\n        StorageDead(_28);\n        drop(_2) -> [return: bb22, unwind unreachable];\n    }\n    bb22: {\n        return;\n    }\n}\n",
  "doc": " Activates the page table on the current CPU.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}