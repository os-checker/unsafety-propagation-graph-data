{
  "name": "mm::tlb::TlbFlusher::<'a, G>::sync_tlb_flush",
  "safe": true,
  "callees": {
    "core::option::Option::<T>::is_none": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns `true` if the option is a [`None`] value.\n\n # Examples\n\n ```\n let x: Option<u32> = Some(2);\n assert_eq!(x.is_none(), false);\n\n let x: Option<u32> = None;\n assert_eq!(x.is_none(), true);\n ```\n",
      "adt": {}
    },
    "arch::irq::ops::is_local_enabled": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {}
    },
    "core::fmt::Arguments::<'a>::from_str": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Create a `fmt::Arguments` object for a single static string.\n\n Formatting this `fmt::Arguments` will just produce the string as-is.\n",
      "adt": {}
    },
    "core::panicking::panic_fmt": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " The entry point for panicking with a formatted message.\n\n This is designed to reduce the amount of code required at the call\n site as much as possible (so that `panic!()` has as low an impact\n on (e.g.) the inlining of other functions as possible), by moving\n the actual formatting into this shared place.\n",
      "adt": {}
    },
    "util::id_set::IdSet::<I>::iter": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Iterates over all IDs in the set.\n\n The iteration is guaranteed to be in ascending order.\n",
      "adt": {
        "util::id_set::IdSet": "ImmutableAsArgument",
        "core::iter::Map": "Constructor"
      }
    },
    "core::iter::IntoIterator::into_iter": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates an iterator from a value.\n\n See the [module-level documentation] for more.\n\n [module-level documentation]: crate::iter\n\n # Examples\n\n ```\n let v = [1, 2, 3];\n let mut iter = v.into_iter();\n\n assert_eq!(Some(1), iter.next());\n assert_eq!(Some(2), iter.next());\n assert_eq!(Some(3), iter.next());\n assert_eq!(None, iter.next());\n ```\n",
      "adt": {}
    },
    "core::iter::Iterator::next": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Advances the iterator and returns the next value.\n\n Returns [`None`] when iteration is finished. Individual iterator\n implementations may choose to resume iteration, and so calling `next()`\n again may or may not eventually start returning [`Some(Item)`] again at some\n point.\n\n [`Some(Item)`]: Some\n\n # Examples\n\n ```\n let a = [1, 2, 3];\n\n let mut iter = a.into_iter();\n\n // A call to next() returns the next value...\n assert_eq!(Some(1), iter.next());\n assert_eq!(Some(2), iter.next());\n assert_eq!(Some(3), iter.next());\n\n // ... and then None once it's over.\n assert_eq!(None, iter.next());\n\n // More calls may or may not return `None`. Here, they always will.\n assert_eq!(None, iter.next());\n assert_eq!(None, iter.next());\n ```\n",
      "adt": {}
    },
    "util::id_set::IdSet::<I>::new_empty": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates a new `IdSet` with no IDs in the system.\n",
      "adt": {
        "util::id_set::IdSet": "Constructor"
      }
    },
    "cpu::local::CpuLocal::<T, S>::get_on_cpu": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Gets access to the CPU-local value on a specific CPU.\n\n This allows the caller to access CPU-local data from a remote CPU,\n so the data type must be `Sync`.\n",
      "adt": {
        "cpu::local::CpuLocal": "ImmutableAsArgument"
      }
    },
    "core::sync::atomic::AtomicBool::load": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Loads a value from the bool.\n\n `load` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. Possible values are [`SeqCst`], [`Acquire`] and [`Relaxed`].\n\n # Panics\n\n Panics if `order` is [`Release`] or [`AcqRel`].\n\n # Examples\n\n ```\n use std::sync::atomic::{AtomicBool, Ordering};\n\n let some_bool = AtomicBool::new(true);\n\n assert_eq!(some_bool.load(Ordering::Relaxed), true);\n ```\n",
      "adt": {}
    },
    "core::hint::spin_loop": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Emits a machine instruction to signal the processor that it is running in\n a busy-wait spin-loop (\"spin lock\").\n\n Upon receiving the spin-loop signal the processor can optimize its behavior by,\n for example, saving power or switching hyper-threads.\n\n This function is different from [`thread::yield_now`] which directly\n yields to the system's scheduler, whereas `spin_loop` does not interact\n with the operating system.\n\n A common use case for `spin_loop` is implementing bounded optimistic\n spinning in a CAS loop in synchronization primitives. To avoid problems\n like priority inversion, it is strongly recommended that the spin loop is\n terminated after a finite amount of iterations and an appropriate blocking\n syscall is made.\n\n **Note**: On platforms that do not support receiving spin-loop hints this\n function does not do anything at all.\n\n # Examples\n\n ```ignore-wasm\n use std::sync::atomic::{AtomicBool, Ordering};\n use std::sync::Arc;\n use std::{hint, thread};\n\n // A shared atomic value that threads will use to coordinate\n let live = Arc::new(AtomicBool::new(false));\n\n // In a background thread we'll eventually set the value\n let bg_work = {\n     let live = live.clone();\n     thread::spawn(move || {\n         // Do some work, then make the value live\n         do_some_work();\n         live.store(true, Ordering::Release);\n     })\n };\n\n // Back on our current thread, we wait for the value to be set\n while !live.load(Ordering::Acquire) {\n     // The spin loop is a hint to the CPU that we're waiting, but probably\n     // not for very long\n     hint::spin_loop();\n }\n\n // The value is now set\n # fn do_some_work() {}\n do_some_work();\n bg_work.join()?;\n # Ok::<(), Box<dyn core::any::Any + Send + 'static>>(())\n ```\n\n [`thread::yield_now`]: ../../std/thread/fn.yield_now.html\n",
      "adt": {}
    }
  },
  "adts": {
    "core::option::Option": [
      "Ref",
      "Plain",
      "Unknown([Downcast(VariantIdx(1, ThreadLocalIndex)), Field(0, Ty { id: 2350, kind: RigidTy(Adt(AdtDef(DefId { id: 4216, name: \"cpu::id::CpuId\" }), GenericArgs([]))) })])"
    ],
    "mm::tlb::TlbFlusher": [
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(3)))",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(1)))",
      "MutRef"
    ],
    "core::fmt::Arguments": [
      "Plain"
    ],
    "util::id_set::IdSet": [
      "Ref",
      "Plain"
    ],
    "core::iter::Map": [
      "Plain",
      "MutRef"
    ],
    "cpu::id::CpuId": [
      "Plain"
    ],
    "cpu::local::CpuLocal": [
      "Ref"
    ],
    "core::sync::atomic::AtomicBool": [
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ]
  },
  "path": 2462,
  "span": "ostd/src/mm/tlb.rs:141:5: 160:6",
  "src": "pub fn sync_tlb_flush(&mut self) {\n        if self.ipi_sender.is_none() {\n            // We performed some TLB flushes in the boot context. The AP's boot\n            // process should take care of them.\n            return;\n        }\n\n        assert!(\n            irq::is_local_enabled(),\n            \"Waiting for remote flush with IRQs disabled\"\n        );\n\n        for cpu in self.have_unsynced_flush.iter() {\n            while !ACK_REMOTE_FLUSH.get_on_cpu(cpu).load(Ordering::Relaxed) {\n                core::hint::spin_loop();\n            }\n        }\n\n        self.have_unsynced_flush = CpuSet::new_empty();\n    }",
  "mir": "fn mm::tlb::TlbFlusher::<'a, G>::sync_tlb_flush(_1: &mut mm::tlb::TlbFlusher<'_, G>) -> () {\n    let mut _0: ();\n    let mut _2: bool;\n    let mut _3: &core::option::Option<&smp::IpiSender>;\n    let mut _4: bool;\n    let  _5: !;\n    let mut _6: core::fmt::Arguments<'_>;\n    let mut _7: core::iter::Map<bitvec::slice::IterOnes<'_, u64, bitvec::order::Lsb0>, {closure@ostd/src/util/id_set.rs:268:18: 268:31}>;\n    let mut _8: core::iter::Map<bitvec::slice::IterOnes<'_, u64, bitvec::order::Lsb0>, {closure@ostd/src/util/id_set.rs:268:18: 268:31}>;\n    let mut _9: &util::id_set::IdSet<cpu::id::CpuId>;\n    let mut _10: core::iter::Map<bitvec::slice::IterOnes<'_, u64, bitvec::order::Lsb0>, {closure@ostd/src/util/id_set.rs:268:18: 268:31}>;\n    let mut _11: core::option::Option<cpu::id::CpuId>;\n    let mut _12: &mut core::iter::Map<bitvec::slice::IterOnes<'_, u64, bitvec::order::Lsb0>, {closure@ostd/src/util/id_set.rs:268:18: 268:31}>;\n    let mut _13: isize;\n    let  _14: cpu::id::CpuId;\n    let mut _15: bool;\n    let  _16: &core::sync::atomic::AtomicBool;\n    let mut _17: &cpu::local::CpuLocal<core::sync::atomic::AtomicBool, cpu::local::static_cpu_local::StaticStorage<core::sync::atomic::AtomicBool>>;\n    let mut _18: core::sync::atomic::Ordering;\n    let  _19: ();\n    let mut _20: util::id_set::IdSet<cpu::id::CpuId>;\n    debug self => _1;\n    debug iter => _10;\n    debug cpu => _14;\n    bb0: {\n        StorageLive(_2);\n        StorageLive(_3);\n        _3 = &((*_1).3: core::option::Option<&smp::IpiSender>);\n        _2 = core::option::Option::<&smp::IpiSender>::is_none(move _3) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        switchInt(move _2) -> [0: bb3, otherwise: bb2];\n    }\n    bb2: {\n        StorageDead(_3);\n        StorageDead(_2);\n        goto -> bb23;\n    }\n    bb3: {\n        StorageDead(_3);\n        StorageDead(_2);\n        StorageLive(_4);\n        _4 = arch::irq::ops::is_local_enabled() -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        switchInt(move _4) -> [0: bb5, otherwise: bb7];\n    }\n    bb5: {\n        StorageLive(_6);\n        _6 = core::fmt::Arguments::<'_>::from_str(\"Waiting for remote flush with IRQs disabled\") -> [return: bb6, unwind unreachable];\n    }\n    bb6: {\n        _5 = core::panicking::panic_fmt(move _6) -> unwind unreachable;\n    }\n    bb7: {\n        StorageDead(_4);\n        StorageLive(_7);\n        StorageLive(_8);\n        StorageLive(_9);\n        _9 = &((*_1).1: util::id_set::IdSet<cpu::id::CpuId>);\n        _8 = util::id_set::IdSet::<cpu::id::CpuId>::iter(move _9) -> [return: bb8, unwind unreachable];\n    }\n    bb8: {\n        StorageDead(_9);\n        _7 = <core::iter::Map<bitvec::slice::IterOnes<'_, u64, bitvec::order::Lsb0>, {closure@ostd/src/util/id_set.rs:268:18: 268:31}> as core::iter::IntoIterator>::into_iter(move _8) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_8);\n        StorageLive(_10);\n        _10 = move _7;\n        goto -> bb10;\n    }\n    bb10: {\n        StorageLive(_11);\n        _12 = &mut _10;\n        _11 = <core::iter::Map<bitvec::slice::IterOnes<'_, u64, bitvec::order::Lsb0>, {closure@ostd/src/util/id_set.rs:268:18: 268:31}> as core::iter::Iterator>::next(_12) -> [return: bb11, unwind unreachable];\n    }\n    bb11: {\n        _13 = discriminant(_11);\n        switchInt(move _13) -> [0: bb14, 1: bb13, otherwise: bb12];\n    }\n    bb12: {\n        unreachable;\n    }\n    bb13: {\n        _14 = ((_11 as variant#1).0: cpu::id::CpuId);\n        goto -> bb15;\n    }\n    bb14: {\n        StorageDead(_11);\n        StorageDead(_10);\n        StorageDead(_7);\n        StorageLive(_20);\n        _20 = util::id_set::IdSet::<cpu::id::CpuId>::new_empty() -> [return: bb21, unwind unreachable];\n    }\n    bb15: {\n        StorageLive(_15);\n        StorageLive(_17);\n        _17 = {alloc1371: &cpu::local::CpuLocal<core::sync::atomic::AtomicBool, cpu::local::static_cpu_local::StaticStorage<core::sync::atomic::AtomicBool>>};\n        _16 = cpu::local::CpuLocal::<core::sync::atomic::AtomicBool, cpu::local::static_cpu_local::StaticStorage<core::sync::atomic::AtomicBool>>::get_on_cpu(move _17, _14) -> [return: bb16, unwind unreachable];\n    }\n    bb16: {\n        StorageDead(_17);\n        StorageLive(_18);\n        _18 = core::sync::atomic::Ordering::Relaxed;\n        _15 = core::sync::atomic::AtomicBool::load(_16, move _18) -> [return: bb17, unwind unreachable];\n    }\n    bb17: {\n        switchInt(move _15) -> [0: bb19, otherwise: bb18];\n    }\n    bb18: {\n        StorageDead(_18);\n        StorageDead(_15);\n        StorageDead(_11);\n        goto -> bb10;\n    }\n    bb19: {\n        StorageDead(_18);\n        _19 = core::hint::spin_loop() -> [return: bb20, unwind unreachable];\n    }\n    bb20: {\n        StorageDead(_15);\n        goto -> bb15;\n    }\n    bb21: {\n        drop(((*_1).1: util::id_set::IdSet<cpu::id::CpuId>)) -> [return: bb22, unwind unreachable];\n    }\n    bb22: {\n        ((*_1).1: util::id_set::IdSet<cpu::id::CpuId>) = move _20;\n        StorageDead(_20);\n        goto -> bb23;\n    }\n    bb23: {\n        return;\n    }\n}\n",
  "doc": " Waits for all the previous TLB flush requests to be completed.\n\n After this function, all TLB entries corresponding to previous\n dispatched TLB flush requests are guaranteed to be coherent.\n\n The TLB flush requests are issued with [`Self::issue_tlb_flush`] and\n dispatched with [`Self::dispatch_tlb_flush`]. This method will not\n dispatch any issued requests so it will not guarantee TLB coherence\n of requests that are not dispatched.\n\n # Panics\n\n This method panics if the IRQs are disabled. Since the remote flush are\n processed in IRQs, two CPUs may deadlock if they are waiting for each\n other's TLB coherence.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}