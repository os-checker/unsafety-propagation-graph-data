{
  "name": "arch::trap::gdt::init_on_cpu",
  "safe": false,
  "callees": {
    "cpu::local::static_cpu_local::<impl cpu::local::CpuLocal<T, cpu::local::static_cpu_local::StaticStorage<T>>>::as_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Gets access to the underlying value through a raw pointer.\n\n This method is safe, but using the returned pointer will be unsafe.\n",
      "adt": {
        "cpu::local::CpuLocal": "ImmutableAsArgument"
      }
    },
    "x86_64::structures::gdt::Descriptor::tss_segment_unchecked": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Similar to [`Descriptor::tss_segment`], but unsafe since it does not enforce a lifetime\n constraint on the provided TSS.\n\n # Safety\n The caller must ensure that the passed pointer is valid for as long as the descriptor is\n being used.\n",
      "adt": {}
    },
    "core::panicking::panic": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " The underlying implementation of core's `panic!` macro when no formatting is used.\n",
      "adt": {}
    },
    "x86_64::instructions::segmentation::Segment::get_reg": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the current value of the segment register.\n",
      "adt": {}
    },
    "core::cmp::PartialEq::eq": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Tests for `self` and `other` values to be equal, and is used by `==`.\n",
      "adt": {}
    },
    "alloc::boxed::Box::<T>::new": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Allocates memory on the heap and then places `x` into it.\n\n This doesn't actually allocate if `T` is zero-sized.\n\n # Examples\n\n ```\n let five = Box::new(5);\n ```\n",
      "adt": {}
    },
    "core::panicking::assert_failed": {
      "safe": true,
      "tags": {
        "tags": [
          {
            "tag": {
              "typ": null,
              "name": "hidden"
            },
            "args": []
          }
        ],
        "spec": {},
        "docs": [
          "* hidden\n"
        ]
      },
      "doc": " Internal function for `assert_eq!` and `assert_ne!` macros\n",
      "adt": {}
    },
    "alloc::boxed::Box::<T, A>::leak": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Consumes and leaks the `Box`, returning a mutable reference,\n `&'a mut T`.\n\n Note that the type `T` must outlive the chosen lifetime `'a`. If the type\n has only static references, or none at all, then this may be chosen to be\n `'static`.\n\n This function is mainly useful for data that lives for the remainder of\n the program's life. Dropping the returned reference will cause a memory\n leak. If this is not acceptable, the reference should first be wrapped\n with the [`Box::from_raw`] function producing a `Box`. This `Box` can\n then be dropped which will properly destroy `T` and release the\n allocated memory.\n\n Note: this is an associated function, which means that you have\n to call it as `Box::leak(b)` instead of `b.leak()`. This\n is so that there is no conflict with a method on the inner type.\n\n # Examples\n\n Simple usage:\n\n ```\n let x = Box::new(41);\n let static_ref: &'static mut usize = Box::leak(x);\n *static_ref += 1;\n assert_eq!(*static_ref, 42);\n # // FIXME(https://github.com/rust-lang/miri/issues/3670):\n # // use -Zmiri-disable-leak-check instead of unleaking in tests meant to leak.\n # drop(unsafe { Box::from_raw(static_ref) });\n ```\n\n Unsized data:\n\n ```\n let x = vec![1, 2, 3].into_boxed_slice();\n let static_ref = Box::leak(x);\n static_ref[0] = 4;\n assert_eq!(*static_ref, [4, 2, 3]);\n # // FIXME(https://github.com/rust-lang/miri/issues/3670):\n # // use -Zmiri-disable-leak-check instead of unleaking in tests meant to leak.\n # drop(unsafe { Box::from_raw(static_ref) });\n ```\n",
      "adt": {}
    },
    "x86_64::registers::segmentation::SegmentSelector::index": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the GDT index.\n",
      "adt": {}
    },
    "core::mem::size_of_val": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the size of the pointed-to value in bytes.\n\n This is usually the same as [`size_of::<T>()`]. However, when `T` *has* no\n statically-known size, e.g., a slice [`[T]`][slice] or a [trait object],\n then `size_of_val` can be used to get the dynamically-known size.\n\n [trait object]: ../../book/ch17-02-trait-objects.html\n\n # Examples\n\n ```\n assert_eq!(4, size_of_val(&5i32));\n\n let x: [u8; 13] = [0; 13];\n let y: &[u8] = &x;\n assert_eq!(13, size_of_val(y));\n ```\n\n [`size_of::<T>()`]: size_of\n",
      "adt": {}
    },
    "core::slice::<impl [T]>::as_ptr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns a raw pointer to the slice's buffer.\n\n The caller must ensure that the slice outlives the pointer this\n function returns, or else it will end up dangling.\n\n The caller must also ensure that the memory the pointer (non-transitively) points to\n is never written to (except inside an `UnsafeCell`) using this pointer or any pointer\n derived from it. If you need to mutate the contents of the slice, use [`as_mut_ptr`].\n\n Modifying the container referenced by this slice may cause its buffer\n to be reallocated, which would also make any pointers to it invalid.\n\n # Examples\n\n ```\n let x = &[1, 2, 4];\n let x_ptr = x.as_ptr();\n\n unsafe {\n     for i in 0..x.len() {\n         assert_eq!(x.get_unchecked(i), &*x_ptr.add(i));\n     }\n }\n ```\n\n [`as_mut_ptr`]: slice::as_mut_ptr\n",
      "adt": {}
    },
    "core::ptr::const_ptr::<impl *const T>::addr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {}
    },
    "x86_64::VirtAddr::new": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates a new canonical virtual address.\n\n This function performs sign extension of bit 47 to make the address canonical.\n\n ## Panics\n\n This function panics if the bits in the range 48 to 64 contain data (i.e. are not null and no sign extension).\n",
      "adt": {}
    },
    "x86_64::instructions::tables::lgdt": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Load a GDT.\n\n Use the\n [`GlobalDescriptorTable`](crate::structures::gdt::GlobalDescriptorTable) struct for a high-level\n interface to loading a GDT.\n\n ## Safety\n\n This function is unsafe because the caller must ensure that the given\n `DescriptorTablePointer` points to a valid GDT and that loading this\n GDT is safe.\n",
      "adt": {}
    },
    "x86_64::registers::segmentation::SegmentSelector::new": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates a new SegmentSelector\n\n # Arguments\n  * `index`: index in GDT or LDT array (not the offset)\n  * `rpl`: the requested privilege level\n",
      "adt": {}
    },
    "x86_64::instructions::tables::load_tss": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Load the task state register using the `ltr` instruction.\n\n Note that loading a TSS segment selector marks the corresponding TSS\n Descriptor in the GDT as \"busy\", preventing it from being loaded again\n (either on this CPU or another CPU). TSS structures (including Descriptors\n and Selectors) should generally be per-CPU. See\n [`tss_segment`](crate::structures::gdt::Descriptor::tss_segment)\n for more information.\n\n Calling `load_tss` with a busy TSS selector results in a `#GP` exception.\n\n ## Safety\n\n This function is unsafe because the caller must ensure that the given\n `SegmentSelector` points to a valid TSS entry in the GDT and that the\n corresponding data in the TSS is valid.\n",
      "adt": {}
    },
    "x86_64::registers::model_specific::x86_64::<impl x86_64::registers::model_specific::Star>::write_raw": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Write the Ring 0 and Ring 3 segment bases.\n The remaining fields are ignored because they are\n not valid for long mode.\n\n # Parameters\n - sysret: The CS selector is set to this field + 16. SS.Sel is set to\n this field + 8. Because SYSRET always returns to CPL 3, the\n RPL bits 1:0 should be initialized to 11b.\n - syscall: This field is copied directly into CS.Sel. SS.Sel is set to\n  this field + 8. Because SYSCALL always switches to CPL 0, the RPL bits\n 33:32 should be initialized to 00b.\n\n # Safety\n\n Unsafe because this can cause system instability if passed in the\n wrong values for the fields.\n",
      "adt": {}
    }
  },
  "adts": {
    "cpu::local::CpuLocal": [
      "Ref"
    ],
    "x86_64::structures::gdt::Descriptor": [
      "Plain",
      "Unknown([Downcast(VariantIdx(1, ThreadLocalIndex)), Field(0, Ty { id: 59, kind: RigidTy(Uint(U64)) })])",
      "Unknown([Downcast(VariantIdx(1, ThreadLocalIndex)), Field(1, Ty { id: 59, kind: RigidTy(Uint(U64)) })])"
    ],
    "x86_64::registers::segmentation::SegmentSelector": [
      "Plain",
      "Ref",
      "RefVariantField(VariantIdx(None)-FieldIdx(Some(0)))",
      "RefVariantField(VariantIdx(None)-FieldIdx(Some(1)))",
      "Unknown([Field(0, Ty { id: 74, kind: RigidTy(Uint(U16)) })])"
    ],
    "alloc::boxed::Box": [
      "Plain"
    ],
    "core::panicking::AssertKind": [
      "Plain"
    ],
    "core::option::Option": [
      "Plain"
    ],
    "x86_64::VirtAddr": [
      "Plain"
    ],
    "x86_64::structures::DescriptorTablePointer": [
      "Plain",
      "Ref"
    ],
    "x86_64::PrivilegeLevel": [
      "Plain"
    ]
  },
  "path": 1533,
  "span": "ostd/src/arch/x86/trap/gdt.rs:33:1: 88:2",
  "src": "pub(super) unsafe fn init_on_cpu() {\n    let tss_ptr = LOCAL_TSS.as_ptr();\n\n    // FIXME: The segment limit in the descriptor created by `tss_segment_unchecked` does not\n    // include the I/O port bitmap.\n\n    // SAFETY: As a CPU-local variable, the TSS lives for `'static`.\n    let tss_desc = unsafe { Descriptor::tss_segment_unchecked(tss_ptr) };\n    let (tss0, tss1) = match tss_desc {\n        Descriptor::SystemSegment(tss0, tss1) => (tss0, tss1),\n        _ => unreachable!(),\n    };\n\n    // The kernel CS is considered a global invariant set by the boot GDT. This method is not\n    // intended for switching to a new kernel CS.\n    assert_eq!(CS::get_reg(), KERNEL_CS);\n\n    // Allocate a new GDT with 8 entries.\n    let gdt = Box::new([\n        0, KCODE64, KDATA, /* UCODE32 (not used) */ 0, UDATA, UCODE64, tss0, tss1,\n    ]);\n    let gdt = &*Box::leak(gdt);\n    assert_eq!(gdt[KERNEL_CS.index() as usize], KCODE64);\n    assert_eq!(gdt[KERNEL_SS.index() as usize], KDATA);\n    assert_eq!(gdt[USER_CS.index() as usize], UCODE64);\n    assert_eq!(gdt[USER_SS.index() as usize], UDATA);\n\n    // Load the new GDT.\n    let gdtr = DescriptorTablePointer {\n        limit: (size_of_val(gdt) - 1) as u16,\n        base: VirtAddr::new(gdt.as_ptr().addr() as u64),\n    };\n    // SAFETY: The GDT is valid to load because:\n    //  - It lives for `'static`.\n    //  - It contains correct entries at correct indexes: the kernel code/data segments, the user\n    //    code/data segments, and the TSS segment.\n    //  - Specifically, the TSS segment points to the CPU-local TSS of the current CPU.\n    unsafe { lgdt(&gdtr) };\n\n    // Load the TSS.\n    let tss_sel = SegmentSelector::new(6, PrivilegeLevel::Ring0);\n    assert_eq!(gdt[tss_sel.index() as usize], tss0);\n    assert_eq!(gdt[(tss_sel.index() + 1) as usize], tss1);\n    // SAFETY: The selector points to the TSS descriptors in the GDT.\n    unsafe { load_tss(tss_sel) };\n\n    // Set up the selectors for the `syscall` and `sysret` instructions.\n    let sysret = SegmentSelector::new(3, PrivilegeLevel::Ring3);\n    assert_eq!(gdt[(sysret.index() + 1) as usize], UDATA);\n    assert_eq!(gdt[(sysret.index() + 2) as usize], UCODE64);\n    let syscall = SegmentSelector::new(1, PrivilegeLevel::Ring0);\n    assert_eq!(gdt[syscall.index() as usize], KCODE64);\n    assert_eq!(gdt[(syscall.index() + 1) as usize], KDATA);\n    // SAFETY: The selector points to correct kernel/user code/data descriptors in the GDT.\n    unsafe { Star::write_raw(sysret.0, syscall.0) };\n}",
  "mir": "fn arch::trap::gdt::init_on_cpu() -> () {\n    let mut _0: ();\n    let  _1: *const x86_64::structures::tss::TaskStateSegment;\n    let mut _2: &cpu::local::CpuLocal<x86_64::structures::tss::TaskStateSegment, cpu::local::static_cpu_local::StaticStorage<x86_64::structures::tss::TaskStateSegment>>;\n    let  _3: x86_64::structures::gdt::Descriptor;\n    let  _4: u64;\n    let  _5: u64;\n    let mut _6: (u64, u64);\n    let mut _7: isize;\n    let  _8: u64;\n    let  _9: u64;\n    let mut _10: !;\n    let mut _11: (&x86_64::registers::segmentation::SegmentSelector, &x86_64::registers::segmentation::SegmentSelector);\n    let mut _12: &x86_64::registers::segmentation::SegmentSelector;\n    let  _13: x86_64::registers::segmentation::SegmentSelector;\n    let mut _14: &x86_64::registers::segmentation::SegmentSelector;\n    let  _15: &x86_64::registers::segmentation::SegmentSelector;\n    let  _16: &x86_64::registers::segmentation::SegmentSelector;\n    let mut _17: bool;\n    let  _18: core::panicking::AssertKind;\n    let  _19: !;\n    let mut _20: core::option::Option<core::fmt::Arguments<'_>>;\n    let  _21: alloc::boxed::Box<[u64; 8]>;\n    let mut _22: [u64; 8];\n    let  _23: &[u64; 8];\n    let  _24: &mut [u64; 8];\n    let mut _25: (&u64, &u64);\n    let mut _26: &u64;\n    let  _27: usize;\n    let mut _28: u16;\n    let mut _29: bool;\n    let mut _30: &u64;\n    let  _31: &u64;\n    let  _32: &u64;\n    let mut _33: bool;\n    let mut _34: u64;\n    let mut _35: u64;\n    let  _36: core::panicking::AssertKind;\n    let  _37: !;\n    let mut _38: core::option::Option<core::fmt::Arguments<'_>>;\n    let mut _39: (&u64, &u64);\n    let mut _40: &u64;\n    let  _41: usize;\n    let mut _42: u16;\n    let mut _43: bool;\n    let mut _44: &u64;\n    let  _45: &u64;\n    let  _46: &u64;\n    let mut _47: bool;\n    let mut _48: u64;\n    let mut _49: u64;\n    let  _50: core::panicking::AssertKind;\n    let  _51: !;\n    let mut _52: core::option::Option<core::fmt::Arguments<'_>>;\n    let mut _53: (&u64, &u64);\n    let mut _54: &u64;\n    let  _55: usize;\n    let mut _56: u16;\n    let mut _57: bool;\n    let mut _58: &u64;\n    let  _59: &u64;\n    let  _60: &u64;\n    let mut _61: bool;\n    let mut _62: u64;\n    let mut _63: u64;\n    let  _64: core::panicking::AssertKind;\n    let  _65: !;\n    let mut _66: core::option::Option<core::fmt::Arguments<'_>>;\n    let mut _67: (&u64, &u64);\n    let mut _68: &u64;\n    let  _69: usize;\n    let mut _70: u16;\n    let mut _71: bool;\n    let mut _72: &u64;\n    let  _73: &u64;\n    let  _74: &u64;\n    let mut _75: bool;\n    let mut _76: u64;\n    let mut _77: u64;\n    let  _78: core::panicking::AssertKind;\n    let  _79: !;\n    let mut _80: core::option::Option<core::fmt::Arguments<'_>>;\n    let  _81: x86_64::structures::DescriptorTablePointer;\n    let mut _82: u16;\n    let mut _83: usize;\n    let mut _84: usize;\n    let mut _85: (usize, bool);\n    let mut _86: x86_64::VirtAddr;\n    let mut _87: u64;\n    let mut _88: usize;\n    let mut _89: *const u64;\n    let mut _90: &[u64];\n    let  _91: ();\n    let  _92: &x86_64::structures::DescriptorTablePointer;\n    let  _93: x86_64::registers::segmentation::SegmentSelector;\n    let mut _94: x86_64::PrivilegeLevel;\n    let mut _95: (&u64, &u64);\n    let mut _96: &u64;\n    let  _97: usize;\n    let mut _98: u16;\n    let mut _99: bool;\n    let mut _100: &u64;\n    let  _101: &u64;\n    let  _102: &u64;\n    let mut _103: bool;\n    let mut _104: u64;\n    let mut _105: u64;\n    let  _106: core::panicking::AssertKind;\n    let  _107: !;\n    let mut _108: core::option::Option<core::fmt::Arguments<'_>>;\n    let mut _109: (&u64, &u64);\n    let mut _110: &u64;\n    let  _111: usize;\n    let mut _112: u16;\n    let mut _113: u16;\n    let mut _114: (u16, bool);\n    let mut _115: bool;\n    let mut _116: &u64;\n    let  _117: &u64;\n    let  _118: &u64;\n    let mut _119: bool;\n    let mut _120: u64;\n    let mut _121: u64;\n    let  _122: core::panicking::AssertKind;\n    let  _123: !;\n    let mut _124: core::option::Option<core::fmt::Arguments<'_>>;\n    let  _125: ();\n    let  _126: x86_64::registers::segmentation::SegmentSelector;\n    let mut _127: x86_64::PrivilegeLevel;\n    let mut _128: (&u64, &u64);\n    let mut _129: &u64;\n    let  _130: usize;\n    let mut _131: u16;\n    let mut _132: u16;\n    let mut _133: (u16, bool);\n    let mut _134: bool;\n    let mut _135: &u64;\n    let  _136: &u64;\n    let  _137: &u64;\n    let mut _138: bool;\n    let mut _139: u64;\n    let mut _140: u64;\n    let  _141: core::panicking::AssertKind;\n    let  _142: !;\n    let mut _143: core::option::Option<core::fmt::Arguments<'_>>;\n    let mut _144: (&u64, &u64);\n    let mut _145: &u64;\n    let  _146: usize;\n    let mut _147: u16;\n    let mut _148: u16;\n    let mut _149: (u16, bool);\n    let mut _150: bool;\n    let mut _151: &u64;\n    let  _152: &u64;\n    let  _153: &u64;\n    let mut _154: bool;\n    let mut _155: u64;\n    let mut _156: u64;\n    let  _157: core::panicking::AssertKind;\n    let  _158: !;\n    let mut _159: core::option::Option<core::fmt::Arguments<'_>>;\n    let  _160: x86_64::registers::segmentation::SegmentSelector;\n    let mut _161: x86_64::PrivilegeLevel;\n    let mut _162: (&u64, &u64);\n    let mut _163: &u64;\n    let  _164: usize;\n    let mut _165: u16;\n    let mut _166: bool;\n    let mut _167: &u64;\n    let  _168: &u64;\n    let  _169: &u64;\n    let mut _170: bool;\n    let mut _171: u64;\n    let mut _172: u64;\n    let  _173: core::panicking::AssertKind;\n    let  _174: !;\n    let mut _175: core::option::Option<core::fmt::Arguments<'_>>;\n    let mut _176: (&u64, &u64);\n    let mut _177: &u64;\n    let  _178: usize;\n    let mut _179: u16;\n    let mut _180: u16;\n    let mut _181: (u16, bool);\n    let mut _182: bool;\n    let mut _183: &u64;\n    let  _184: &u64;\n    let  _185: &u64;\n    let mut _186: bool;\n    let mut _187: u64;\n    let mut _188: u64;\n    let  _189: core::panicking::AssertKind;\n    let  _190: !;\n    let mut _191: core::option::Option<core::fmt::Arguments<'_>>;\n    let  _192: ();\n    let mut _193: u16;\n    let mut _194: u16;\n    debug tss_ptr => _1;\n    debug tss_desc => _3;\n    debug tss0 => _4;\n    debug tss1 => _5;\n    debug tss0 => _8;\n    debug tss1 => _9;\n    debug left_val => _15;\n    debug right_val => _16;\n    debug kind => _18;\n    debug gdt => _21;\n    debug gdt => _23;\n    debug left_val => _31;\n    debug right_val => _32;\n    debug kind => _36;\n    debug left_val => _45;\n    debug right_val => _46;\n    debug kind => _50;\n    debug left_val => _59;\n    debug right_val => _60;\n    debug kind => _64;\n    debug left_val => _73;\n    debug right_val => _74;\n    debug kind => _78;\n    debug gdtr => _81;\n    debug tss_sel => _93;\n    debug left_val => _101;\n    debug right_val => _102;\n    debug kind => _106;\n    debug left_val => _117;\n    debug right_val => _118;\n    debug kind => _122;\n    debug sysret => _126;\n    debug left_val => _136;\n    debug right_val => _137;\n    debug kind => _141;\n    debug left_val => _152;\n    debug right_val => _153;\n    debug kind => _157;\n    debug syscall => _160;\n    debug left_val => _168;\n    debug right_val => _169;\n    debug kind => _173;\n    debug left_val => _184;\n    debug right_val => _185;\n    debug kind => _189;\n    bb0: {\n        StorageLive(_2);\n        _2 = {alloc601: &cpu::local::CpuLocal<x86_64::structures::tss::TaskStateSegment, cpu::local::static_cpu_local::StaticStorage<x86_64::structures::tss::TaskStateSegment>>};\n        _1 = cpu::local::static_cpu_local::<impl cpu::local::CpuLocal<x86_64::structures::tss::TaskStateSegment, cpu::local::static_cpu_local::StaticStorage<x86_64::structures::tss::TaskStateSegment>>>::as_ptr(move _2) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_2);\n        StorageLive(_3);\n        _3 = x86_64::structures::gdt::Descriptor::tss_segment_unchecked(_1) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageLive(_6);\n        _7 = discriminant(_3);\n        switchInt(move _7) -> [1: bb4, 0: bb3, otherwise: bb66];\n    }\n    bb3: {\n        _10 = core::panicking::panic(\"internal error: entered unreachable code\") -> unwind unreachable;\n    }\n    bb4: {\n        _8 = ((_3 as variant#1).0: u64);\n        _9 = ((_3 as variant#1).1: u64);\n        _6 = (_8, _9);\n        _4 = (_6.0: u64);\n        _5 = (_6.1: u64);\n        StorageDead(_6);\n        StorageLive(_11);\n        StorageLive(_12);\n        StorageLive(_13);\n        _13 = <x86_64::instructions::segmentation::CS as x86_64::instructions::segmentation::Segment>::get_reg() -> [return: bb5, unwind unreachable];\n    }\n    bb5: {\n        _12 = &_13;\n        StorageLive(_14);\n        _14 = arch::trap::gdt::init_on_cpu::promoted[8];\n        _11 = (move _12, move _14);\n        StorageDead(_14);\n        StorageDead(_12);\n        _15 = (_11.0: &x86_64::registers::segmentation::SegmentSelector);\n        _16 = (_11.1: &x86_64::registers::segmentation::SegmentSelector);\n        StorageLive(_17);\n        _17 = <x86_64::registers::segmentation::SegmentSelector as core::cmp::PartialEq>::eq(_15, _16) -> [return: bb6, unwind unreachable];\n    }\n    bb6: {\n        switchInt(move _17) -> [0: bb8, otherwise: bb7];\n    }\n    bb7: {\n        StorageDead(_17);\n        StorageDead(_13);\n        StorageDead(_11);\n        StorageLive(_22);\n        _22 = [0_u64, arch::trap::gdt::KCODE64, arch::trap::gdt::KDATA, 0_u64, arch::trap::gdt::UDATA, arch::trap::gdt::UCODE64, _4, _5];\n        _21 = alloc::boxed::Box::<[u64; 8]>::new(move _22) -> [return: bb9, unwind unreachable];\n    }\n    bb8: {\n        _18 = core::panicking::AssertKind::Eq;\n        StorageLive(_20);\n        _20 = core::option::Option::None;\n        _19 = core::panicking::assert_failed::<x86_64::registers::segmentation::SegmentSelector, x86_64::registers::segmentation::SegmentSelector>(_18, _15, _16, move _20) -> unwind unreachable;\n    }\n    bb9: {\n        StorageDead(_22);\n        StorageLive(_24);\n        _24 = alloc::boxed::Box::<[u64; 8]>::leak::<'_>(_21) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        _23 = &(*_24);\n        StorageLive(_25);\n        StorageLive(_26);\n        StorageLive(_27);\n        StorageLive(_28);\n        _28 = x86_64::registers::segmentation::SegmentSelector::index(arch::trap::gdt::KERNEL_CS) -> [return: bb11, unwind unreachable];\n    }\n    bb11: {\n        _27 = move _28 as usize;\n        StorageDead(_28);\n        _29 = Lt(_27, 8_usize);\n        assert(move _29, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _27) -> [success: bb12, unwind unreachable];\n    }\n    bb12: {\n        _26 = &(*_23)[_27];\n        StorageLive(_30);\n        _30 = arch::trap::gdt::init_on_cpu::promoted[7];\n        _25 = (move _26, move _30);\n        StorageDead(_30);\n        StorageDead(_26);\n        _31 = (_25.0: &u64);\n        _32 = (_25.1: &u64);\n        StorageLive(_33);\n        StorageLive(_34);\n        _34 = (*_31);\n        StorageLive(_35);\n        _35 = (*_32);\n        _33 = Eq(move _34, move _35);\n        switchInt(move _33) -> [0: bb14, otherwise: bb13];\n    }\n    bb13: {\n        StorageDead(_35);\n        StorageDead(_34);\n        StorageDead(_33);\n        StorageDead(_27);\n        StorageDead(_25);\n        StorageLive(_39);\n        StorageLive(_40);\n        StorageLive(_41);\n        StorageLive(_42);\n        _42 = x86_64::registers::segmentation::SegmentSelector::index(arch::trap::gdt::KERNEL_SS) -> [return: bb15, unwind unreachable];\n    }\n    bb14: {\n        StorageDead(_35);\n        StorageDead(_34);\n        _36 = core::panicking::AssertKind::Eq;\n        StorageLive(_38);\n        _38 = core::option::Option::None;\n        _37 = core::panicking::assert_failed::<u64, u64>(_36, _31, _32, move _38) -> unwind unreachable;\n    }\n    bb15: {\n        _41 = move _42 as usize;\n        StorageDead(_42);\n        _43 = Lt(_41, 8_usize);\n        assert(move _43, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _41) -> [success: bb16, unwind unreachable];\n    }\n    bb16: {\n        _40 = &(*_23)[_41];\n        StorageLive(_44);\n        _44 = arch::trap::gdt::init_on_cpu::promoted[6];\n        _39 = (move _40, move _44);\n        StorageDead(_44);\n        StorageDead(_40);\n        _45 = (_39.0: &u64);\n        _46 = (_39.1: &u64);\n        StorageLive(_47);\n        StorageLive(_48);\n        _48 = (*_45);\n        StorageLive(_49);\n        _49 = (*_46);\n        _47 = Eq(move _48, move _49);\n        switchInt(move _47) -> [0: bb18, otherwise: bb17];\n    }\n    bb17: {\n        StorageDead(_49);\n        StorageDead(_48);\n        StorageDead(_47);\n        StorageDead(_41);\n        StorageDead(_39);\n        StorageLive(_53);\n        StorageLive(_54);\n        StorageLive(_55);\n        StorageLive(_56);\n        _56 = x86_64::registers::segmentation::SegmentSelector::index(arch::trap::gdt::USER_CS) -> [return: bb19, unwind unreachable];\n    }\n    bb18: {\n        StorageDead(_49);\n        StorageDead(_48);\n        _50 = core::panicking::AssertKind::Eq;\n        StorageLive(_52);\n        _52 = core::option::Option::None;\n        _51 = core::panicking::assert_failed::<u64, u64>(_50, _45, _46, move _52) -> unwind unreachable;\n    }\n    bb19: {\n        _55 = move _56 as usize;\n        StorageDead(_56);\n        _57 = Lt(_55, 8_usize);\n        assert(move _57, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _55) -> [success: bb20, unwind unreachable];\n    }\n    bb20: {\n        _54 = &(*_23)[_55];\n        StorageLive(_58);\n        _58 = arch::trap::gdt::init_on_cpu::promoted[5];\n        _53 = (move _54, move _58);\n        StorageDead(_58);\n        StorageDead(_54);\n        _59 = (_53.0: &u64);\n        _60 = (_53.1: &u64);\n        StorageLive(_61);\n        StorageLive(_62);\n        _62 = (*_59);\n        StorageLive(_63);\n        _63 = (*_60);\n        _61 = Eq(move _62, move _63);\n        switchInt(move _61) -> [0: bb22, otherwise: bb21];\n    }\n    bb21: {\n        StorageDead(_63);\n        StorageDead(_62);\n        StorageDead(_61);\n        StorageDead(_55);\n        StorageDead(_53);\n        StorageLive(_67);\n        StorageLive(_68);\n        StorageLive(_69);\n        StorageLive(_70);\n        _70 = x86_64::registers::segmentation::SegmentSelector::index(arch::trap::gdt::USER_SS) -> [return: bb23, unwind unreachable];\n    }\n    bb22: {\n        StorageDead(_63);\n        StorageDead(_62);\n        _64 = core::panicking::AssertKind::Eq;\n        StorageLive(_66);\n        _66 = core::option::Option::None;\n        _65 = core::panicking::assert_failed::<u64, u64>(_64, _59, _60, move _66) -> unwind unreachable;\n    }\n    bb23: {\n        _69 = move _70 as usize;\n        StorageDead(_70);\n        _71 = Lt(_69, 8_usize);\n        assert(move _71, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _69) -> [success: bb24, unwind unreachable];\n    }\n    bb24: {\n        _68 = &(*_23)[_69];\n        StorageLive(_72);\n        _72 = arch::trap::gdt::init_on_cpu::promoted[4];\n        _67 = (move _68, move _72);\n        StorageDead(_72);\n        StorageDead(_68);\n        _73 = (_67.0: &u64);\n        _74 = (_67.1: &u64);\n        StorageLive(_75);\n        StorageLive(_76);\n        _76 = (*_73);\n        StorageLive(_77);\n        _77 = (*_74);\n        _75 = Eq(move _76, move _77);\n        switchInt(move _75) -> [0: bb26, otherwise: bb25];\n    }\n    bb25: {\n        StorageDead(_77);\n        StorageDead(_76);\n        StorageDead(_75);\n        StorageDead(_69);\n        StorageDead(_67);\n        StorageLive(_81);\n        StorageLive(_82);\n        StorageLive(_83);\n        StorageLive(_84);\n        _84 = core::mem::size_of_val::<[u64; 8]>(_23) -> [return: bb27, unwind unreachable];\n    }\n    bb26: {\n        StorageDead(_77);\n        StorageDead(_76);\n        _78 = core::panicking::AssertKind::Eq;\n        StorageLive(_80);\n        _80 = core::option::Option::None;\n        _79 = core::panicking::assert_failed::<u64, u64>(_78, _73, _74, move _80) -> unwind unreachable;\n    }\n    bb27: {\n        _85 = CheckedSub(_84, 1_usize);\n        assert(!move (_85.1: bool), \"attempt to compute `{} - {}`, which would overflow\", move _84, 1_usize) -> [success: bb28, unwind unreachable];\n    }\n    bb28: {\n        _83 = move (_85.0: usize);\n        StorageDead(_84);\n        _82 = move _83 as u16;\n        StorageDead(_83);\n        StorageLive(_86);\n        StorageLive(_87);\n        StorageLive(_88);\n        StorageLive(_89);\n        StorageLive(_90);\n        _90 = _23 as &[u64];\n        _89 = core::slice::<impl [u64]>::as_ptr(move _90) -> [return: bb29, unwind unreachable];\n    }\n    bb29: {\n        StorageDead(_90);\n        _88 = core::ptr::const_ptr::<impl *const u64>::addr(move _89) -> [return: bb30, unwind unreachable];\n    }\n    bb30: {\n        StorageDead(_89);\n        _87 = move _88 as u64;\n        StorageDead(_88);\n        _86 = x86_64::VirtAddr::new(move _87) -> [return: bb31, unwind unreachable];\n    }\n    bb31: {\n        StorageDead(_87);\n        _81 = DescriptorTablePointer(move _82, move _86);\n        StorageDead(_86);\n        StorageDead(_82);\n        _92 = &_81;\n        _91 = x86_64::instructions::tables::lgdt(_92) -> [return: bb32, unwind unreachable];\n    }\n    bb32: {\n        StorageLive(_94);\n        _94 = x86_64::PrivilegeLevel::Ring0;\n        _93 = x86_64::registers::segmentation::SegmentSelector::new(6_u16, move _94) -> [return: bb33, unwind unreachable];\n    }\n    bb33: {\n        StorageDead(_94);\n        StorageLive(_95);\n        StorageLive(_96);\n        StorageLive(_97);\n        StorageLive(_98);\n        _98 = x86_64::registers::segmentation::SegmentSelector::index(_93) -> [return: bb34, unwind unreachable];\n    }\n    bb34: {\n        _97 = move _98 as usize;\n        StorageDead(_98);\n        _99 = Lt(_97, 8_usize);\n        assert(move _99, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _97) -> [success: bb35, unwind unreachable];\n    }\n    bb35: {\n        _96 = &(*_23)[_97];\n        StorageLive(_100);\n        _100 = &_4;\n        _95 = (move _96, move _100);\n        StorageDead(_100);\n        StorageDead(_96);\n        _101 = (_95.0: &u64);\n        _102 = (_95.1: &u64);\n        StorageLive(_103);\n        StorageLive(_104);\n        _104 = (*_101);\n        StorageLive(_105);\n        _105 = (*_102);\n        _103 = Eq(move _104, move _105);\n        switchInt(move _103) -> [0: bb37, otherwise: bb36];\n    }\n    bb36: {\n        StorageDead(_105);\n        StorageDead(_104);\n        StorageDead(_103);\n        StorageDead(_97);\n        StorageDead(_95);\n        StorageLive(_109);\n        StorageLive(_110);\n        StorageLive(_111);\n        StorageLive(_112);\n        StorageLive(_113);\n        _113 = x86_64::registers::segmentation::SegmentSelector::index(_93) -> [return: bb38, unwind unreachable];\n    }\n    bb37: {\n        StorageDead(_105);\n        StorageDead(_104);\n        _106 = core::panicking::AssertKind::Eq;\n        StorageLive(_108);\n        _108 = core::option::Option::None;\n        _107 = core::panicking::assert_failed::<u64, u64>(_106, _101, _102, move _108) -> unwind unreachable;\n    }\n    bb38: {\n        _114 = CheckedAdd(_113, 1_u16);\n        assert(!move (_114.1: bool), \"attempt to compute `{} + {}`, which would overflow\", move _113, 1_u16) -> [success: bb39, unwind unreachable];\n    }\n    bb39: {\n        _112 = move (_114.0: u16);\n        StorageDead(_113);\n        _111 = move _112 as usize;\n        StorageDead(_112);\n        _115 = Lt(_111, 8_usize);\n        assert(move _115, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _111) -> [success: bb40, unwind unreachable];\n    }\n    bb40: {\n        _110 = &(*_23)[_111];\n        StorageLive(_116);\n        _116 = &_5;\n        _109 = (move _110, move _116);\n        StorageDead(_116);\n        StorageDead(_110);\n        _117 = (_109.0: &u64);\n        _118 = (_109.1: &u64);\n        StorageLive(_119);\n        StorageLive(_120);\n        _120 = (*_117);\n        StorageLive(_121);\n        _121 = (*_118);\n        _119 = Eq(move _120, move _121);\n        switchInt(move _119) -> [0: bb42, otherwise: bb41];\n    }\n    bb41: {\n        StorageDead(_121);\n        StorageDead(_120);\n        StorageDead(_119);\n        StorageDead(_111);\n        StorageDead(_109);\n        _125 = x86_64::instructions::tables::load_tss(_93) -> [return: bb43, unwind unreachable];\n    }\n    bb42: {\n        StorageDead(_121);\n        StorageDead(_120);\n        _122 = core::panicking::AssertKind::Eq;\n        StorageLive(_124);\n        _124 = core::option::Option::None;\n        _123 = core::panicking::assert_failed::<u64, u64>(_122, _117, _118, move _124) -> unwind unreachable;\n    }\n    bb43: {\n        StorageLive(_127);\n        _127 = x86_64::PrivilegeLevel::Ring3;\n        _126 = x86_64::registers::segmentation::SegmentSelector::new(3_u16, move _127) -> [return: bb44, unwind unreachable];\n    }\n    bb44: {\n        StorageDead(_127);\n        StorageLive(_128);\n        StorageLive(_129);\n        StorageLive(_130);\n        StorageLive(_131);\n        StorageLive(_132);\n        _132 = x86_64::registers::segmentation::SegmentSelector::index(_126) -> [return: bb45, unwind unreachable];\n    }\n    bb45: {\n        _133 = CheckedAdd(_132, 1_u16);\n        assert(!move (_133.1: bool), \"attempt to compute `{} + {}`, which would overflow\", move _132, 1_u16) -> [success: bb46, unwind unreachable];\n    }\n    bb46: {\n        _131 = move (_133.0: u16);\n        StorageDead(_132);\n        _130 = move _131 as usize;\n        StorageDead(_131);\n        _134 = Lt(_130, 8_usize);\n        assert(move _134, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _130) -> [success: bb47, unwind unreachable];\n    }\n    bb47: {\n        _129 = &(*_23)[_130];\n        StorageLive(_135);\n        _135 = arch::trap::gdt::init_on_cpu::promoted[3];\n        _128 = (move _129, move _135);\n        StorageDead(_135);\n        StorageDead(_129);\n        _136 = (_128.0: &u64);\n        _137 = (_128.1: &u64);\n        StorageLive(_138);\n        StorageLive(_139);\n        _139 = (*_136);\n        StorageLive(_140);\n        _140 = (*_137);\n        _138 = Eq(move _139, move _140);\n        switchInt(move _138) -> [0: bb49, otherwise: bb48];\n    }\n    bb48: {\n        StorageDead(_140);\n        StorageDead(_139);\n        StorageDead(_138);\n        StorageDead(_130);\n        StorageDead(_128);\n        StorageLive(_144);\n        StorageLive(_145);\n        StorageLive(_146);\n        StorageLive(_147);\n        StorageLive(_148);\n        _148 = x86_64::registers::segmentation::SegmentSelector::index(_126) -> [return: bb50, unwind unreachable];\n    }\n    bb49: {\n        StorageDead(_140);\n        StorageDead(_139);\n        _141 = core::panicking::AssertKind::Eq;\n        StorageLive(_143);\n        _143 = core::option::Option::None;\n        _142 = core::panicking::assert_failed::<u64, u64>(_141, _136, _137, move _143) -> unwind unreachable;\n    }\n    bb50: {\n        _149 = CheckedAdd(_148, 2_u16);\n        assert(!move (_149.1: bool), \"attempt to compute `{} + {}`, which would overflow\", move _148, 2_u16) -> [success: bb51, unwind unreachable];\n    }\n    bb51: {\n        _147 = move (_149.0: u16);\n        StorageDead(_148);\n        _146 = move _147 as usize;\n        StorageDead(_147);\n        _150 = Lt(_146, 8_usize);\n        assert(move _150, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _146) -> [success: bb52, unwind unreachable];\n    }\n    bb52: {\n        _145 = &(*_23)[_146];\n        StorageLive(_151);\n        _151 = arch::trap::gdt::init_on_cpu::promoted[2];\n        _144 = (move _145, move _151);\n        StorageDead(_151);\n        StorageDead(_145);\n        _152 = (_144.0: &u64);\n        _153 = (_144.1: &u64);\n        StorageLive(_154);\n        StorageLive(_155);\n        _155 = (*_152);\n        StorageLive(_156);\n        _156 = (*_153);\n        _154 = Eq(move _155, move _156);\n        switchInt(move _154) -> [0: bb54, otherwise: bb53];\n    }\n    bb53: {\n        StorageDead(_156);\n        StorageDead(_155);\n        StorageDead(_154);\n        StorageDead(_146);\n        StorageDead(_144);\n        StorageLive(_161);\n        _161 = x86_64::PrivilegeLevel::Ring0;\n        _160 = x86_64::registers::segmentation::SegmentSelector::new(1_u16, move _161) -> [return: bb55, unwind unreachable];\n    }\n    bb54: {\n        StorageDead(_156);\n        StorageDead(_155);\n        _157 = core::panicking::AssertKind::Eq;\n        StorageLive(_159);\n        _159 = core::option::Option::None;\n        _158 = core::panicking::assert_failed::<u64, u64>(_157, _152, _153, move _159) -> unwind unreachable;\n    }\n    bb55: {\n        StorageDead(_161);\n        StorageLive(_162);\n        StorageLive(_163);\n        StorageLive(_164);\n        StorageLive(_165);\n        _165 = x86_64::registers::segmentation::SegmentSelector::index(_160) -> [return: bb56, unwind unreachable];\n    }\n    bb56: {\n        _164 = move _165 as usize;\n        StorageDead(_165);\n        _166 = Lt(_164, 8_usize);\n        assert(move _166, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _164) -> [success: bb57, unwind unreachable];\n    }\n    bb57: {\n        _163 = &(*_23)[_164];\n        StorageLive(_167);\n        _167 = arch::trap::gdt::init_on_cpu::promoted[1];\n        _162 = (move _163, move _167);\n        StorageDead(_167);\n        StorageDead(_163);\n        _168 = (_162.0: &u64);\n        _169 = (_162.1: &u64);\n        StorageLive(_170);\n        StorageLive(_171);\n        _171 = (*_168);\n        StorageLive(_172);\n        _172 = (*_169);\n        _170 = Eq(move _171, move _172);\n        switchInt(move _170) -> [0: bb59, otherwise: bb58];\n    }\n    bb58: {\n        StorageDead(_172);\n        StorageDead(_171);\n        StorageDead(_170);\n        StorageDead(_164);\n        StorageDead(_162);\n        StorageLive(_176);\n        StorageLive(_177);\n        StorageLive(_178);\n        StorageLive(_179);\n        StorageLive(_180);\n        _180 = x86_64::registers::segmentation::SegmentSelector::index(_160) -> [return: bb60, unwind unreachable];\n    }\n    bb59: {\n        StorageDead(_172);\n        StorageDead(_171);\n        _173 = core::panicking::AssertKind::Eq;\n        StorageLive(_175);\n        _175 = core::option::Option::None;\n        _174 = core::panicking::assert_failed::<u64, u64>(_173, _168, _169, move _175) -> unwind unreachable;\n    }\n    bb60: {\n        _181 = CheckedAdd(_180, 1_u16);\n        assert(!move (_181.1: bool), \"attempt to compute `{} + {}`, which would overflow\", move _180, 1_u16) -> [success: bb61, unwind unreachable];\n    }\n    bb61: {\n        _179 = move (_181.0: u16);\n        StorageDead(_180);\n        _178 = move _179 as usize;\n        StorageDead(_179);\n        _182 = Lt(_178, 8_usize);\n        assert(move _182, \"index out of bounds: the length is {} but the index is {}\", 8_usize, _178) -> [success: bb62, unwind unreachable];\n    }\n    bb62: {\n        _177 = &(*_23)[_178];\n        StorageLive(_183);\n        _183 = arch::trap::gdt::init_on_cpu::promoted[0];\n        _176 = (move _177, move _183);\n        StorageDead(_183);\n        StorageDead(_177);\n        _184 = (_176.0: &u64);\n        _185 = (_176.1: &u64);\n        StorageLive(_186);\n        StorageLive(_187);\n        _187 = (*_184);\n        StorageLive(_188);\n        _188 = (*_185);\n        _186 = Eq(move _187, move _188);\n        switchInt(move _186) -> [0: bb64, otherwise: bb63];\n    }\n    bb63: {\n        StorageDead(_188);\n        StorageDead(_187);\n        StorageDead(_186);\n        StorageDead(_178);\n        StorageDead(_176);\n        StorageLive(_193);\n        _193 = (_126.0: u16);\n        StorageLive(_194);\n        _194 = (_160.0: u16);\n        _192 = x86_64::registers::model_specific::x86_64::<impl x86_64::registers::model_specific::Star>::write_raw(move _193, move _194) -> [return: bb65, unwind unreachable];\n    }\n    bb64: {\n        StorageDead(_188);\n        StorageDead(_187);\n        _189 = core::panicking::AssertKind::Eq;\n        StorageLive(_191);\n        _191 = core::option::Option::None;\n        _190 = core::panicking::assert_failed::<u64, u64>(_189, _184, _185, move _191) -> unwind unreachable;\n    }\n    bb65: {\n        StorageDead(_194);\n        StorageDead(_193);\n        StorageDead(_81);\n        StorageDead(_24);\n        StorageDead(_3);\n        return;\n    }\n    bb66: {\n        unreachable;\n    }\n}\n",
  "doc": " Initializes and loads the GDT and TSS.\n\n The caller should only call this method once in the boot context for each available processor.\n This is not a safety requirement, however, because calling this method again will do nothing\n more than load the GDT and TSS with the same contents.\n\n # Safety\n\n The caller must ensure that no preemption can occur during the method, otherwise we may\n accidentally load a wrong GDT and TSS that actually belongs to another CPU.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}