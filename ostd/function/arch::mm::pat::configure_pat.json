{
  "name": "arch::mm::pat::configure_pat",
  "safe": true,
  "callees": {
    "core::slice::<impl [T]>::iter": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns an iterator over the slice.\n\n The iterator yields all items from start to end.\n\n # Examples\n\n ```\n let x = &[1, 2, 4];\n let mut iterator = x.iter();\n\n assert_eq!(iterator.next(), Some(&1));\n assert_eq!(iterator.next(), Some(&2));\n assert_eq!(iterator.next(), Some(&4));\n assert_eq!(iterator.next(), None);\n ```\n",
      "adt": {}
    },
    "core::iter::Iterator::copied": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates an iterator which copies all of its elements.\n\n This is useful when you have an iterator over `&T`, but you need an\n iterator over `T`.\n\n # Examples\n\n ```\n let a = [1, 2, 3];\n\n let v_copied: Vec<_> = a.iter().copied().collect();\n\n // copied is the same as .map(|&x| x)\n let v_map: Vec<_> = a.iter().map(|&x| x).collect();\n\n assert_eq!(v_copied, [1, 2, 3]);\n assert_eq!(v_map, [1, 2, 3]);\n ```\n",
      "adt": {}
    },
    "core::iter::Iterator::enumerate": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates an iterator which gives the current iteration count as well as\n the next value.\n\n The iterator returned yields pairs `(i, val)`, where `i` is the\n current index of iteration and `val` is the value returned by the\n iterator.\n\n `enumerate()` keeps its count as a [`usize`]. If you want to count by a\n different sized integer, the [`zip`] function provides similar\n functionality.\n\n # Overflow Behavior\n\n The method does no guarding against overflows, so enumerating more than\n [`usize::MAX`] elements either produces the wrong result or panics. If\n overflow checks are enabled, a panic is guaranteed.\n\n # Panics\n\n The returned iterator might panic if the to-be-returned index would\n overflow a [`usize`].\n\n [`zip`]: Iterator::zip\n\n # Examples\n\n ```\n let a = ['a', 'b', 'c'];\n\n let mut iter = a.into_iter().enumerate();\n\n assert_eq!(iter.next(), Some((0, 'a')));\n assert_eq!(iter.next(), Some((1, 'b')));\n assert_eq!(iter.next(), Some((2, 'c')));\n assert_eq!(iter.next(), None);\n ```\n",
      "adt": {}
    },
    "core::iter::IntoIterator::into_iter": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Creates an iterator from a value.\n\n See the [module-level documentation] for more.\n\n [module-level documentation]: crate::iter\n\n # Examples\n\n ```\n let v = [1, 2, 3];\n let mut iter = v.into_iter();\n\n assert_eq!(Some(1), iter.next());\n assert_eq!(Some(2), iter.next());\n assert_eq!(Some(3), iter.next());\n assert_eq!(None, iter.next());\n ```\n",
      "adt": {}
    },
    "core::iter::Iterator::next": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Advances the iterator and returns the next value.\n\n Returns [`None`] when iteration is finished. Individual iterator\n implementations may choose to resume iteration, and so calling `next()`\n again may or may not eventually start returning [`Some(Item)`] again at some\n point.\n\n [`Some(Item)`]: Some\n\n # Examples\n\n ```\n let a = [1, 2, 3];\n\n let mut iter = a.into_iter();\n\n // A call to next() returns the next value...\n assert_eq!(Some(1), iter.next());\n assert_eq!(Some(2), iter.next());\n assert_eq!(Some(3), iter.next());\n\n // ... and then None once it's over.\n assert_eq!(None, iter.next());\n\n // More calls may or may not return `None`. Here, they always will.\n assert_eq!(None, iter.next());\n assert_eq!(None, iter.next());\n ```\n",
      "adt": {}
    },
    "arch::mm::pat::configure_pat::cache_policy_to_pat_entry": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {}
    },
    "x86::msr::wrmsr": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Write 64 bits to msr register.\n\n # Safety\n Needs CPL 0.\n",
      "adt": {}
    }
  },
  "adts": {
    "core::slice::Iter": [
      "Plain"
    ],
    "core::iter::Copied": [
      "Plain"
    ],
    "core::iter::Enumerate": [
      "Plain",
      "MutRef"
    ],
    "core::option::Option": [
      "Plain",
      "Unknown([Downcast(VariantIdx(1, ThreadLocalIndex)), Field(0, Ty { id: 2443, kind: RigidTy(Tuple([Ty { id: 11, kind: RigidTy(Uint(Usize)) }, Ty { id: 1098, kind: RigidTy(Adt(AdtDef(DefId { id: 3469, name: \"mm::page_prop::CachePolicy\" }), GenericArgs([]))) }])) }), Field(0, Ty { id: 11, kind: RigidTy(Uint(Usize)) })])",
      "Unknown([Downcast(VariantIdx(1, ThreadLocalIndex)), Field(0, Ty { id: 2443, kind: RigidTy(Tuple([Ty { id: 11, kind: RigidTy(Uint(Usize)) }, Ty { id: 1098, kind: RigidTy(Adt(AdtDef(DefId { id: 3469, name: \"mm::page_prop::CachePolicy\" }), GenericArgs([]))) }])) }), Field(1, Ty { id: 1098, kind: RigidTy(Adt(AdtDef(DefId { id: 3469, name: \"mm::page_prop::CachePolicy\" }), GenericArgs([]))) })])"
    ],
    "mm::page_prop::CachePolicy": [
      "Plain"
    ]
  },
  "path": 1313,
  "span": "ostd/src/arch/x86/mm/pat.rs:70:1: 95:2",
  "src": "pub(super) fn configure_pat() {\n    // Reference: Intel(R) 64 and IA-32 Architectures Software Developer's Manual, Table 12-10,\n    // \"Memory Types That Can Be Encoded With PAT\".\n    fn cache_policy_to_pat_entry(cache_policy: CachePolicy) -> u8 {\n        match cache_policy {\n            CachePolicy::Uncacheable => 0x00,\n            CachePolicy::WriteCombining => 0x01,\n            CachePolicy::WriteProtected => 0x05,\n            CachePolicy::Writethrough => 0x04,\n            CachePolicy::Writeback => 0x06,\n        }\n    }\n\n    let mut programmed_pat = 0u64;\n    for (idx, policy) in IA32_PAT_MAPPINGS.iter().copied().enumerate() {\n        programmed_pat |= (cache_policy_to_pat_entry(policy) as u64) << (idx * 8);\n    }\n\n    // SAFETY: Writing `IA32_PAT` only programs the PAT MSR of the current CPU.\n    // Updating PAT merely redefines how hardware interprets future cache\n    // policy encodings. The programmed value is the global invariant, which\n    // is set up before the kernel page table is activated.\n    unsafe {\n        wrmsr(IA32_PAT, programmed_pat);\n    }\n}",
  "mir": "fn arch::mm::pat::configure_pat() -> () {\n    let mut _0: ();\n    let mut _1: u64;\n    let mut _2: core::iter::Enumerate<core::iter::Copied<core::slice::Iter<'_, mm::page_prop::CachePolicy>>>;\n    let mut _3: core::iter::Enumerate<core::iter::Copied<core::slice::Iter<'_, mm::page_prop::CachePolicy>>>;\n    let mut _4: core::iter::Copied<core::slice::Iter<'_, mm::page_prop::CachePolicy>>;\n    let mut _5: core::slice::Iter<'_, mm::page_prop::CachePolicy>;\n    let mut _6: &[mm::page_prop::CachePolicy];\n    let mut _7: &[mm::page_prop::CachePolicy; 8];\n    let mut _8: core::iter::Enumerate<core::iter::Copied<core::slice::Iter<'_, mm::page_prop::CachePolicy>>>;\n    let mut _9: core::option::Option<(usize, mm::page_prop::CachePolicy)>;\n    let mut _10: &mut core::iter::Enumerate<core::iter::Copied<core::slice::Iter<'_, mm::page_prop::CachePolicy>>>;\n    let mut _11: isize;\n    let  _12: usize;\n    let  _13: mm::page_prop::CachePolicy;\n    let mut _14: u64;\n    let mut _15: u64;\n    let mut _16: u8;\n    let mut _17: usize;\n    let mut _18: (usize, bool);\n    let mut _19: bool;\n    let  _20: ();\n    let mut _21: u64;\n    debug programmed_pat => _1;\n    debug iter => _8;\n    debug idx => _12;\n    debug policy => _13;\n    bb0: {\n        StorageLive(_1);\n        _1 = 0_u64;\n        StorageLive(_2);\n        StorageLive(_3);\n        StorageLive(_4);\n        StorageLive(_5);\n        StorageLive(_6);\n        StorageLive(_7);\n        _7 = arch::mm::pat::configure_pat::promoted[0];\n        _6 = move _7 as &[mm::page_prop::CachePolicy];\n        StorageDead(_7);\n        _5 = core::slice::<impl [mm::page_prop::CachePolicy]>::iter(move _6) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_6);\n        _4 = <core::slice::Iter<'_, mm::page_prop::CachePolicy> as core::iter::Iterator>::copied::<'_, mm::page_prop::CachePolicy>(move _5) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_5);\n        _3 = <core::iter::Copied<core::slice::Iter<'_, mm::page_prop::CachePolicy>> as core::iter::Iterator>::enumerate(move _4) -> [return: bb3, unwind unreachable];\n    }\n    bb3: {\n        StorageDead(_4);\n        _2 = <core::iter::Enumerate<core::iter::Copied<core::slice::Iter<'_, mm::page_prop::CachePolicy>>> as core::iter::IntoIterator>::into_iter(move _3) -> [return: bb4, unwind unreachable];\n    }\n    bb4: {\n        StorageDead(_3);\n        StorageLive(_8);\n        _8 = move _2;\n        goto -> bb5;\n    }\n    bb5: {\n        StorageLive(_9);\n        _10 = &mut _8;\n        _9 = <core::iter::Enumerate<core::iter::Copied<core::slice::Iter<'_, mm::page_prop::CachePolicy>>> as core::iter::Iterator>::next(_10) -> [return: bb6, unwind unreachable];\n    }\n    bb6: {\n        _11 = discriminant(_9);\n        switchInt(move _11) -> [0: bb9, 1: bb8, otherwise: bb7];\n    }\n    bb7: {\n        unreachable;\n    }\n    bb8: {\n        _12 = (((_9 as variant#1).0: (usize, mm::page_prop::CachePolicy)).0: usize);\n        _13 = (((_9 as variant#1).0: (usize, mm::page_prop::CachePolicy)).1: mm::page_prop::CachePolicy);\n        StorageLive(_14);\n        StorageLive(_15);\n        StorageLive(_16);\n        _16 = arch::mm::pat::configure_pat::cache_policy_to_pat_entry(_13) -> [return: bb10, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_9);\n        StorageDead(_8);\n        StorageDead(_2);\n        StorageLive(_21);\n        _21 = _1;\n        _20 = x86::msr::wrmsr(x86::msr::IA32_PAT, move _21) -> [return: bb13, unwind unreachable];\n    }\n    bb10: {\n        _15 = move _16 as u64;\n        StorageDead(_16);\n        StorageLive(_17);\n        _18 = CheckedMul(_12, 8_usize);\n        assert(!move (_18.1: bool), \"attempt to compute `{} * {}`, which would overflow\", _12, 8_usize) -> [success: bb11, unwind unreachable];\n    }\n    bb11: {\n        _17 = move (_18.0: usize);\n        _19 = Lt(_17, 64_usize);\n        assert(move _19, \"attempt to shift left by `{}`, which would overflow\", _17) -> [success: bb12, unwind unreachable];\n    }\n    bb12: {\n        _14 = Shl(move _15, move _17);\n        StorageDead(_17);\n        StorageDead(_15);\n        _1 = BitOr(_1, move _14);\n        StorageDead(_14);\n        StorageDead(_9);\n        goto -> bb5;\n    }\n    bb13: {\n        StorageDead(_21);\n        StorageDead(_1);\n        return;\n    }\n}\n",
  "doc": " Programs the PAT MSR so that write-combining mappings use the\n correct memory type.\n",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}