{
  "name": "<mm::frame::Frame<M> as core::ops::Drop>::drop",
  "safe": true,
  "callees": {
    "mm::frame::Frame::<M>::slot": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {
        "mm::frame::Frame": "ImmutableAsArgument"
      }
    },
    "core::sync::atomic::AtomicU64::fetch_sub": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Subtracts from the current value, returning the previous value.\n\n This operation wraps around on overflow.\n\n `fetch_sub` takes an [`Ordering`] argument which describes the memory ordering\n of this operation. All ordering modes are possible. Note that using\n [`Acquire`] makes the store part of this operation [`Relaxed`], and\n using [`Release`] makes the load part [`Relaxed`].\n\n **Note**: This method is only available on platforms that support atomic operations on\n\n # Examples\n\n ```\n\n assert_eq!(foo.fetch_sub(10, Ordering::SeqCst), 20);\n assert_eq!(foo.load(Ordering::SeqCst), 10);\n ```\n",
      "adt": {}
    },
    "core::panicking::panic": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " The underlying implementation of core's `panic!` macro when no formatting is used.\n",
      "adt": {}
    },
    "core::sync::atomic::fence": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " An atomic fence.\n\n Fences create synchronization between themselves and atomic operations or fences in other\n threads. To achieve this, a fence prevents the compiler and CPU from reordering certain types of\n memory operations around it.\n\n There are 3 different ways to use an atomic fence:\n\n - atomic - fence synchronization: an atomic operation with (at least) [`Release`] ordering\n   semantics synchronizes with a fence with (at least) [`Acquire`] ordering semantics.\n - fence - atomic synchronization: a fence with (at least) [`Release`] ordering semantics\n   synchronizes with an atomic operation with (at least) [`Acquire`] ordering semantics.\n - fence - fence synchronization: a fence with (at least) [`Release`] ordering semantics\n   synchronizes with a fence with (at least) [`Acquire`] ordering semantics.\n\n These 3 ways complement the regular, fence-less, atomic - atomic synchronization.\n\n ## Atomic - Fence\n\n An atomic operation on one thread will synchronize with a fence on another thread when:\n\n -   on thread 1:\n     -   an atomic operation 'X' with (at least) [`Release`] ordering semantics on some atomic\n         object 'm',\n\n -   is paired on thread 2 with:\n     -   an atomic read 'Y' with any order on 'm',\n     -   followed by a fence 'B' with (at least) [`Acquire`] ordering semantics.\n\n This provides a happens-before dependence between X and B.\n\n ```text\n     Thread 1                                          Thread 2\n\n m.store(3, Release); X ---------\n                                |\n                                |\n                                -------------> Y  if m.load(Relaxed) == 3 {\n                                               B      fence(Acquire);\n                                                      ...\n                                                  }\n ```\n\n ## Fence - Atomic\n\n A fence on one thread will synchronize with an atomic operation on another thread when:\n\n -   on thread:\n     -   a fence 'A' with (at least) [`Release`] ordering semantics,\n     -   followed by an atomic write 'X' with any ordering on some atomic object 'm',\n\n -   is paired on thread 2 with:\n     -   an atomic operation 'Y' with (at least) [`Acquire`] ordering semantics.\n\n This provides a happens-before dependence between A and Y.\n\n ```text\n     Thread 1                                          Thread 2\n\n fence(Release);      A\n m.store(3, Relaxed); X ---------\n                                |\n                                |\n                                -------------> Y  if m.load(Acquire) == 3 {\n                                                      ...\n                                                  }\n ```\n\n ## Fence - Fence\n\n A fence on one thread will synchronize with a fence on another thread when:\n\n -   on thread 1:\n     -   a fence 'A' which has (at least) [`Release`] ordering semantics,\n     -   followed by an atomic write 'X' with any ordering on some atomic object 'm',\n\n -   is paired on thread 2 with:\n     -   an atomic read 'Y' with any ordering on 'm',\n     -   followed by a fence 'B' with (at least) [`Acquire`] ordering semantics.\n\n This provides a happens-before dependence between A and B.\n\n ```text\n     Thread 1                                          Thread 2\n\n fence(Release);      A --------------\n m.store(3, Relaxed); X ---------    |\n                                |    |\n                                |    |\n                                -------------> Y  if m.load(Relaxed) == 3 {\n                                     |-------> B      fence(Acquire);\n                                                      ...\n                                                  }\n ```\n\n ## Mandatory Atomic\n\n Note that in the examples above, it is crucial that the access to `m` are atomic. Fences cannot\n be used to establish synchronization between non-atomic accesses in different threads. However,\n thanks to the happens-before relationship, any non-atomic access that happen-before the atomic\n operation or fence with (at least) [`Release`] ordering semantics are now also properly\n synchronized with any non-atomic accesses that happen-after the atomic operation or fence with\n (at least) [`Acquire`] ordering semantics.\n\n ## Memory Ordering\n\n A fence which has [`SeqCst`] ordering, in addition to having both [`Acquire`] and [`Release`]\n semantics, participates in the global program order of the other [`SeqCst`] operations and/or\n fences.\n\n Accepts [`Acquire`], [`Release`], [`AcqRel`] and [`SeqCst`] orderings.\n\n # Panics\n\n Panics if `order` is [`Relaxed`].\n\n # Examples\n\n ```\n use std::sync::atomic::AtomicBool;\n use std::sync::atomic::fence;\n use std::sync::atomic::Ordering;\n\n // A mutual exclusion primitive based on spinlock.\n pub struct Mutex {\n     flag: AtomicBool,\n }\n\n impl Mutex {\n     pub fn new() -> Mutex {\n         Mutex {\n             flag: AtomicBool::new(false),\n         }\n     }\n\n     pub fn lock(&self) {\n         // Wait until the old value is `false`.\n         while self\n             .flag\n             .compare_exchange_weak(false, true, Ordering::Relaxed, Ordering::Relaxed)\n             .is_err()\n         {}\n         // This fence synchronizes-with store in `unlock`.\n         fence(Ordering::Acquire);\n     }\n\n     pub fn unlock(&self) {\n         self.flag.store(false, Ordering::Release);\n     }\n }\n ```\n",
      "adt": {}
    },
    "mm::frame::meta::MetaSlot::drop_last_in_place": {
      "safe": false,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Drops the metadata and deallocates the frame.\n\n # Safety\n\n The caller should ensure that:\n  - the reference count is `0` (so we are the sole owner of the frame);\n  - the metadata is initialized;\n",
      "adt": {
        "mm::frame::meta::MetaSlot": "ImmutableAsArgument"
      }
    },
    "mm::frame::allocator::get_global_frame_allocator": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": "",
      "adt": {}
    },
    "mm::mem_obj::HasPaddr::paddr": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Returns the start physical address of the memory object.\n",
      "adt": {}
    },
    "mm::frame::allocator::GlobalFrameAllocator::dealloc": {
      "safe": true,
      "tags": {
        "tags": [],
        "spec": {},
        "docs": []
      },
      "doc": " Deallocates a contiguous range of frames.\n\n The caller guarantees that `addr` and `size` are both aligned to\n [`PAGE_SIZE`]. The deallocated memory should always be allocated by\n [`GlobalFrameAllocator::alloc`]. However, if\n [`GlobalFrameAllocator::alloc`] returns multiple frames, it is possible\n that some of them are deallocated before others. The deallocated memory\n must never overlap with any memory that is already deallocated or\n added, without being allocated in between.\n\n The deallocated memory can be uninitialized.\n",
      "adt": {}
    }
  },
  "adts": {
    "mm::frame::Frame": [
      "Ref",
      "Deref",
      "MutRef"
    ],
    "mm::frame::meta::MetaSlot": [
      "Ref",
      "DerefVariantField(VariantIdx(None)-FieldIdx(Some(1)))"
    ],
    "core::sync::atomic::AtomicU64": [
      "Ref"
    ],
    "core::sync::atomic::Ordering": [
      "Plain"
    ]
  },
  "path": 2043,
  "span": "ostd/src/mm/frame/mod.rs:247:5: 261:6",
  "src": "fn drop(&mut self) {\n        let last_ref_cnt = self.slot().ref_count.fetch_sub(1, Ordering::Release);\n        debug_assert!(last_ref_cnt != 0 && last_ref_cnt != REF_COUNT_UNUSED);\n\n        if last_ref_cnt == 1 {\n            // A fence is needed here with the same reasons stated in the implementation of\n            // `Arc::drop`: <https://doc.rust-lang.org/std/sync/struct.Arc.html#method.drop>.\n            core::sync::atomic::fence(Ordering::Acquire);\n\n            // SAFETY: this is the last reference and is about to be dropped.\n            unsafe { self.slot().drop_last_in_place() };\n\n            allocator::get_global_frame_allocator().dealloc(self.paddr(), PAGE_SIZE);\n        }\n    }",
  "mir": "fn <mm::frame::Frame<M> as core::ops::Drop>::drop(_1: &mut mm::frame::Frame<M>) -> () {\n    let mut _0: ();\n    let  _2: u64;\n    let mut _3: &core::sync::atomic::AtomicU64;\n    let  _4: &mm::frame::meta::MetaSlot;\n    let mut _5: &mm::frame::Frame<M>;\n    let mut _6: core::sync::atomic::Ordering;\n    let mut _7: bool;\n    let mut _8: !;\n    let  _9: ();\n    let mut _10: core::sync::atomic::Ordering;\n    let  _11: ();\n    let  _12: &mm::frame::meta::MetaSlot;\n    let mut _13: &mm::frame::Frame<M>;\n    let  _14: ();\n    let  _15: &dyn mm::frame::allocator::GlobalFrameAllocator;\n    let mut _16: usize;\n    let mut _17: &&mut mm::frame::Frame<M>;\n    debug self => _1;\n    debug last_ref_cnt => _2;\n    bb0: {\n        StorageLive(_3);\n        StorageLive(_4);\n        StorageLive(_5);\n        _5 = &(*_1);\n        _4 = mm::frame::Frame::<M>::slot(move _5) -> [return: bb1, unwind unreachable];\n    }\n    bb1: {\n        StorageDead(_5);\n        _3 = &((*_4).1: core::sync::atomic::AtomicU64);\n        StorageLive(_6);\n        _6 = core::sync::atomic::Ordering::Release;\n        _2 = core::sync::atomic::AtomicU64::fetch_sub(move _3, 1_u64, move _6) -> [return: bb2, unwind unreachable];\n    }\n    bb2: {\n        StorageDead(_6);\n        StorageDead(_3);\n        StorageDead(_4);\n        switchInt(_2) -> [0: bb6, otherwise: bb3];\n    }\n    bb3: {\n        StorageLive(_7);\n        _7 = Ne(_2, mm::frame::meta::REF_COUNT_UNUSED);\n        switchInt(move _7) -> [0: bb5, otherwise: bb4];\n    }\n    bb4: {\n        StorageDead(_7);\n        switchInt(_2) -> [1: bb8, otherwise: bb15];\n    }\n    bb5: {\n        goto -> bb7;\n    }\n    bb6: {\n        goto -> bb7;\n    }\n    bb7: {\n        _8 = core::panicking::panic(\"assertion failed: last_ref_cnt != 0 && last_ref_cnt != REF_COUNT_UNUSED\") -> unwind unreachable;\n    }\n    bb8: {\n        StorageLive(_10);\n        _10 = core::sync::atomic::Ordering::Acquire;\n        _9 = core::sync::atomic::fence(move _10) -> [return: bb9, unwind unreachable];\n    }\n    bb9: {\n        StorageDead(_10);\n        StorageLive(_13);\n        _13 = &(*_1);\n        _12 = mm::frame::Frame::<M>::slot(move _13) -> [return: bb10, unwind unreachable];\n    }\n    bb10: {\n        StorageDead(_13);\n        _11 = mm::frame::meta::MetaSlot::drop_last_in_place(_12) -> [return: bb11, unwind unreachable];\n    }\n    bb11: {\n        _15 = mm::frame::allocator::get_global_frame_allocator() -> [return: bb12, unwind unreachable];\n    }\n    bb12: {\n        StorageLive(_16);\n        StorageLive(_17);\n        _17 = &_1;\n        _16 = <&mut mm::frame::Frame<M> as mm::mem_obj::HasPaddr>::paddr(move _17) -> [return: bb13, unwind unreachable];\n    }\n    bb13: {\n        StorageDead(_17);\n        _14 = <dyn mm::frame::allocator::GlobalFrameAllocator as mm::frame::allocator::GlobalFrameAllocator>::dealloc(_15, move _16, mm::PAGE_SIZE) -> [return: bb14, unwind unreachable];\n    }\n    bb14: {\n        StorageDead(_16);\n        goto -> bb16;\n    }\n    bb15: {\n        goto -> bb16;\n    }\n    bb16: {\n        return;\n    }\n}\n",
  "doc": "",
  "tags": {
    "tags": [],
    "spec": {},
    "docs": []
  }
}