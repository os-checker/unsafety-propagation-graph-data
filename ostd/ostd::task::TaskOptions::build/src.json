{
  "name": "ostd::task::TaskOptions::build",
  "span": "ostd/src/task/mod.rs:163:5: 163:39",
  "src": "pub fn build(self) -> Result<Task> {\n        // All tasks will enter this function. It is meant to execute the `task_fn` in `Task`.\n        //\n        // We provide an assembly wrapper for this function as the end of call stack so we\n        // have to disable name mangling for it.\n        //\n        // # Safety\n        //\n        // This function must be called from `switch.S` when the context is prepared correctly.\n        // SAFETY: The name does not collide with other symbols.\n        #[unsafe(no_mangle)]\n        unsafe extern \"C\" fn kernel_task_entry() -> ! {\n            // SAFETY: The new task is switched on a CPU for the first time, `after_switching_to`\n            // hasn't been called yet.\n            unsafe { processor::after_switching_to() };\n\n            let current_task = Task::current()\n                .expect(\"no current task, it should have current task in kernel task entry\");\n\n            // SAFETY: The `func` field will only be accessed by the current task in the task\n            // context, so the data won't be accessed concurrently.\n            let task_func = unsafe { current_task.func.get() };\n            let task_func = task_func\n                .take()\n                .expect(\"task function is `None` when trying to run\");\n            task_func();\n\n            // Manually drop all the on-stack variables to prevent memory leakage!\n            // This is needed because `scheduler::exit_current()` will never return.\n            //\n            // However, `current_task` _borrows_ the current task without holding\n            // an extra reference count. So we do nothing here.\n\n            scheduler::exit_current();\n        }\n\n        let kstack = KernelStack::new_with_guard_page()?;\n\n        let mut ctx = TaskContext::new();\n        ctx.set_instruction_pointer(\n            crate::arch::task::kernel_task_entry_wrapper as *const () as usize,\n        );\n        // We should reserve space for the return address in the stack, otherwise\n        // we will write across the page boundary due to the implementation of\n        // the context switch.\n        //\n        // According to the System V AMD64 ABI, the stack pointer should be aligned\n        // to at least 16 bytes. And a larger alignment is needed if larger arguments\n        // are passed to the function. The `kernel_task_entry` function does not\n        // have any arguments, so we only need to align the stack pointer to 16 bytes.\n        ctx.set_stack_pointer(kstack.end_vaddr() - 16);\n\n        let new_task = Task {\n            func: ForceSync::new(Cell::new(self.func)),\n            data: self.data.unwrap_or_else(|| Box::new(())),\n            local_data: ForceSync::new(self.local_data.unwrap_or_else(|| Box::new(()))),\n            ctx: SyncUnsafeCell::new(ctx),\n            kstack,\n            schedule_info: TaskScheduleInfo {\n                cpu: AtomicCpuId::default(),\n            },\n            switched_to_cpu: AtomicBool::new(false),\n        };\n\n        Ok(new_task)\n    }"
}