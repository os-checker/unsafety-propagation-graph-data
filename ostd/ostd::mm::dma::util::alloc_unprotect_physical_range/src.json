{
  "name": "ostd::mm::dma::util::alloc_unprotect_physical_range",
  "span": "ostd/src/mm/dma/util.rs:163:1: 163:66",
  "src": "unsafe fn alloc_unprotect_physical_range(pa_range: &Range<Paddr>) {\n    use alloc::{vec, vec::Vec};\n\n    debug_assert!(pa_range.start.is_multiple_of(PAGE_SIZE));\n    debug_assert!(pa_range.end.is_multiple_of(PAGE_SIZE));\n    let pfn_range = pa_range.start / PAGE_SIZE..pa_range.end / PAGE_SIZE;\n\n    let mut refcnts = PADDR_REF_CNTS.lock();\n    let ranges = refcnts.add(&pfn_range);\n    #[cfg(target_arch = \"x86_64\")]\n    crate::arch::if_tdx_enabled!({\n        for partial in ranges {\n            debug_assert_eq!(partial, pfn_range.clone());\n            // SAFETY:\n            //  - The provided physical address is page aligned.\n            //  - The provided physical address range is in bounds.\n            //  - All of the physical pages are untyped memory.\n            unsafe {\n                crate::arch::tdx_guest::unprotect_gpa_tdvm_call(\n                    partial.start * PAGE_SIZE,\n                    partial.len() * PAGE_SIZE,\n                )\n                .expect(\"failed to unprotect the DMA segment in TDX guest\");\n            }\n        }\n    } else {\n        debug_assert_eq!(ranges.collect::<Vec<_>>(), vec![pfn_range.clone()]);\n    });\n    #[cfg(not(target_arch = \"x86_64\"))]\n    debug_assert_eq!(ranges.collect::<Vec<_>>(), vec![pfn_range.clone()]);\n}"
}